## 著名网络架构：VGG (2014)
提出者：牛津大学 VGG 团队   
第一作者：Karen Simonyan   
<img width="200" height="260" alt="image" src="https://github.com/user-attachments/assets/626157bc-3d32-4b67-b475-0e9c186dd986" />  
   
 VGG 是由 Karen Simonyan 和 Andrew Zisserman 在 2014 年提出的卷积神经网络（Convolutional Neural Network, CNN）架构，来自牛津大学的视觉几何组（Visual Geometry Group），因此得名 VGG。VGG 在论文《Very Deep Convolutional Networks for Large-Scale Image Recognition》中首次亮相（ICLR 2015），并在 2014 年 ImageNet 大规模视觉识别挑战赛（ILSVRC）中获得分类任务亚军（仅次于 GoogLeNet）和目标检测任务冠军。VGG 以其简单、统一的架构和深层网络设计著称，广泛应用于计算机视觉任务，并对后续模型（如 ResNet、YOLO 等）产生深远影响。    
   
特点：使用多个3x3卷积核堆叠，构建深层网络（16或19层），参数量大但结构规整。  
应用：图像分类、预训练模型用于目标检测和分割。  
掌握要点：深层网络的优缺点、预训练模型应用。  
<img width="500" height="270" alt="image" src="https://github.com/user-attachments/assets/50363707-9ec8-4de3-989f-f57b77d63465" />  
## 代码

该代码实现了一个**简化的VGG-11模型**，用于在**CIFAR-10数据集**上进行图像分类任务。主要功能如下：

1. **模型定义**：
   - 实现简化的VGG-11模型，包含8个卷积层（带ReLU激活和最大池化）和3个全连接层，输出10类分类结果。
   - 卷积层逐步增加通道数（64→128→256→512），通过最大池化降采样（32x32→2x2）。

2. **数据预处理**：
   - 加载CIFAR-10数据集（32x32彩色图像），应用归一化变换。
   - 使用DataLoader进行批处理（batch_size=64）。

3. **训练过程**：
   - 使用SGD优化器（学习率0.001，动量0.9）和交叉熵损失函数，训练模型50个epoch。
   - 每200个批次记录并打印平均损失。

4. **测试过程**：
   - 在测试集上评估模型，计算并输出分类准确率。

5. **可视化**：
   - 绘制训练过程中的损失曲线，保存为`vgg_training_curve.png`。
   - 从测试集取8张图像，显示预测和真实标签，保存为`vgg_predictions.png`，支持中文显示（使用SimHei字体）。

代码运行在CPU或GPU上，训练完成后输出测试集准确率，并生成损失曲线和预测结果的可视化图像，用于分析模型性能和分类效果。

```python
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import matplotlib

# 配置Matplotlib支持中文显示
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'Arial', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False  # 修复负号显示问题

# 定义简化的VGG-11模型（适配CIFAR-10）
class VGG(nn.Module):
    def __init__(self, num_classes=10):
        super(VGG, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),  # 32x32 -> 16x16
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),  # 16x16 -> 8x8
            nn.Conv2d(128, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),  # 8x8 -> 4x4
            nn.Conv2d(256, 512, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),  # 4x4 -> 2x2
        )
        self.classifier = nn.Sequential(
            nn.Linear(512 * 2 * 2, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(),
            nn.Linear(4096, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(),
            nn.Linear(4096, num_classes),
        )

    def forward(self, x):
        x = self.features(x)
        x = x.view(-1, 512 * 2 * 2)
        x = self.classifier(x)
        return x

# 数据预处理
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

# 加载CIFAR-10数据集
trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)
testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)

# 初始化模型、损失函数和优化器
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = VGG(num_classes=10).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

# 存储训练指标
train_losses = []

# 训练函数
def train_model(epochs=50):
    model.train()
    for epoch in range(epochs):
        running_loss = 0.0
        for i, data in enumerate(trainloader, 0):
            inputs, labels = data[0].to(device), data[1].to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
            if i % 200 == 199:
                avg_loss = running_loss / 200
                print(f'[Epoch {epoch + 1}, Batch {i + 1}] Loss: {avg_loss:.3f}')
                train_losses.append(avg_loss)
                running_loss = 0.0
    print('训练完成！')

# 测试函数
def test_model():
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for data in testloader:
            images, labels = data[0].to(device), data[1].to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    accuracy = 100 * correct / total
    print(f'测试集准确率: {accuracy:.2f}%')
    return accuracy

# 可视化验证结果
def visualize_predictions():
    model.eval()
    images, labels = next(iter(testloader))  # 获取一批测试数据
    images, labels = images[:8].to(device), labels[:8].to(device)  # 取8个样本
    with torch.no_grad():
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)
    
    # 反归一化图像以便显示
    images = images.cpu() * 0.5 + 0.5  # 还原到[0,1]
    classes = ('飞机', '汽车', '鸟', '猫', '鹿', '狗', '青蛙', '马', '船', '卡车')
    fig, axes = plt.subplots(1, 8, figsize=(12, 2))
    for i in range(8):
        axes[i].imshow(images[i].permute(1, 2, 0))
        axes[i].set_title(f'预测: {classes[predicted[i]]}\n真实: {classes[labels[i]]}')
        axes[i].axis('off')
    plt.tight_layout()
    plt.savefig('vgg_predictions.png', dpi=300, bbox_inches='tight')
    print('预测结果已保存为: vgg_predictions.png')
    plt.close()

# 绘制训练损失曲线
def plot_training_curve():
    plt.figure(figsize=(10, 5))
    plt.plot(train_losses, label='训练损失')
    plt.xlabel('训练批次 (每200批)')
    plt.ylabel('损失')
    plt.title('简化版VGG训练损失曲线')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig('vgg_training_curve.png', dpi=300, bbox_inches='tight')
    print('训练损失曲线已保存为: vgg_training_curve.png')
    plt.close()

# 执行训练、测试和可视化
if __name__ == "__main__":
    train_model(epochs=50)
    test_model()
    plot_training_curve()
    visualize_predictions()
```
## 训练结果
[Epoch 49, Batch 600] Loss: 0.168  
[Epoch 50, Batch 200] Loss: 0.131  
[Epoch 50, Batch 400] Loss: 0.142  
[Epoch 50, Batch 600] Loss: 0.143  
训练完成！ 
测试集准确率: 77.41%  
训练损失曲线已保存为: vgg_training_curve.png  
预测结果已保存为: vgg_predictions.png  

<img width="1248" height="612" alt="image" src="https://github.com/user-attachments/assets/6692f924-d6cc-4a2c-831b-7d175493e080" />
图2 损失曲线  

<img width="1265" height="236" alt="image" src="https://github.com/user-attachments/assets/087d6d04-676d-49c0-b067-bc16b0b8778c" />

图3 预测结果  
