## è‘—åç½‘ç»œæ¶æ„ï¼šAlexNet (2012)
æå‡ºè€…ï¼šAlex Krizhevsky ç­‰  
<div align="center">
<img width="206" height="245" alt="image" src="https://github.com/user-attachments/assets/062a3e51-cb54-4711-adaa-f68671fca005" />    
</div>

AlexNet æ˜¯ä¸€ç§å…·æœ‰é‡Œç¨‹ç¢‘æ„ä¹‰çš„å·ç§¯ç¥ç»ç½‘ç»œï¼ˆConvolutional Neural Network, CNNï¼‰æ¶æ„ï¼Œç”± Alex Krizhevskyã€Ilya Sutskever å’Œ Geoffrey Hinton åœ¨ 2012 å¹´æå‡ºï¼Œå‘è¡¨åœ¨è®ºæ–‡ã€ŠImageNet Classification with Deep Convolutional Neural Networksã€‹ä¸­ï¼ˆNeurIPS 2012ï¼‰ã€‚AlexNet åœ¨ 2012 å¹´çš„ ImageNet å¤§è§„æ¨¡è§†è§‰è¯†åˆ«æŒ‘æˆ˜èµ›ï¼ˆILSVRCï¼‰ä¸­å¤ºå† ï¼Œä»¥æ˜¾è‘—ä¼˜åŠ¿è¶…è¶Šä¼ ç»Ÿæœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œæ ‡å¿—ç€æ·±åº¦å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„çªç ´ã€‚AlexNet å¥ å®šäº†ç°ä»£ CNN çš„åŸºç¡€ï¼Œå½±å“äº†åç»­æ¨¡å‹å¦‚ VGGã€ResNet å’Œ YOLO ç­‰ã€‚ 
   
ç‰¹ç‚¹ï¼šå¼•å…¥ReLUæ¿€æ´»å‡½æ•°ã€Dropoutæ­£åˆ™åŒ–ã€æ•°æ®å¢å¼ºå’ŒGPUåŠ é€Ÿï¼Œåœ¨ImageNetç«èµ›ä¸­å¤§å¹…æå‡æ€§èƒ½ã€‚  
åº”ç”¨ï¼šå›¾åƒåˆ†ç±»ã€ç‰¹å¾æå–ã€è¿ç§»å­¦ä¹ åŸºç¡€ã€‚  
æŒæ¡è¦ç‚¹ï¼šæ·±å±‚CNNè®¾è®¡ã€è¿‡æ‹Ÿåˆæ§åˆ¶ã€‚  
<div align="center">
<img width="700" height="380" alt="image" src="https://github.com/user-attachments/assets/5bd0deb5-051a-43ba-95f7-931fcd671b32" />  
</div>

<div align="center">
å›¾1 AlexNet æ¶æ„å›¾ ï¼ˆç°ä»£çš„æ¶æ„ï¼Œç°åœ¨GPUå†…å­˜å¾ˆå¤§äº†ï¼Œæ— éœ€åˆ†æ”¯ã€‚ï¼‰
</div>

<div align="center">
<img width="700" height="400" alt="image" src="https://github.com/user-attachments/assets/e27296cb-2aee-4389-a119-7c2ac8120d4d" />  
</div>

<div align="center">
å›¾2 åŒå›¾1
</div>

<div align="center">
<img width="700" height="250" alt="image" src="https://github.com/user-attachments/assets/7b145c0e-205a-4c61-ad7f-b477203e8db6" /> 
</div>


<div align="center">
å›¾3 æœ€å…ˆçš„åŒGPUè®¡ç®—æ¶æ„ã€‚ 
</div>

<div align="center">
(ä»¥ä¸Šä¸‰ä¸ªå›¾å‡å¼•è‡ªInternetã€‚)
</div>

åœ¨AlexNetçš„åŸå§‹è®¾è®¡ä¸­ï¼Œç¬¬äºŒå±‚å·ç§¯ï¼ˆCONV2ï¼‰åˆ°ç¬¬ä¸‰å±‚å·ç§¯ï¼ˆCONV3ï¼‰çš„â€œäº¤å‰â€æŒ‡çš„æ˜¯è·¨GPUè¿æ¥ï¼Œå³CONV3çš„å†…æ ¸ä¼šä»å‰ä¸€å±‚ï¼ˆCONV2ï¼‰çš„æ‰€æœ‰å†…æ ¸åœ°å›¾ï¼ˆkernel mapsï¼ŒåŒ…æ‹¬ä¸¤ä¸ªGPUä¸Šçš„ï¼‰è·å–è¾“å…¥ã€‚è¿™ç§è®¾è®¡æ˜¯ä¸ºäº†åœ¨å¤šGPUå¹¶è¡Œè®­ç»ƒæ—¶ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæ•è·æ›´å…¨é¢çš„ç‰¹å¾ä¿¡æ¯ï¼ŒåŒæ—¶æ§åˆ¶è®¡ç®—å¼€é”€ã€‚åŸè®ºæ–‡ä¸­æŒ‡å‡ºï¼Œè¿™ç§è¿æ¥æ¨¡å¼æ˜¯é€šè¿‡äº¤å‰éªŒè¯ï¼ˆcross-validationï¼‰å®éªŒé€‰æ‹©çš„ï¼Œä»¥å¹³è¡¡GPUé—´çš„é€šä¿¡é‡å’Œæ•´ä½“æ€§èƒ½â€”â€”å¦‚æœæ‰€æœ‰å±‚éƒ½äº¤å‰ï¼Œé€šä¿¡å¼€é”€ä¼šè¿‡é«˜ï¼Œæˆä¸ºè®­ç»ƒç“¶é¢ˆï¼›å¦‚æœå®Œå…¨æ— äº¤å‰ï¼Œåˆ™æ¨¡å‹å‡†ç¡®ç‡ä¼šä¸‹é™ï¼ˆå®éªŒæ˜¾ç¤ºï¼Œç›¸æ¯”å•GPUä¸€åŠå†…æ ¸çš„ç‰ˆæœ¬ï¼Œè¿™ç§è®¾è®¡é™ä½äº†top-1é”™è¯¯ç‡1.7%å’Œtop-5é”™è¯¯ç‡1.2%ï¼‰ã€‚ 

### ğŸ“– ä»£ç 
è¯¥ä»£ç å®ç°äº†ä¸€ä¸ª**ç®€åŒ–çš„AlexNetå·ç§¯ç¥ç»ç½‘ç»œ**ï¼Œç”¨äºåœ¨**CIFAR-10æ•°æ®é›†**ä¸Šè¿›è¡Œå›¾åƒåˆ†ç±»ä»»åŠ¡ã€‚ä¸»è¦åŠŸèƒ½å¦‚ä¸‹ï¼š

1. **æ¨¡å‹å®šä¹‰**ï¼šå®ç°äº†ä¸€ä¸ªé€‚é…CIFAR-10çš„AlexNetæ¨¡å‹ï¼ŒåŒ…å«5å±‚å·ç§¯ï¼ˆ`features`ï¼‰å’Œ3å±‚å…¨è¿æ¥å±‚ï¼ˆ`classifier`ï¼‰ï¼Œä½¿ç”¨ReLUæ¿€æ´»ã€æœ€å¤§æ± åŒ–å’ŒDropoutæ­£åˆ™åŒ–ï¼Œè¾“å‡º10ç±»åˆ†ç±»ç»“æœã€‚

2. **æ•°æ®é¢„å¤„ç†**ï¼šåŠ è½½CIFAR-10æ•°æ®é›†ï¼ˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼‰ï¼Œåº”ç”¨å˜æ¢ï¼ˆè°ƒæ•´å¤§å°åˆ°32x32ã€å½’ä¸€åŒ–ï¼‰ï¼Œå¹¶ä½¿ç”¨DataLoaderè¿›è¡Œæ‰¹å¤„ç†ï¼ˆbatch_size=64ï¼‰ã€‚

3. **è®­ç»ƒè¿‡ç¨‹**ï¼šä½¿ç”¨SGDä¼˜åŒ–å™¨ï¼ˆå­¦ä¹ ç‡0.001ï¼ŒåŠ¨é‡0.9ï¼‰å’Œäº¤å‰ç†µæŸå¤±å‡½æ•°ï¼Œè®­ç»ƒæ¨¡å‹30ä¸ªepochã€‚æ¯200ä¸ªæ‰¹æ¬¡è®°å½•å¹³å‡æŸå¤±å’Œå‡†ç¡®ç‡ï¼Œå¹¶æ‰“å°æŸå¤±ã€‚

4. **æµ‹è¯•è¿‡ç¨‹**ï¼šåœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹ï¼Œè®¡ç®—å¹¶è¾“å‡ºåˆ†ç±»å‡†ç¡®ç‡ã€‚

5. **å¯è§†åŒ–**ï¼šç»˜åˆ¶è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŸå¤±æ›²çº¿ï¼Œä¿å­˜ä¸º`alexnet_training_curve.png`ï¼Œæ”¯æŒä¸­æ–‡æ˜¾ç¤ºï¼ˆä½¿ç”¨SimHeiå­—ä½“ï¼‰ã€‚

ä»£ç è¿è¡Œåœ¨CPUæˆ–GPUä¸Šï¼Œè®­ç»ƒå®Œæˆåè¾“å‡ºæµ‹è¯•é›†å‡†ç¡®ç‡å¹¶ç”ŸæˆæŸå¤±æ›²çº¿å›¾ï¼Œç”¨äºåˆ†ææ¨¡å‹è®­ç»ƒæ•ˆæœã€‚
```python
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import matplotlib

# é…ç½® Matplotlib ä½¿ç”¨æ”¯æŒä¸­æ–‡çš„å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'Arial', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False  # ä¿®å¤è´Ÿå·æ˜¾ç¤ºé—®é¢˜

# å®šä¹‰ AlexNetï¼ˆé€‚é… CIFAR-10ï¼‰
class AlexNet(nn.Module):
    def __init__(self, num_classes=10):
        super(AlexNet, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=5, stride=1, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
            nn.Conv2d(64, 192, kernel_size=5, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
            nn.Conv2d(192, 384, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(384, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
        )
        self.classifier = nn.Sequential(
            nn.Dropout(),
            nn.Linear(256 * 3 * 3, 4096),  # é€‚é… 3x3x256=2304
            nn.ReLU(inplace=True),
            nn.Dropout(),
            nn.Linear(4096, 4096),
            nn.ReLU(inplace=True),
            nn.Linear(4096, num_classes),
        )

    def forward(self, x):
        x = self.features(x)
        x = torch.flatten(x, 1)
        x = self.classifier(x)
        return x

# æ•°æ®é¢„å¤„ç†
transform = transforms.Compose([
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

# åŠ è½½ CIFAR-10 æ•°æ®é›†
trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)
testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)

# åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = AlexNet(num_classes=10).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

# å­˜å‚¨è®­ç»ƒæŒ‡æ ‡
train_losses = []
train_accuracies = []

# è®­ç»ƒå‡½æ•°
def train_model(epochs=30):
    model.train()
    for epoch in range(epochs):
        running_loss = 0.0
        correct = 0
        total = 0
        for i, data in enumerate(trainloader, 0):
            inputs, labels = data[0].to(device), data[1].to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            if i % 200 == 199:
                avg_loss = running_loss / 200
                print(f'[Epoch {epoch + 1}, Batch {i + 1}] Loss: {avg_loss:.3f}')
                train_losses.append(avg_loss)
                train_accuracies.append(100 * correct / total)
                running_loss = 0.0
                correct = 0
                total = 0
    print('è®­ç»ƒå®Œæˆï¼')

# æµ‹è¯•å‡½æ•°
def test_model():
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for data in testloader:
            images, labels = data[0].to(device), data[1].to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    accuracy = 100 * correct / total
    print(f'æµ‹è¯•é›†å‡†ç¡®ç‡: {accuracy:.2f}%')
    return accuracy

# ç»˜åˆ¶è®­ç»ƒæŸå¤±æ›²çº¿
def plot_training_curve():
    plt.figure(figsize=(10, 5))
    plt.plot(train_losses, label='è®­ç»ƒæŸå¤±')
    plt.xlabel('è®­ç»ƒæ‰¹æ¬¡ (æ¯200æ‰¹)')
    plt.ylabel('æŸå¤±')
    plt.title('ç®€åŒ–ç‰ˆAlexNetè®­ç»ƒæŸå¤±æ›²çº¿')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig('alexnet_training_curve.png', dpi=300, bbox_inches='tight')
    print('è®­ç»ƒæŸå¤±æ›²çº¿å·²ä¿å­˜ä¸º: alexnet_training_curve.png')
    plt.close()

# æ‰§è¡Œè®­ç»ƒã€æµ‹è¯•å’Œç»˜å›¾
if __name__ == "__main__":
    train_model(epochs=30)
    test_model()
    plot_training_curve()
```
### ğŸ“– è®­ç»ƒç»“æœ
[Epoch 29, Batch 600] Loss: 0.421  
[Epoch 30, Batch 200] Loss: 0.378  
[Epoch 30, Batch 400] Loss: 0.396  
[Epoch 30, Batch 600] Loss: 0.409  
è®­ç»ƒå®Œæˆï¼  
æµ‹è¯•é›†å‡†ç¡®ç‡: 77.61%  
è®­ç»ƒæŸå¤±æ›²çº¿å·²ä¿å­˜ä¸º: alexnet_training_curve.png   
<img width="1239" height="609" alt="image" src="https://github.com/user-attachments/assets/f102aae9-d87d-4f43-bbb1-b3fac9d373b7" />
