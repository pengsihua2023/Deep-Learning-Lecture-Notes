## U-Net (2015) 
- 提出者：Olaf Ronneberger 等
<div align="center"> 
  <img width="194" height="260" alt="image" src="https://github.com/user-attachments/assets/220a9ffe-af0d-49a4-8eeb-6b1a2d67ba04" />
</div>

U-Net 是一种由 Olaf Ronneberger、Philipp Fischer 和 Thomas Brox 在 2015 年提出的卷积神经网络（Convolutional Neural Network, CNN）架构，专门为医学图像分割任务设计。它在论文《U-Net: Convolutional Networks for Biomedical Image Segmentation》中首次亮相（MICCAI 2015）。U-Net 以其对称的 U 形结构和高效的分割性能在医学图像分割领域广受欢迎，尤其适用于小数据集场景。U-Net 的设计理念和跳跃连接（Skip Connections）使其在精确分割和特征保留方面表现出色，广泛应用于生物医学影像（如 CT、MRI）以及其他分割任务。  
   
- 特点：对称编码-解码结构，跳跃连接保留细节信息，专为图像分割设计。  
- 应用：医学图像分割、语义分割。  
- 掌握要点：编码-解码架构、特征融合。
<div align="center">
<img width="500" height="250" alt="image" src="https://github.com/user-attachments/assets/00b53895-4271-48df-abc5-f39e671ec419" />
</div>

<div align="center">
(此图引自Internet。)
</div>

## 代码
代码实现了一个简化但有效的U-Net图像分割模型，专门用于CIFAR-10数据集的语义分割任务。  
### 核心功能
- 模型架构 (SimpleEffectiveUNet)
  - U-Net结构：经典的编码器-解码器架构，带跳跃连接  
  - 简化设计：32-512通道（比标准U-Net更小）  
  - 4层深度：编码器4层 + 瓶颈层 + 解码器4层  
  - 输出：单通道分割掩码（0-1概率值）  
- 数据处理 (SimpleCIFAR10Dataset)  
  - 数据源：CIFAR-10数据集（10类物体图像）  
  - 掩码生成：根据类别标签生成固定形状的分割掩码  
飞机、猫、马 → 椭圆形  
汽车、鹿、青蛙、船、卡车 → 矩形  
鸟、狗 → 圆形  
  - 数据增强：标准化处理  
- 损失函数
  - 组合损失：BCE + Dice Loss (权重各50%)  
  - 目标：平衡像素级精度和区域级重叠度  
- 训练策略
  - 优化器：Adam (学习率0.001)  
  - 调度器：StepLR (每15个epoch减半)  
  - 数据量：10000训练样本，2000测试样本  
  - 批次大小：16
  - 早停机制：8个epoch无改善则停止  
- 可视化功能
  - 训练过程：每5个epoch显示预测结果  
  - 最终测试：12个样本的综合预测展示  
  - 训练曲线：损失和Dice分数变化图  

```python
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
import torchvision
import torchvision.transforms as transforms
from torchvision import datasets

class SimpleEffectiveUNet(nn.Module):
    """简化但有效的U-Net模型"""
    def __init__(self, in_channels=3, out_channels=1):
        super(SimpleEffectiveUNet, self).__init__()
        
        # 编码器
        self.enc1 = self.conv_block(in_channels, 32)
        self.enc2 = self.conv_block(32, 64)
        self.enc3 = self.conv_block(64, 128)
        self.enc4 = self.conv_block(128, 256)
        
        # 瓶颈层
        self.bottleneck = self.conv_block(256, 512)
        
        # 解码器
        self.up4 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)
        self.dec4 = self.conv_block(512, 256)
        
        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)
        self.dec3 = self.conv_block(256, 128)
        
        self.up2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        self.dec2 = self.conv_block(128, 64)
        
        self.up1 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)
        self.dec1 = self.conv_block(64, 32)
        
        # 输出层
        self.final = nn.Conv2d(32, out_channels, kernel_size=1)
        
    def conv_block(self, in_channels, out_channels):
        """简单的卷积块"""
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x):
        # 编码器路径
        enc1 = self.enc1(x)
        enc2 = self.enc2(F.max_pool2d(enc1, 2))
        enc3 = self.enc3(F.max_pool2d(enc2, 2))
        enc4 = self.enc4(F.max_pool2d(enc3, 2))
        
        # 瓶颈层
        bottleneck = self.bottleneck(F.max_pool2d(enc4, 2))
        
        # 解码器路径
        dec4 = self.up4(bottleneck)
        dec4 = torch.cat([dec4, enc4], dim=1)
        dec4 = self.dec4(dec4)
        
        dec3 = self.up3(dec4)
        dec3 = torch.cat([dec3, enc3], dim=1)
        dec3 = self.dec3(dec3)
        
        dec2 = self.up2(dec3)
        dec2 = torch.cat([dec2, enc2], dim=1)
        dec2 = self.dec2(dec2)
        
        dec1 = self.up1(dec2)
        dec1 = torch.cat([dec1, enc1], dim=1)
        dec1 = self.dec1(dec1)
        
        # 输出
        output = self.final(dec1)
        return torch.sigmoid(output)

class SimpleCIFAR10Dataset(Dataset):
    """简化的CIFAR-10分割数据集"""
    def __init__(self, root='./data', train=True, transform=None, max_samples=None):
        self.cifar10 = datasets.CIFAR10(root=root, train=train, download=True, transform=None)
        self.transform = transform
        self.max_samples = max_samples
        
    def __len__(self):
        if self.max_samples:
            return min(self.max_samples, len(self.cifar10))
        return len(self.cifar10)
    
    def __getitem__(self, idx):
        img, label = self.cifar10[idx]
        
        # 将PIL图像转换为numpy数组
        img_np = np.array(img)
        
        # 生成简单的分割掩码
        mask = self.generate_simple_mask(label)
        
        # 转换为PyTorch张量
        img_tensor = torch.from_numpy(img_np.transpose(2, 0, 1)).float() / 255.0
        mask_tensor = torch.from_numpy(mask).float().unsqueeze(0)
        
        # 应用transform（如果有）
        if self.transform:
            img_tensor = self.transform(img_tensor)
        
        return img_tensor, mask_tensor
    
    def generate_simple_mask(self, label):
        """生成简单的分割掩码 - 基于标签类别"""
        mask = np.zeros((32, 32), dtype=np.float32)
        
        # 根据CIFAR-10标签生成不同形状的掩码
        if label == 0:  # 飞机 - 椭圆形
            y, x = np.ogrid[:32, :32]
            mask = ((x - 16)**2 / 8**2 + (y - 16)**2 / 6**2) <= 1
        elif label == 1:  # 汽车 - 矩形
            mask[12:20, 8:24] = 1.0
        elif label == 2:  # 鸟 - 圆形
            y, x = np.ogrid[:32, :32]
            mask = ((x - 16)**2 + (y - 16)**2) <= 7**2
        elif label == 3:  # 猫 - 椭圆形
            y, x = np.ogrid[:32, :32]
            mask = ((x - 16)**2 / 7**2 + (y - 16)**2 / 8**2) <= 1
        elif label == 4:  # 鹿 - 矩形
            mask[10:22, 10:22] = 1.0
        elif label == 5:  # 狗 - 圆形
            y, x = np.ogrid[:32, :32]
            mask = ((x - 16)**2 + (y - 16)**2) <= 8**2
        elif label == 6:  # 青蛙 - 矩形
            mask[11:21, 9:23] = 1.0
        elif label == 7:  # 马 - 椭圆形
            y, x = np.ogrid[:32, :32]
            mask = ((x - 16)**2 / 9**2 + (y - 16)**2 / 7**2) <= 1
        elif label == 8:  # 船 - 矩形
            mask[10:22, 8:24] = 1.0
        elif label == 9:  # 卡车 - 矩形
            mask[12:20, 10:22] = 1.0
        
        return mask.astype(np.float32)

def simple_bce_loss(pred, target):
    """简单的二元交叉熵损失"""
    return F.binary_cross_entropy(pred, target)

def dice_loss_simple(pred, target, smooth=1e-6):
    """简化的Dice损失"""
    pred_flat = pred.view(-1)
    target_flat = target.view(-1)
    
    intersection = (pred_flat * target_flat).sum()
    dice = (2. * intersection + smooth) / (pred_flat.sum() + target_flat.sum() + smooth)
    
    return 1 - dice

def combined_loss_simple(pred, target, alpha=0.5):
    """简化的组合损失：BCE + Dice"""
    bce = simple_bce_loss(pred, target)
    dice = dice_loss_simple(pred, target)
    
    return alpha * bce + (1 - alpha) * dice

def dice_score_simple(pred, target, smooth=1e-6):
    """计算Dice系数"""
    pred_flat = pred.view(-1)
    target_flat = target.view(-1)
    
    intersection = (pred_flat * target_flat).sum()
    dice = (2. * intersection + smooth) / (pred_flat.sum() + target_flat.sum() + smooth)
    
    return dice.item()

def train_simple_unet():
    """训练简化的U-Net模型"""
    # 设置设备
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"使用设备: {device}")
    
    # 数据变换
    transform = transforms.Compose([
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])
    
    # 创建数据集 - 使用更多训练数据
    train_dataset = SimpleCIFAR10Dataset(root='./data', train=True, transform=transform, max_samples=10000)
    test_dataset = SimpleCIFAR10Dataset(root='./data', train=False, transform=transform, max_samples=2000)
    
    # 创建数据加载器
    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)
    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0)
    
    print(f"训练样本数: {len(train_dataset)}")
    print(f"测试样本数: {len(test_dataset)}")
    
    # 创建模型
    model = SimpleEffectiveUNet(in_channels=3, out_channels=1)
    model = model.to(device)
    
    print(f"模型参数数量: {sum(p.numel() for p in model.parameters()):,}")
    
    # 损失函数和优化器 - 使用更简单的设置
    criterion = combined_loss_simple
    optimizer = optim.Adam(model.parameters(), lr=0.001)  # 更高的学习率
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.5)  # 简单的步进调度
    
    # 训练循环
    print("开始训练...")
    num_epochs = 30
    train_losses = []
    test_dice_scores = []
    best_dice = 0
    patience = 8
    patience_counter = 0
    
    for epoch in range(num_epochs):
        # 训练阶段
        model.train()
        total_loss = 0
        
        for batch_idx, (inputs, targets) in enumerate(train_loader):
            inputs = inputs.to(device)
            targets = targets.to(device)
            
            # 前向传播
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            
            # 反向传播
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            
            if batch_idx % 100 == 0:
                print(f'Epoch: {epoch+1}/{num_epochs}, Batch: {batch_idx}/{len(train_loader)}, '
                      f'Loss: {loss.item():.4f}')
        
        avg_loss = total_loss / len(train_loader)
        train_losses.append(avg_loss)
        
        # 测试阶段
        model.eval()
        total_dice = 0
        num_batches = 0
        
        with torch.no_grad():
            for inputs, targets in test_loader:
                inputs = inputs.to(device)
                targets = targets.to(device)
                
                outputs = model(inputs)
                dice = dice_score_simple(outputs, targets)
                total_dice += dice
                num_batches += 1
        
        avg_dice = total_dice / num_batches
        test_dice_scores.append(avg_dice)
        
        # 学习率调度
        scheduler.step()
        
        # 保存最佳模型
        if avg_dice > best_dice:
            best_dice = avg_dice
            torch.save(model.state_dict(), 'best_simple_unet_model.pth')
            patience_counter = 0
        else:
            patience_counter += 1
        
        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_loss:.4f}, Test Dice: {avg_dice:.4f}')
        
        # 每5个epoch显示一些预测结果
        if (epoch + 1) % 5 == 0:
            visualize_predictions_simple(model, test_dataset, device, epoch + 1)
        
        # 早停
        if patience_counter >= patience:
            print(f"Early stopping at epoch {epoch+1}")
            break
    
    return model, train_losses, test_dice_scores

def visualize_predictions_simple(model, test_dataset, device, epoch, num_samples=8):
    """可视化简化预测结果"""
    model.eval()
    
    with torch.no_grad():
        fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))
        
        for i in range(num_samples):
            input_img, target_mask = test_dataset[i]
            input_img = input_img.unsqueeze(0).to(device)
            target_mask = target_mask.unsqueeze(0).to(device)
            
            # 预测
            pred_mask = model(input_img)
            
            # 转换为numpy数组用于显示
            input_np = input_img[0].cpu().numpy().transpose(1, 2, 0)
            # 反归一化
            input_np = (input_np * 0.5 + 0.5).clip(0, 1)
            target_np = target_mask[0, 0].cpu().numpy()
            pred_np = pred_mask[0, 0].cpu().numpy()
            
            # 显示结果
            axes[i, 0].imshow(input_np)
            axes[i, 0].set_title(f'Input Image {i+1}')
            axes[i, 0].axis('off')
            
            axes[i, 1].imshow(target_np, cmap='gray')
            axes[i, 1].set_title(f'Ground Truth {i+1}')
            axes[i, 1].axis('off')
            
            axes[i, 2].imshow(pred_np, cmap='gray')
            axes[i, 2].set_title(f'Prediction {i+1} (Epoch {epoch})')
            axes[i, 2].axis('off')
        
        plt.tight_layout()
        plt.savefig(f'unet_simple_predictions_epoch_{epoch}.png', dpi=300, bbox_inches='tight')
        plt.show()

def test_simple_model_comprehensive(model, num_samples=12):
    """综合测试简化模型"""
    print("\n综合测试简化模型...")
    model.eval()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # 加载测试数据
    transform = transforms.Compose([
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])
    test_dataset = SimpleCIFAR10Dataset(root='./data', train=False, transform=transform, max_samples=num_samples)
    
    with torch.no_grad():
        fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))
        
        for i in range(num_samples):
            input_img, target_mask = test_dataset[i]
            input_img = input_img.unsqueeze(0).to(device)
            target_mask = target_mask.unsqueeze(0).to(device)
            
            # 预测
            pred_mask = model(input_img)
            
            # 转换为numpy数组用于显示
            input_np = input_img[0].cpu().numpy().transpose(1, 2, 0)
            # 反归一化
            input_np = (input_np * 0.5 + 0.5).clip(0, 1)
            target_np = target_mask[0, 0].cpu().numpy()
            pred_np = pred_mask[0, 0].cpu().numpy()
            
            # 显示结果
            axes[i, 0].imshow(input_np)
            axes[i, 0].set_title(f'CIFAR-10 Image {i+1}')
            axes[i, 0].axis('off')
            
            axes[i, 1].imshow(target_np, cmap='gray')
            axes[i, 1].set_title(f'Ground Truth {i+1}')
            axes[i, 1].axis('off')
            
            axes[i, 2].imshow(pred_np, cmap='gray')
            axes[i, 2].set_title(f'Prediction {i+1}')
            axes[i, 2].axis('off')
        
        plt.tight_layout()
        plt.savefig('unet_simple_comprehensive_predictions.png', dpi=300, bbox_inches='tight')
        plt.show()

def plot_training_curves_simple(train_losses, test_dice_scores):
    """绘制简化训练曲线"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # 训练损失
    ax1.plot(train_losses, 'b-', linewidth=2)
    ax1.set_title('Simple U-Net Training Loss Curve', fontsize=14)
    ax1.set_xlabel('Epoch', fontsize=12)
    ax1.set_ylabel('Combined Loss (BCE + Dice)', fontsize=12)
    ax1.grid(True, alpha=0.3)
    
    # 测试Dice分数
    ax2.plot(test_dice_scores, 'r-', linewidth=2)
    ax2.set_title('Simple U-Net Test Dice Score Curve', fontsize=14)
    ax2.set_xlabel('Epoch', fontsize=12)
    ax2.set_ylabel('Dice Score', fontsize=12)
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('unet_simple_training_curves.png', dpi=300, bbox_inches='tight')
    plt.show()

def main():
    """主函数"""
    print("=== 简化有效的U-Net CIFAR-10 实现 ===")
    
    # 训练模型
    model, train_losses, test_dice_scores = train_simple_unet()
    
    # 综合测试简化模型
    test_simple_model_comprehensive(model)
    
    # 绘制训练曲线
    plot_training_curves_simple(train_losses, test_dice_scores)
    
    print("\n训练完成！")
    print("可视化结果已保存:")
    print("- unet_simple_comprehensive_predictions.png: 综合预测结果")
    print("- unet_simple_training_curves.png: 训练曲线")
    print("- unet_simple_predictions_epoch_*.png: 训练过程中的预测结果")

if __name__ == "__main__":
    main()

```
## 训练结果

Epoch: 25/30, Batch: 600/625, Loss: 0.0011  
Epoch 25/30, Train Loss: 0.0029, Test Dice: 0.9626  
Early stopping at epoch 25  

综合测试简化模型...  

训练完成！   
可视化结果已保存:  
- unet_simple_comprehensive_predictions.png: 综合预测结果  
- unet_simple_training_curves.png: 训练曲线  
- unet_simple_predictions_epoch_*.png: 训练过程中的预测结果
- 
<img width="1160" height="478" alt="image" src="https://github.com/user-attachments/assets/1a5972da-8c94-4e1d-815c-9277f41070f6" />  

<img width="1486" height="597" alt="image" src="https://github.com/user-attachments/assets/85549d73-4890-4caa-a850-42566e62fc32" />

