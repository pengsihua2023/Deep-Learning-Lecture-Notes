## å¯¹æ¯”å­¦ä¹ ï¼ˆContrastive Learningï¼‰

å¯¹æ¯”å­¦ä¹ ï¼ˆContrastive Learningï¼‰æ˜¯ä¸€ç§ **è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡æ¯”è¾ƒï¼ˆå¯¹æ¯”ï¼‰æ ·æœ¬ä¹‹é—´çš„ç›¸ä¼¼æ€§ä¸å·®å¼‚æ€§æ¥å­¦ä¹ æœ‰æ•ˆçš„æ•°æ®è¡¨ç¤ºã€‚

### åŸºæœ¬å®šä¹‰

åœ¨å¯¹æ¯”å­¦ä¹ ä¸­ï¼Œæ¨¡å‹ä¼šå°†æ•°æ®æ ·æœ¬æ˜ å°„åˆ°ä¸€ä¸ªå‘é‡ç©ºé—´ï¼Œç„¶åé€šè¿‡ä»¥ä¸‹ç›®æ ‡æ¥è®­ç»ƒï¼š

* **ç›¸ä¼¼æ ·æœ¬ï¼ˆæ­£æ ·æœ¬å¯¹ï¼‰**ï¼šåœ¨å‘é‡ç©ºé—´ä¸­åº”è¯¥å°½å¯èƒ½é è¿‘ï¼›
* **ä¸ç›¸ä¼¼æ ·æœ¬ï¼ˆè´Ÿæ ·æœ¬å¯¹ï¼‰**ï¼šåœ¨å‘é‡ç©ºé—´ä¸­åº”è¯¥å°½å¯èƒ½è¿œç¦»ã€‚

æ¢å¥è¯è¯´ï¼Œå¯¹æ¯”å­¦ä¹ çš„ç›®æ ‡æ˜¯è®©æ¨¡å‹å­¦ä¼šåŒºåˆ†â€œç›¸ä¼¼â€å’Œâ€œä¸ç›¸ä¼¼â€ï¼Œä»è€Œè·å¾—å…·æœ‰åˆ¤åˆ«æ€§çš„ç‰¹å¾è¡¨ç¤ºï¼Œè€Œä¸éœ€è¦ä¾èµ–å¤§é‡äººå·¥æ ‡æ³¨ã€‚

### æ ¸å¿ƒæ€æƒ³

* **ä¿¡æ¯åˆ©ç”¨**ï¼šé€šå¸¸åˆ©ç”¨æ•°æ®çš„å†…åœ¨ç»“æ„æˆ–æ•°æ®å¢å¼ºï¼ˆä¾‹å¦‚åŒä¸€å›¾åƒçš„ä¸åŒè§†è§’ï¼‰æ¥æ„é€ æ­£æ ·æœ¬å¯¹ã€‚
* **ç›®æ ‡å‡½æ•°**ï¼šå¸¸è§çš„æ˜¯å¯¹æ¯”æŸå¤±ï¼ˆContrastive Lossï¼‰æˆ– InfoNCE æŸå¤±ï¼Œè¿™ç±»æŸå¤±å‡½æ•°æ¨åŠ¨ç›¸ä¼¼æ ·æœ¬åµŒå…¥æ¥è¿‘ã€ä¸ç›¸ä¼¼æ ·æœ¬åµŒå…¥è¿œç¦»ã€‚
* **åº”ç”¨åœºæ™¯**ï¼šå¸¸è§äºè®¡ç®—æœºè§†è§‰ï¼ˆå¦‚ SimCLRã€MoCoï¼‰ã€è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆå¦‚ SimCSEï¼‰ã€è¯­éŸ³è¡¨ç¤ºå­¦ä¹ ç­‰é¢†åŸŸã€‚

### ä¸¾ä¾‹

ä»¥å›¾åƒä¸ºä¾‹ï¼š

* åŸå§‹å›¾ç‰‡ç»è¿‡ä¸åŒçš„æ•°æ®å¢å¼ºï¼ˆè£å‰ªã€é¢œè‰²æ‰°åŠ¨ï¼‰å¾—åˆ°ä¸¤å¼ è§†è§’ä¸åŒçš„å›¾ç‰‡ï¼Œå®ƒä»¬æ„æˆä¸€ä¸ªæ­£æ ·æœ¬å¯¹ã€‚
* è¿™ä¸¤å¼ å›¾ç‰‡å’Œå¦ä¸€å¼ æ¥è‡ªä¸åŒç±»åˆ«çš„å›¾ç‰‡æ„æˆè´Ÿæ ·æœ¬å¯¹ã€‚
* æ¨¡å‹è®­ç»ƒçš„ç›®æ ‡æ˜¯è®©æ­£æ ·æœ¬å¯¹åœ¨è¡¨ç¤ºç©ºé—´é‡Œæ¥è¿‘ï¼Œè´Ÿæ ·æœ¬å¯¹å°½é‡åˆ†å¼€ã€‚


<div align="center">  
<img width="560" height="390" alt="image" src="https://github.com/user-attachments/assets/4f14b5b3-0951-4417-b7f1-4a00f3b39683" />  
  
  (æœ¬å›¾å¼•è‡ªInternet)
</div>

### ğŸ“– å½¢å¼åŒ–å®šä¹‰

ç»™å®šä¸€ä¸ªæ ·æœ¬ \$x\$ï¼Œé€šè¿‡æ•°æ®å¢å¼ºï¼ˆå¦‚å›¾åƒæ—‹è½¬ã€è£å‰ªã€åŠ å™ªå£°ç­‰ï¼‰å¾—åˆ°ä¸¤ä¸ªè§†è§’ \$x\_i, x\_j\$ ï¼Œå®ƒä»¬è¢«è§†ä¸º**æ­£æ ·æœ¬å¯¹**ï¼›è€Œæ¥è‡ªå…¶ä»–æ ·æœ¬çš„è§†è§’ï¼ˆå¦‚ \$x\_k\$ï¼‰åˆ™æ˜¯**è´Ÿæ ·æœ¬**ã€‚

ç›®æ ‡æ˜¯å­¦ä¹ ä¸€ä¸ªç¼–ç å™¨ \$f(\cdot)\$ï¼Œå°†æ ·æœ¬æ˜ å°„åˆ°ç‰¹å¾ç©ºé—´ï¼Œä½¿å¾—ï¼š

* **æ­£æ ·æœ¬å¯¹**åœ¨ç‰¹å¾ç©ºé—´ä¸­çš„è·ç¦»å°½å¯èƒ½æ¥è¿‘ï¼š

  $\text{sim}(f(x_i), f(x_j)) \ \text{maximize}$

* **è´Ÿæ ·æœ¬å¯¹**åœ¨ç‰¹å¾ç©ºé—´ä¸­çš„è·ç¦»å°½å¯èƒ½è¿œç¦»ï¼š

  $\text{sim}(f(x_i), f(x_k)) \ \text{minimize}$

å…¶ä¸­ \$\text{sim}(\cdot,\cdot)\$ é€šå¸¸æ˜¯ **ä½™å¼¦ç›¸ä¼¼åº¦** æˆ– **å†…ç§¯**ã€‚


### å…¸å‹æ–¹æ³•

* **SimCLR**ï¼šé€šè¿‡å¤§è§„æ¨¡æ•°æ®å¢å¼ºæ„é€ æ­£è´Ÿæ ·æœ¬å¯¹ï¼Œä½¿ç”¨ InfoNCE æŸå¤±å‡½æ•°è®­ç»ƒã€‚
* **MoCo**ï¼ˆMomentum Contrastï¼‰ï¼šå¼•å…¥åŠ¨é‡æ›´æ–°æœºåˆ¶ï¼Œç»´æŒä¸€ä¸ªå¤§çš„åŠ¨æ€è´Ÿæ ·æœ¬åº“ã€‚
* **BYOL**ï¼ˆBootstrap Your Own Latentï¼‰ï¼šä¸æ˜¾å¼ä½¿ç”¨è´Ÿæ ·æœ¬ï¼Œä»…é€šè¿‡ä¸¤ä¸ªç½‘ç»œï¼ˆåœ¨çº¿ç½‘ç»œ & ç›®æ ‡ç½‘ç»œï¼‰çš„äº¤äº’æ¥å­¦ä¹ ã€‚


### æ€»ç»“

å¯¹æ¯”å­¦ä¹ çš„æœ¬è´¨æ˜¯ï¼š

* ä¸ä¾èµ–å¤§é‡äººå·¥æ ‡ç­¾ï¼Œ
* é€šè¿‡â€œç›¸ä¼¼æ ·æœ¬é è¿‘ã€éç›¸ä¼¼æ ·æœ¬åˆ†ç¦»â€æ¥å­¦ä¹ ç‰¹å¾è¡¨ç¤ºï¼Œ
* åœ¨è®¡ç®—æœºè§†è§‰ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€è¯­éŸ³ç­‰é¢†åŸŸéƒ½æœ‰å¹¿æ³›åº”ç”¨ã€‚


- é‡è¦æ€§ï¼š
å¯¹æ¯”å­¦ä¹ æ˜¯ä¸€ç§è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡è®©æ¨¡å‹å­¦ä¹ åŒºåˆ†â€œç›¸ä¼¼â€å’Œâ€œä¸ç›¸ä¼¼â€çš„æ•°æ®å¯¹ï¼Œæå–é«˜è´¨é‡çš„ç‰¹å¾è¡¨ç¤ºã€‚  
å®ƒæ˜¯ç°ä»£æ— ç›‘ç£å­¦ä¹ çš„æ ¸å¿ƒï¼Œé©±åŠ¨äº†å¦‚ SimCLRã€MoCoï¼ˆè®¡ç®—æœºè§†è§‰ï¼‰å’Œ CLIPï¼ˆå¤šæ¨¡æ€å­¦ä¹ ï¼‰çš„æˆåŠŸã€‚  
åœ¨æ ‡æ³¨æ•°æ®ç¨€ç¼ºçš„åœºæ™¯ä¸‹ï¼ˆå¦‚åŒ»ç–—å½±åƒã€ç¨€æœ‰è¯­è¨€ï¼‰ï¼Œå¯¹æ¯”å­¦ä¹ èƒ½æ˜¾è‘—å‡å°‘å¯¹æ ‡æ³¨çš„ä¾èµ–ã€‚  
- æ ¸å¿ƒæ¦‚å¿µï¼š
å¯¹æ¯”å­¦ä¹ çš„ç›®æ ‡æ˜¯è®©ç›¸ä¼¼çš„æ•°æ®å¯¹ï¼ˆæ­£æ ·æœ¬å¯¹ï¼‰åœ¨ç‰¹å¾ç©ºé—´ä¸­é å¾—æ›´è¿‘ï¼Œä¸ç›¸ä¼¼çš„æ•°æ®å¯¹ï¼ˆè´Ÿæ ·æœ¬å¯¹ï¼‰é å¾—æ›´è¿œã€‚   
ä½¿ç”¨å¯¹æ¯”æŸå¤±å‡½æ•°ï¼ˆå¦‚ InfoNCE æŸå¤±ï¼‰æ¥ä¼˜åŒ–ç‰¹å¾è¡¨ç¤ºã€‚ 
- æ¯”å–»ï¼šåƒâ€œæ‰¾æœ‹å‹æ¸¸æˆâ€ï¼Œæ¨¡å‹å­¦ä¼šæŠŠâ€œæœ‹å‹â€ï¼ˆç›¸ä¼¼å›¾ç‰‡/æ–‡æœ¬ï¼‰èšåœ¨ä¸€èµ·ï¼ŒæŠŠâ€œé™Œç”Ÿäººâ€ï¼ˆä¸ç›¸ä¼¼æ•°æ®ï¼‰åˆ†å¼€ã€‚  
- åº”ç”¨ï¼š
å›¾åƒåˆ†ç±»ï¼ˆSimCLRã€MoCoï¼‰ï¼šç”¨å°‘é‡æ ‡æ³¨æ•°æ®å®ç°é«˜ç²¾åº¦åˆ†ç±»ã€‚  
å¤šæ¨¡æ€å­¦ä¹ ï¼ˆCLIPï¼‰ï¼šå›¾æ–‡æœç´¢ã€å›¾åƒç”Ÿæˆï¼ˆå¦‚ DALLÂ·Eï¼‰ã€‚

## ğŸ“– å¯¹æ¯”å­¦ä¹ çš„æ•°å­¦æè¿°
å¯¹æ¯”å­¦ä¹ ï¼ˆContrastive Learningï¼‰çš„æ•°å­¦æè¿°é€šå¸¸ä»â€œè¡¨ç¤ºå­¦ä¹ â€çš„ç›®æ ‡å‡ºå‘ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯ï¼š**å°†è¯­ä¹‰ç›¸ä¼¼çš„æ ·æœ¬æ‹‰è¿‘ï¼Œè¯­ä¹‰ä¸ç›¸ä¼¼çš„æ ·æœ¬æ¨è¿œ**ã€‚ä¸‹é¢æˆ‘ç»™å‡ºæ¯”è¾ƒç³»ç»Ÿçš„æ•°å­¦å½¢å¼åŒ–ï¼š

## 1. è¡¨ç¤ºå‡½æ•°

å‡è®¾æˆ‘ä»¬æœ‰æ ·æœ¬é›†åˆ $\mathcal{X} = \{x_1, x_2, \dots, x_N\}$ 

æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªç¼–ç å™¨ï¼ˆä¾‹å¦‚ç¥ç»ç½‘ç»œï¼‰ $f_\theta: \mathcal{X} \to \mathbb {R}^d$ ï¼Œ 

å°†æ ·æœ¬æ˜ å°„åˆ°ç‰¹å¾ç©ºé—´ï¼š $z_i = f_\theta(x_i), \quad z_i \in \mathbb{R}^d$

é€šå¸¸ä¼šåŠ ä¸Šå½’ä¸€åŒ–çº¦æŸ $\|z_i\|_2 = 1$ï¼Œä½¿å¾—è¡¨ç¤ºè½åœ¨å•ä½çƒé¢ä¸Šã€‚

## 2. æ­£æ ·æœ¬ä¸è´Ÿæ ·æœ¬

* **æ­£æ ·æœ¬å¯¹ï¼ˆpositive pairï¼‰**ï¼šæ¥è‡ªç›¸åŒè¯­ä¹‰ç±»åˆ«ï¼Œæˆ–åŒä¸€æ ·æœ¬çš„ä¸åŒå¢å¼ºï¼ˆdata augmentationï¼‰ç‰ˆæœ¬ï¼Œä¾‹å¦‚ $(x_i, x_j^+)$ã€‚
* **è´Ÿæ ·æœ¬å¯¹ï¼ˆnegative pairï¼‰**ï¼šæ¥è‡ªä¸åŒè¯­ä¹‰ç±»åˆ«çš„æ ·æœ¬å¯¹ï¼Œä¾‹å¦‚ $(x_i, x_k^-)$ã€‚

## 3. ç›¸ä¼¼åº¦åº¦é‡

å¸¸ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ï¼š

$\text{sim}(z_i, z_j) = \frac{z_i^\top z_j}{\|z_i\|\|z_j\|}$

è‹¥å·²å½’ä¸€åŒ–ï¼Œåˆ™ç®€åŒ–ä¸º $\text{sim}(z_i, z_j) = z_i^\top z_j$ã€‚

## 4. æŸå¤±å‡½æ•°ï¼ˆä»¥ InfoNCE ä¸ºä¾‹ï¼‰

å¯¹æ¯”å­¦ä¹ çš„å¸¸ç”¨ç›®æ ‡æ˜¯ **InfoNCE æŸå¤±**ã€‚è®¾ç¬¬ $i$ ä¸ªæ ·æœ¬çš„æ­£æ ·æœ¬ä¸º $z_j^+$ï¼Œå…¶ä½™ä¸ºè´Ÿæ ·æœ¬ $\{z_k^-\}$ ï¼Œåˆ™æŸå¤±ä¸ºï¼š

<img width="258" height="71" alt="image" src="https://github.com/user-attachments/assets/c8502645-6c4c-4ae2-b370-07e2d4d0e73d" />

å…¶ä¸­ï¼š

* $\tau > 0$ æ˜¯ **æ¸©åº¦å‚æ•°ï¼ˆtemperatureï¼‰**ï¼Œè°ƒèŠ‚åˆ†å¸ƒçš„å¹³æ»‘åº¦ï¼›
* åˆ†å­é¡¹å¯¹åº” **æ­£æ ·æœ¬å¯¹**ï¼›
* åˆ†æ¯é¡¹åŒ…å«æ‰€æœ‰å€™é€‰ï¼ˆæ­£ + è´Ÿï¼‰ï¼Œé€šå¸¸æ˜¯ **softmax å½’ä¸€åŒ–**ã€‚

## 5. æ€»æŸå¤±

å¯¹ä¸€ä¸ª batch ä¸­æ‰€æœ‰æ ·æœ¬å–å¹³å‡ï¼š

$\mathcal{L} = \frac{1}{N} \sum_{i=1}^N \mathcal{L}_i$

## 6. æ€»ç»“

* å¯¹æ¯”å­¦ä¹ çš„æ ¸å¿ƒæ•°å­¦å…¬å¼æ˜¯ **å½’ä¸€åŒ–çš„ softmax å¯¹æ•°ä¼¼ç„¶ç›®æ ‡ï¼ˆInfoNCEï¼‰**ï¼›
* ä¼˜åŒ–ç›®æ ‡ï¼šæœ€å¤§åŒ–æ­£æ ·æœ¬ç›¸ä¼¼åº¦ï¼Œæœ€å°åŒ–è´Ÿæ ·æœ¬ç›¸ä¼¼åº¦ï¼›
* æ‰©å±•ï¼šæœ‰ **NT-Xent æŸå¤±**ï¼ˆSimCLRï¼‰ã€**Triplet Loss**ã€**Margin Loss** ç­‰å˜ä½“ã€‚

---

## ğŸ“– ä»£ç 

ç¼–å†™ä¸€ä¸ªåŸºäºPyTorchçš„æœ€ç®€å•Contrastive Learningç¤ºä¾‹ï¼Œä½¿ç”¨çœŸå®æ•°æ®é›†ï¼ˆMNISTæ‰‹å†™æ•°å­—æ•°æ®é›†ï¼‰ï¼Œå®ç°å¯¹æ¯”å­¦ä¹ ä»¥å­¦ä¹ å›¾åƒç‰¹å¾åµŒå…¥ã€‚æ¨¡å‹å°†ä½¿ç”¨SimCLRé£æ ¼çš„å¯¹æ¯”æŸå¤±ï¼ˆNT-Xentï¼‰ï¼Œç›®æ ‡æ˜¯ä½¿ç›¸åŒæ•°å­—çš„å›¾åƒåµŒå…¥æ›´æ¥è¿‘ï¼Œä¸åŒæ•°å­—çš„åµŒå…¥æ›´è¿œç¦»ã€‚ç»“æœå°†é€šè¿‡å¯è§†åŒ–åµŒå…¥ç©ºé—´ï¼ˆä½¿ç”¨t-SNEé™ç»´ï¼‰å’Œè¯„ä¼°k-NNåˆ†ç±»å‡†ç¡®ç‡æ¥å±•ç¤ºã€‚

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import numpy as np
from sklearn.manifold import TSNE
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

# å®šä¹‰ç®€å•å·ç§¯ç½‘ç»œ
class SimpleCNN(nn.Module):
    def __init__(self, embed_dim=128):
        super(SimpleCNN, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 16, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(16, 32, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Flatten(),
            nn.Linear(32 * 7 * 7, embed_dim),
            nn.ReLU()
        )
    
    def forward(self, x):
        return self.encoder(x)

# å¯¹æ¯”æŸå¤±ï¼ˆNT-Xentï¼‰
class NTXentLoss(nn.Module):
    def __init__(self, temperature=0.5):
        super(NTXentLoss, self).__init__()
        self.temperature = temperature
        self.criterion = nn.CrossEntropyLoss()
    
    def forward(self, z1, z2, batch_size):
        # å½’ä¸€åŒ–åµŒå…¥
        z1 = nn.functional.normalize(z1, dim=1)
        z2 = nn.functional.normalize(z2, dim=1)
        z = torch.cat([z1, z2], dim=0)
        
        # è®¡ç®—ç›¸ä¼¼æ€§çŸ©é˜µ
        sim_matrix = torch.mm(z, z.transpose(0, 1)) / self.temperature
        labels = torch.cat([torch.arange(batch_size) for _ in range(2)], dim=0)
        labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()
        labels = labels.to(z.device)
        
        # æ©ç å»é™¤è‡ªèº«ç›¸ä¼¼æ€§
        mask = torch.eye(labels.shape[0], dtype=torch.bool).to(z.device)
        sim_matrix = sim_matrix.masked_fill(mask, -9e15)
        
        # è®¡ç®—æŸå¤±
        loss = self.criterion(sim_matrix, labels.argmax(dim=1))
        return loss

# æ•°æ®å¢å¼º
def get_data_loaders():
    transform = transforms.Compose([
        transforms.RandomResizedCrop(28, scale=(0.8, 1.0)),
        transforms.RandomRotation(10),
        transforms.ToTensor()
    ])
    train_dataset = datasets.MNIST(root='./data', train=True, download=True,
                                 transform=transforms.Compose([transforms.ToTensor()]))
    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)
    
    # ç”¨äºè¯„ä¼°çš„åŸå§‹æ•°æ®ï¼ˆæ— å¢å¼ºï¼‰
    test_dataset = datasets.MNIST(root='./data', train=False, download=True,
                                transform=transforms.ToTensor())
    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)
    
    return train_loader, test_loader

# è®­ç»ƒæ¨¡å‹
def train_model(model, train_loader, epochs=10):
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    criterion = NTXentLoss(temperature=0.5)
    
    model.train()
    for epoch in range(epochs):
        total_loss = 0
        for batch_idx, (images, _) in enumerate(train_loader):
            images = images.to(device)
            # åˆ›å»ºä¸¤ç»„å¢å¼ºè§†å›¾
            aug1 = transforms.RandomResizedCrop(28, scale=(0.8, 1.0))(images)
            aug2 = transforms.RandomRotation(10)(images)
            
            optimizer.zero_grad()
            z1 = model(aug1)
            z2 = model(aug2)
            loss = criterion(z1, z2, images.size(0))
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        
        print(f'Epoch [{epoch+1}/{epochs}], Loss: {total_loss / len(train_loader):.4f}')

# è¯„ä¼°å’Œå¯è§†åŒ–
def evaluate_and_visualize(model, test_loader):
    model.eval()
    embeddings = []
    labels = []
    
    with torch.no_grad():
        for images, targets in test_loader:
            images = images.to(device)
            emb = model(images)
            embeddings.append(emb.cpu().numpy())
            labels.append(targets.numpy())
    
    embeddings = np.concatenate(embeddings, axis=0)
    labels = np.concatenate(labels, axis=0)
    
    # t-SNEé™ç»´
    tsne = TSNE(n_components=2, random_state=42)
    embeddings_2d = tsne.fit_transform(embeddings[:1000])  # å–å‰1000ä¸ªæ ·æœ¬
    
    # å¯è§†åŒ–åµŒå…¥
    plt.figure(figsize=(10, 8))
    for i in range(10):
        mask = labels[:1000] == i
        plt.scatter(embeddings_2d[mask, 0], embeddings_2d[mask, 1], label=f'Digit {i}', alpha=0.5)
    plt.legend()
    plt.title('t-SNE Visualization of MNIST Embeddings')
    plt.savefig('mnist_embeddings.png')
    plt.close()
    print("t-SNE visualization saved as 'mnist_embeddings.png'")
    
    # k-NNè¯„ä¼°
    knn = KNeighborsClassifier(n_neighbors=5)
    knn.fit(embeddings[:8000], labels[:8000])
    pred = knn.predict(embeddings[8000:])
    accuracy = accuracy_score(labels[8000:], pred)
    print(f'k-NN Classification Accuracy: {accuracy:.4f}')

def main():
    global device
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = SimpleCNN(embed_dim=128).to(device)
    train_loader, test_loader = get_data_loaders()
    train_model(model, train_loader, epochs=10)
    evaluate_and_visualize(model, test_loader)

if __name__ == "__main__":
    main()
```

### ğŸ“– ä»£ç è¯´æ˜ï¼š
1. **æ•°æ®é›†**ï¼š
   - ä½¿ç”¨MNISTæ‰‹å†™æ•°å­—æ•°æ®é›†ï¼ˆ60,000è®­ç»ƒæ ·æœ¬ï¼Œ10,000æµ‹è¯•æ ·æœ¬ï¼‰ã€‚
   - è®­ç»ƒæ—¶åº”ç”¨æ•°æ®å¢å¼ºï¼ˆéšæœºè£å‰ªå’Œæ—‹è½¬ï¼‰ï¼Œç”Ÿæˆä¸¤ç»„è§†å›¾ä»¥è¿›è¡Œå¯¹æ¯”å­¦ä¹ ã€‚
   - æµ‹è¯•æ—¶ä½¿ç”¨åŸå§‹å›¾åƒè¯„ä¼°åµŒå…¥è´¨é‡ã€‚

2. **æ¨¡å‹ç»“æ„**ï¼š
   - ç®€å•CNNç¼–ç å™¨ï¼šä¸¤å±‚å·ç§¯ï¼ˆå¸¦ReLUå’ŒMaxPoolï¼‰ï¼Œå±•å¹³åæ¥å…¨è¿æ¥å±‚ï¼Œè¾“å‡º128ç»´åµŒå…¥ã€‚
   - å¯¹æ¯”æŸå¤±ï¼ˆNT-Xentï¼‰ï¼šä½¿ç›¸åŒæ ·æœ¬çš„å¢å¼ºè§†å›¾åµŒå…¥æ¥è¿‘ï¼Œä¸åŒæ ·æœ¬çš„åµŒå…¥è¿œç¦»ï¼Œæ¸©åº¦å‚æ•°è®¾ä¸º0.5ã€‚

3. **è®­ç»ƒ**ï¼š
   - ä½¿ç”¨Adamä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡0.001ï¼Œè®­ç»ƒ10ä¸ªepochã€‚
   - æ¯æ‰¹æ¬¡å¯¹ä¸¤ç»„å¢å¼ºè§†å›¾è®¡ç®—å¯¹æ¯”æŸå¤±ï¼Œä¼˜åŒ–åµŒå…¥ç©ºé—´ã€‚

4. **è¯„ä¼°ä¸å¯è§†åŒ–**ï¼š
   - **å¯è§†åŒ–**ï¼šå¯¹æµ‹è¯•é›†å‰1000ä¸ªæ ·æœ¬çš„åµŒå…¥è¿›è¡Œt-SNEé™ç»´ï¼Œç»˜åˆ¶äºŒç»´æ•£ç‚¹å›¾ï¼ŒæŒ‰æ•°å­—ç±»åˆ«ç€è‰²ï¼Œä¿å­˜ä¸º`mnist_embeddings.png`ã€‚
   - **è¯„ä¼°**ï¼šä½¿ç”¨k-NNåˆ†ç±»å™¨ï¼ˆk=5ï¼‰åœ¨åµŒå…¥ç©ºé—´ä¸Šè¯„ä¼°åˆ†ç±»å‡†ç¡®ç‡ï¼Œè®­ç»ƒé›†ä¸ºå‰8000ä¸ªæ ·æœ¬ï¼Œæµ‹è¯•é›†ä¸ºå‰©ä½™æ ·æœ¬ã€‚
   - è¾“å‡ºk-NNåˆ†ç±»å‡†ç¡®ç‡å’Œå¯è§†åŒ–æ–‡ä»¶è·¯å¾„ã€‚

5. **ä¾èµ–**ï¼š
   - éœ€å®‰è£…`torch`ã€`torchvision`ã€`sklearn`ã€`matplotlib`ï¼ˆ`pip install torch torchvision scikit-learn matplotlib`ï¼‰ã€‚
   - MNISTæ•°æ®é›†ä¼šè‡ªåŠ¨ä¸‹è½½åˆ°`./data`ç›®å½•ã€‚

### ğŸ“– è¿è¡Œç»“æœï¼š
- è¾“å‡ºæ¯è½®è®­ç»ƒçš„å¹³å‡æŸå¤±ã€‚
- ç”Ÿæˆ`mnist_embeddings.png`ï¼Œå±•ç¤ºåµŒå…¥ç©ºé—´ä¸­ä¸åŒæ•°å­—ç±»åˆ«çš„åˆ†å¸ƒï¼ˆç†æƒ³æƒ…å†µä¸‹åŒç±»æ•°å­—èšç±»ï¼Œå¼‚ç±»åˆ†å¼€ï¼‰ã€‚
- è¾“å‡ºk-NNåˆ†ç±»å‡†ç¡®ç‡ï¼Œåæ˜ åµŒå…¥ç©ºé—´çš„è´¨é‡ã€‚
- è¿è¡Œæ—¶é—´è¾ƒé•¿ï¼ˆå› t-SNEå’Œk-NNè®¡ç®—ï¼‰ï¼Œå¯åœ¨CPUä¸Šè¿è¡Œï¼Œä½†GPUä¼šæ›´å¿«ã€‚

### ğŸ“– æ³¨æ„ï¼š
- æ•£ç‚¹å›¾ä¿å­˜åœ¨è¿è¡Œç›®å½•ä¸‹ï¼Œå¯ç”¨å›¾åƒæŸ¥çœ‹å™¨æ£€æŸ¥ï¼Œé¢œè‰²è¡¨ç¤ºä¸åŒæ•°å­—ç±»åˆ«ã€‚
- æ¨¡å‹ç®€å•ï¼Œé€‚åˆå±•ç¤ºå¯¹æ¯”å­¦ä¹ æ¦‚å¿µï¼›å®é™…åº”ç”¨å¯å¢åŠ ç½‘ç»œæ·±åº¦æˆ–è°ƒæ•´è¶…å‚æ•°ã€‚
