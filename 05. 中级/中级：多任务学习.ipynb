{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed78455b",
   "metadata": {},
   "source": [
    "## 多任务学习（Multi-Task Learning, MTL）\n",
    "<div align=\"center\">\n",
    "<img width=\"400\" height=\"250\" alt=\"image\" src=\"https://github.com/user-attachments/assets/4dd18183-6e9e-4418-ab2b-b0f9e8edb4bb\" />\n",
    "</div>\n",
    "\n",
    "# 定义  \n",
    "多任务学习（Multi-Task Learning, MTL）是一种机器学习训练范式，核心思想是：一个模型同时学习多个相关任务，而不是像传统方法那样为每个任务单独训练模型。模型共享大部分参数，每个任务有特定输出头，联合优化多个目标。  \n",
    "\n",
    "---\n",
    "\n",
    "# 多任务学习的数学描述\n",
    "\n",
    "## 1. 单任务学习的基本形式\n",
    "\n",
    "给定数据集：\n",
    "\n",
    "$$\n",
    "\\mathcal{D} = \\{(x_i, y_i)\\}_{i=1}^N,\n",
    "$$\n",
    "\n",
    "* $x_i \\in \\mathcal{X}$：第 $i$ 个样本的输入特征。  \n",
    "* $y_i \\in \\mathcal{Y}$：第 $i$ 个样本对应的监督信号（标签）。  \n",
    "* $N$：训练样本数量。  \n",
    "\n",
    "我们训练一个参数为 $\\theta$ 的模型：\n",
    "\n",
    "$$\n",
    "f_\\theta : \\mathcal{X} \\to \\mathcal{Y},\n",
    "$$\n",
    "\n",
    "目标是最小化期望损失：\n",
    "\n",
    "$$\n",
    "\\min_\\theta \\ \\mathbb{E}_{(x,y)\\sim \\mathcal{D}} \\left[ \\mathcal{L}(f_\\theta(x), y) \\right].\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 2. 多任务学习的扩展形式\n",
    "\n",
    "假设有 $T$ 个任务，每个任务 $t$ 的数据集为：\n",
    "\n",
    "$$\n",
    "\\mathcal{D}_t = \\{(x_i^t, y_i^t)\\}_{i=1}^{N_t},\n",
    "$$\n",
    "\n",
    "* $x_i^t$：任务 $t$ 的输入。  \n",
    "* $y_i^t$：任务 $t$ 的标签。  \n",
    "* $N_t$：任务 $t$ 的样本数量。  \n",
    "\n",
    "每个任务对应损失函数 $\\mathcal{L}_t$。多任务学习优化目标是：\n",
    "\n",
    "$$\n",
    "\\min_\\theta \\ \\sum_{t=1}^T \\lambda_t \\, \\mathbb{E}_{(x,y)\\sim \\mathcal{D}_t} \\Big[ \\mathcal{L}_t(f_\\theta(x), y) \\Big].\n",
    "$$\n",
    "\n",
    "* $\\lambda_t$：任务权重，控制不同任务在整体目标中的重要性。  \n",
    "\n",
    "---\n",
    "\n",
    "## 3. 参数共享的结构化表示\n",
    "\n",
    "实际中常用 **共享表示层 + 任务专用输出层**：\n",
    "\n",
    "1. **共享表示层**：\n",
    "\n",
    "$$\n",
    "h = \\phi_{\\theta_s}(x),\n",
    "$$\n",
    "\n",
    "* $\\phi_{\\theta_s}$：特征抽取器（如神经网络的前几层），参数 $\\theta_s$ 在所有任务中共享。  \n",
    "* $h$：共享的隐含表示（latent representation）。  \n",
    "\n",
    "2. **任务专用输出层**：\n",
    "\n",
    "$$\n",
    "\\hat{y}^t = f^t_{\\theta_t}(h),\n",
    "$$\n",
    "\n",
    "* $f^t_{\\theta_t}$：任务 $t$ 的预测器，参数 $\\theta_t$ 仅供任务 $t$ 使用。  \n",
    "* $\\hat{y}^t$：模型对任务 $t$ 的预测。  \n",
    "\n",
    "整体优化目标：\n",
    "\n",
    "$$\n",
    "\\min_{\\theta_s, \\{\\theta_t\\}_{t=1}^T} \\ \\sum_{t=1}^T \\lambda_t \\, \\mathbb{E}_{(x,y)\\sim \\mathcal{D}_t} \\left[ \\mathcal{L}_t(f^t_{\\theta_t}(\\phi_{\\theta_s}(x)), y) \\right].\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 4. 矩阵/正则化视角\n",
    "\n",
    "若假设任务参数矩阵为：\n",
    "\n",
    "$$\n",
    "W = [\\theta_1, \\dots, \\theta_T] \\in \\mathbb{R}^{d \\times T},\n",
    "$$\n",
    "\n",
    "则可在损失函数外加正则化约束：\n",
    "\n",
    "### (a) 低秩约束\n",
    "\n",
    "$$\n",
    "\\min_W \\ \\sum_{t=1}^T \\mathcal{L}_t(W_t) + \\lambda \\|W\\|_*\n",
    "$$\n",
    "\n",
    "* $\\|W\\|_*$：核范数，促使 $W$ 的秩较低，表示任务共享一个低维子空间。  \n",
    "\n",
    "### (b) 图正则化\n",
    "\n",
    "$$\n",
    "\\min_W \\ \\sum_{t=1}^T \\mathcal{L}_t(W_t) + \\gamma \\sum_{(i,j)\\in E} \\|W_i - W_j\\|^2\n",
    "$$\n",
    "\n",
    "* $E$：任务关系图的边集合。  \n",
    "* $\\|W_i - W_j\\|^2$：鼓励相似任务的参数接近。  \n",
    "\n",
    "---\n",
    "\n",
    "## 5. 贝叶斯视角\n",
    "\n",
    "引入任务参数的先验分布：\n",
    "\n",
    "$$\n",
    "p(\\theta_1, \\dots, \\theta_T | \\alpha) = \\prod_{t=1}^T p(\\theta_t | \\alpha)\n",
    "$$\n",
    "\n",
    "* $\\alpha$：共享的超参数，控制所有任务的先验分布。  \n",
    "\n",
    "---\n",
    "\n",
    "## 总结\n",
    "\n",
    "多任务学习的数学建模有三种主要思路：\n",
    "\n",
    "1. **加权损失函数**（任务简单相加，带权重 $\\lambda_t$）；  \n",
    "2. **参数共享**（共享层 $\\theta_s$ + 任务专用头 $\\theta_t$）；  \n",
    "3. **正则化 / 概率建模**（通过核范数、图正则化或共享先验建模任务关系）。  \n"
    "一个基于PyTorch的最简单Multi-Task Learning（MTL）示例，使用真实数据集（UCI Wine Quality数据集），实现两个任务：预测葡萄酒质量（回归任务）和预测葡萄酒是否优质（分类任务，质量≥6为优质）。结果将通过可视化（预测质量的散点图）和评估指标（回归的MSE、分类的准确率）来展示。\n"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894f49a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定义多任务学习模型\n",
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.regression_head = nn.Linear(hidden_dim, 1)\n",
    "        self.classification_head = nn.Linear(hidden_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        shared_features = self.shared(x)\n",
    "        quality_pred = self.regression_head(shared_features)\n",
    "        is_good_pred = self.classification_head(shared_features)\n",
    "        return quality_pred, is_good_pred\n",
    "\n",
    "# 数据准备\n",
    "def prepare_data():\n",
    "    data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv', sep=';')\n",
    "    X = data.drop('quality', axis=1).values\n",
    "    y_quality = data['quality'].values\n",
    "    y_class = (y_quality >= 6).astype(int)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    X_train, X_test, y_quality_train, y_quality_test, y_class_train, y_class_test = train_test_split(\n",
    "        X, y_quality, y_class, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    X_train = torch.FloatTensor(X_train)\n",
    "    X_test = torch.FloatTensor(X_test)\n",
    "    y_quality_train = torch.FloatTensor(y_quality_train).reshape(-1, 1)\n",
    "    y_quality_test = torch.FloatTensor(y_quality_test).reshape(-1, 1)\n",
    "    y_class_train = torch.FloatTensor(y_class_train).reshape(-1, 1)\n",
    "    y_class_test = torch.FloatTensor(y_class_test).reshape(-1, 1)\n",
    "    \n",
    "    return X_train, X_test, y_quality_train, y_quality_test, y_class_train, y_class_test\n",
    "\n",
    "# 训练模型\n",
    "def train_model(model, X_train, y_quality_train, y_class_train, epochs=100, lr=0.01):\n",
    "    criterion_reg = nn.MSELoss()\n",
    "    criterion_cls = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        quality_pred, is_good_pred = model(X_train)\n",
    "        loss_reg = criterion_reg(quality_pred, y_quality_train)\n",
    "        loss_cls = criterion_cls(is_good_pred, y_class_train)\n",
    "        loss = loss_reg + loss_cls\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}, '\n",
    "                  f'Regression Loss: {loss_reg.item():.4f}, Classification Loss: {loss_cls.item():.4f}')\n",
    "\n",
    "# 评估和可视化\n",
    "def evaluate_and_visualize(model, X_test, y_quality_test, y_class_test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        quality_pred, is_good_pred = model(X_test)\n",
    "        quality_pred = quality_pred.numpy()\n",
    "        is_good_pred = (torch.sigmoid(is_good_pred) > 0.5).float().numpy()\n",
    "        y_quality_test = y_quality_test.numpy()\n",
    "        y_class_test = y_class_test.numpy()\n",
    "    \n",
    "    mse = mean_squared_error(y_quality_test, quality_pred)\n",
    "    accuracy = accuracy_score(y_class_test, is_good_pred)\n",
    "    print(f'\\nTest Set Evaluation:')\n",
    "    print(f'Regression MSE: {mse:.4f}')\n",
    "    print(f'Classification Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_quality_test, quality_pred, alpha=0.5)\n",
    "    plt.plot([y_quality_test.min(), y_quality_test.max()], [y_quality_test.min(), y_quality_test.max()], 'r--')\n",
    "    plt.xlabel('True Quality')\n",
    "    plt.ylabel('Predicted Quality')\n",
    "    plt.title('Wine Quality Prediction (Regression Task)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('wine_quality_prediction.png')\n",
    "    plt.close()\n",
    "    print(\"Prediction scatter plot saved as 'wine_quality_prediction.png'\")\n",
    "\n",
    "    print(\"\\nSample Predictions (First 5):\")\n",
    "    for i in range(5):\n",
    "        print(f\"Sample {i+1}: True Quality={y_quality_test[i][0]:.2f}, Predicted Quality={quality_pred[i][0]:.2f}, \"\n",
    "              f\"True Class={y_class_test[i][0]:.0f}, Predicted Class={is_good_pred[i][0]:.0f}\")\n",
    "\n",
    "def main():\n",
    "    X_train, X_test, y_quality_train, y_quality_test, y_class_train, y_class_test = prepare_data()\n",
    "    model = MultiTaskModel(input_dim=11, hidden_dim=64)\n",
    "    train_model(model, X_train, y_quality_train, y_class_train, epochs=100)\n",
    "    evaluate_and_visualize(model, X_test, y_quality_test, y_class_test)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3886f6cb",
   "metadata": {},
   "source": [
    "### 代码说明：\n",
    "1. **数据集**：\n",
    "   - 使用UCI Wine Quality数据集（红酒，1599条样本），包含11个化学特征和质量评分（3-8分）。\n",
    "   - 任务1（回归）：预测质量分数。\n",
    "   - 任务2（分类）：预测是否优质（质量≥6）。\n",
    "   - 数据通过`pandas`从UCI网站加载，标准化后划分为训练集（80%）和测试集（20%）。\n",
    "\n",
    "2. **模型结构**：\n",
    "   - 共享层：两层全连接（ReLU激活），输入11维特征，隐层64维。\n",
    "   - 回归头：输出1维质量分数。\n",
    "   - 分类头：输出1维二分类概率（优质/非优质）。\n",
    "   - 损失函数：回归用MSELoss，分类用BCEWithLogitsLoss，联合损失为两者之和。\n",
    "\n",
    "3. **训练**：\n",
    "   - 使用Adam优化器，学习率0.01，训练100个epoch。\n",
    "   - 每20个epoch打印总损失、回归损失和分类损失。\n",
    "\n",
    "4. **评估与可视化**：\n",
    "   - 评估回归任务的均方误差（MSE）和分类任务的准确率。\n",
    "   - 绘制散点图，展示真实质量与预测质量的关系，保存为`wine_quality_prediction.png`。\n",
    "   - 打印前5个测试样本的真实和预测值（质量分数和分类结果）。\n",
    "\n",
    "5. **依赖**：\n",
    "   - 需安装`torch`、`sklearn`、`pandas`、`matplotlib`、`seaborn`（`pip install torch scikit-learn pandas matplotlib seaborn datasets`）。\n",
    "   - 数据集在线加载，无需手动下载。\n",
    "\n",
    "### 运行结果：\n",
    "- 输出训练过程中的损失值。\n",
    "- 测试集评估：\n",
    "  - 回归任务的MSE（反映预测质量分数的误差）。\n",
    "  - 分类任务的准确率（反映优质/非优质分类正确率）。\n",
    "- 生成`wine_quality_prediction.png`，展示预测质量与真实质量的散点图（红线为理想预测线）。\n",
    "- 打印前5个样本的预测结果，展示真实和预测的质量分数及分类结果。\n",
    "\n",
    "### 注意：\n",
    "- 热图保存在运行目录下，可用图像查看器检查。\n",
    "- 模型简单（两层共享网络），适合展示MTL概念；实际应用可增加层数或使用更复杂结构。\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
