# å¤šä»»åŠ¡å­¦ä¹ ï¼ˆMulti-Task Learning, MTLï¼‰

<div align="center">
<img width="400" height="250" alt="image" src="https://github.com/user-attachments/assets/4dd18183-6e9e-4418-ab2b-b0f9e8edb4bb" />
</div>
<div align="center">
ï¼ˆæ­¤å›¾å¼•è‡ªInternetï¼‰
</div>

## ğŸ“– å®šä¹‰  
å¤šä»»åŠ¡å­¦ä¹ ï¼ˆMulti-Task Learning, MTLï¼‰æ˜¯ä¸€ç§æœºå™¨å­¦ä¹ è®­ç»ƒèŒƒå¼ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯ï¼šä¸€ä¸ªæ¨¡å‹åŒæ—¶å­¦ä¹ å¤šä¸ªç›¸å…³ä»»åŠ¡ï¼Œè€Œä¸æ˜¯åƒä¼ ç»Ÿæ–¹æ³•é‚£æ ·ä¸ºæ¯ä¸ªä»»åŠ¡å•ç‹¬è®­ç»ƒæ¨¡å‹ã€‚æ¨¡å‹å…±äº«å¤§éƒ¨åˆ†å‚æ•°ï¼Œæ¯ä¸ªä»»åŠ¡æœ‰ç‰¹å®šè¾“å‡ºå¤´ï¼Œè”åˆä¼˜åŒ–å¤šä¸ªç›®æ ‡ã€‚  


## ğŸ“– å¤šä»»åŠ¡å­¦ä¹ çš„æ•°å­¦æè¿°

### 1. å•ä»»åŠ¡å­¦ä¹ çš„åŸºæœ¬å½¢å¼

ç»™å®šæ•°æ®é›†ï¼š

$$
\mathcal{D} = \{(x_i, y_i)\}_{i=1}^N,
$$

* $x_i \in \mathcal{X}$ï¼šç¬¬ $i$ ä¸ªæ ·æœ¬çš„è¾“å…¥ç‰¹å¾ã€‚  
* $y_i \in \mathcal{Y}$ï¼šç¬¬ $i$ ä¸ªæ ·æœ¬å¯¹åº”çš„ç›‘ç£ä¿¡å·ï¼ˆæ ‡ç­¾ï¼‰ã€‚  
* $N$ï¼šè®­ç»ƒæ ·æœ¬æ•°é‡ã€‚  

æˆ‘ä»¬è®­ç»ƒä¸€ä¸ªå‚æ•°ä¸º $\theta$ çš„æ¨¡å‹ï¼š

$$
f_\theta : \mathcal{X} \to \mathcal{Y},
$$

ç›®æ ‡æ˜¯æœ€å°åŒ–æœŸæœ›æŸå¤±ï¼š

$$
\min_\theta \ \mathbb{E}_{(x,y)\sim \mathcal{D}} \left[ \mathcal{L}(f_\theta(x), y) \right].
$$



### 2. å¤šä»»åŠ¡å­¦ä¹ çš„æ‰©å±•å½¢å¼

å‡è®¾æœ‰ $T$ ä¸ªä»»åŠ¡ï¼Œæ¯ä¸ªä»»åŠ¡ $t$ çš„æ•°æ®é›†ä¸ºï¼š

$$
\mathcal{D}_t = \{(x_i^t, y_i^t)\}_{i=1}^{N_t},
$$

* $x_i^t$ï¼šä»»åŠ¡ $t$ çš„è¾“å…¥ã€‚  
* $y_i^t$ï¼šä»»åŠ¡ $t$ çš„æ ‡ç­¾ã€‚  
* $N_t$ï¼šä»»åŠ¡ $t$ çš„æ ·æœ¬æ•°é‡ã€‚  

æ¯ä¸ªä»»åŠ¡å¯¹åº”æŸå¤±å‡½æ•° $\mathcal{L}_t$ã€‚å¤šä»»åŠ¡å­¦ä¹ ä¼˜åŒ–ç›®æ ‡æ˜¯ï¼š

$$
\min_\theta \ \sum_{t=1}^T \lambda_t \, \mathbb{E}_{(x,y)\sim \mathcal{D}_t} \Big[ \mathcal{L}_t(f_\theta(x), y) \Big].
$$

* $\lambda_t$ï¼šä»»åŠ¡æƒé‡ï¼Œæ§åˆ¶ä¸åŒä»»åŠ¡åœ¨æ•´ä½“ç›®æ ‡ä¸­çš„é‡è¦æ€§ã€‚  



### 3. å‚æ•°å…±äº«çš„ç»“æ„åŒ–è¡¨ç¤º

å®é™…ä¸­å¸¸ç”¨ **å…±äº«è¡¨ç¤ºå±‚ + ä»»åŠ¡ä¸“ç”¨è¾“å‡ºå±‚**ï¼š

1. **å…±äº«è¡¨ç¤ºå±‚**ï¼š

$$
h = \phi_{\theta_s}(x),
$$

* $\phi_{\theta_s}$ï¼šç‰¹å¾æŠ½å–å™¨ï¼ˆå¦‚ç¥ç»ç½‘ç»œçš„å‰å‡ å±‚ï¼‰ï¼Œå‚æ•° $\theta_s$ åœ¨æ‰€æœ‰ä»»åŠ¡ä¸­å…±äº«ã€‚  
* $h$ï¼šå…±äº«çš„éšå«è¡¨ç¤ºï¼ˆlatent representationï¼‰ã€‚  

2. **ä»»åŠ¡ä¸“ç”¨è¾“å‡ºå±‚**ï¼š

$$
\hat{y}^t = f^t_{\theta_t}(h),
$$

* $f^t_{\theta_t}$ï¼šä»»åŠ¡ $t$ çš„é¢„æµ‹å™¨ï¼Œå‚æ•° $\theta_t$ ä»…ä¾›ä»»åŠ¡ $t$ ä½¿ç”¨ã€‚  
* $\hat{y}^t$ï¼šæ¨¡å‹å¯¹ä»»åŠ¡ $t$ çš„é¢„æµ‹ã€‚  

æ•´ä½“ä¼˜åŒ–ç›®æ ‡ï¼š

$$
\min_{\theta_s, \{\theta_t\}_{t=1}^T} \ \sum_{t=1}^T \lambda_t \, \mathbb{E}_{(x,y)\sim \mathcal{D}_t} \left[ \mathcal{L}_t(f^t_{\theta_t}(\phi_{\theta_s}(x)), y) \right].
$$



### 4. çŸ©é˜µ/æ­£åˆ™åŒ–è§†è§’

è‹¥å‡è®¾ä»»åŠ¡å‚æ•°çŸ©é˜µä¸ºï¼š

$$
W = [\theta_1, \dots, \theta_T] \in \mathbb{R}^{d \times T},
$$

åˆ™å¯åœ¨æŸå¤±å‡½æ•°å¤–åŠ æ­£åˆ™åŒ–çº¦æŸï¼š

### (a) ä½ç§©çº¦æŸ

$$
\min_W \ \sum_{t=1}^T \mathcal{L}_t(W_t) + \lambda \|W\|_*
$$

* $\|W\|_*$ï¼šæ ¸èŒƒæ•°ï¼Œä¿ƒä½¿ $W$ çš„ç§©è¾ƒä½ï¼Œè¡¨ç¤ºä»»åŠ¡å…±äº«ä¸€ä¸ªä½ç»´å­ç©ºé—´ã€‚  

### (b) å›¾æ­£åˆ™åŒ–

$$
\min_W \ \sum_{t=1}^T \mathcal{L}_t(W_t) + \gamma \sum_{(i,j)\in E} \|W_i - W_j\|^2
$$

* $E$ï¼šä»»åŠ¡å…³ç³»å›¾çš„è¾¹é›†åˆã€‚  
* $\|W_i - W_j\|^2$ï¼šé¼“åŠ±ç›¸ä¼¼ä»»åŠ¡çš„å‚æ•°æ¥è¿‘ã€‚  



### 5. è´å¶æ–¯è§†è§’

å¼•å…¥ä»»åŠ¡å‚æ•°çš„å…ˆéªŒåˆ†å¸ƒï¼š

$$
p(\theta_1, \dots, \theta_T | \alpha) = \prod_{t=1}^T p(\theta_t | \alpha)
$$

* $\alpha$ï¼šå…±äº«çš„è¶…å‚æ•°ï¼Œæ§åˆ¶æ‰€æœ‰ä»»åŠ¡çš„å…ˆéªŒåˆ†å¸ƒã€‚  



### æ€»ç»“

å¤šä»»åŠ¡å­¦ä¹ çš„æ•°å­¦å»ºæ¨¡æœ‰ä¸‰ç§ä¸»è¦æ€è·¯ï¼š

1. **åŠ æƒæŸå¤±å‡½æ•°**ï¼ˆä»»åŠ¡ç®€å•ç›¸åŠ ï¼Œå¸¦æƒé‡ $\lambda_t$ï¼‰ï¼›  
2. **å‚æ•°å…±äº«**ï¼ˆå…±äº«å±‚ $\theta_s$ + ä»»åŠ¡ä¸“ç”¨å¤´ $\theta_t$ï¼‰ï¼›  
3. **æ­£åˆ™åŒ– / æ¦‚ç‡å»ºæ¨¡**ï¼ˆé€šè¿‡æ ¸èŒƒæ•°ã€å›¾æ­£åˆ™åŒ–æˆ–å…±äº«å…ˆéªŒå»ºæ¨¡ä»»åŠ¡å…³ç³»ï¼‰ã€‚  
---
## ğŸ“– Code
ä¸€ä¸ªåŸºäºPyTorchçš„æœ€ç®€å•Multi-Task Learningï¼ˆMTLï¼‰ç¤ºä¾‹ï¼Œä½¿ç”¨çœŸå®æ•°æ®é›†ï¼ˆUCI Wine Qualityæ•°æ®é›†ï¼‰ï¼Œå®ç°ä¸¤ä¸ªä»»åŠ¡ï¼šé¢„æµ‹è‘¡è„é…’è´¨é‡ï¼ˆå›å½’ä»»åŠ¡ï¼‰å’Œé¢„æµ‹è‘¡è„é…’æ˜¯å¦ä¼˜è´¨ï¼ˆåˆ†ç±»ä»»åŠ¡ï¼Œè´¨é‡â‰¥6ä¸ºä¼˜è´¨ï¼‰ã€‚ç»“æœå°†é€šè¿‡å¯è§†åŒ–ï¼ˆé¢„æµ‹è´¨é‡çš„æ•£ç‚¹å›¾ï¼‰å’Œè¯„ä¼°æŒ‡æ ‡ï¼ˆå›å½’çš„MSEã€åˆ†ç±»çš„å‡†ç¡®ç‡ï¼‰æ¥å±•ç¤ºã€‚


```python
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, accuracy_score
import pandas as pd
import matplotlib.pyplot as plt

# å®šä¹‰å¤šä»»åŠ¡å­¦ä¹ æ¨¡å‹
class MultiTaskModel(nn.Module):
    def __init__(self, input_dim, hidden_dim):
        super(MultiTaskModel, self).__init__()
        self.shared = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU()
        )
        self.regression_head = nn.Linear(hidden_dim, 1)
        self.classification_head = nn.Linear(hidden_dim, 1)
    
    def forward(self, x):
        shared_features = self.shared(x)
        quality_pred = self.regression_head(shared_features)
        is_good_pred = self.classification_head(shared_features)
        return quality_pred, is_good_pred

# æ•°æ®å‡†å¤‡
def prepare_data():
    data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv', sep=';')
    X = data.drop('quality', axis=1).values
    y_quality = data['quality'].values
    y_class = (y_quality >= 6).astype(int)
    
    scaler = StandardScaler()
    X = scaler.fit_transform(X)
    
    X_train, X_test, y_quality_train, y_quality_test, y_class_train, y_class_test = train_test_split(
        X, y_quality, y_class, test_size=0.2, random_state=42
    )
    
    X_train = torch.FloatTensor(X_train)
    X_test = torch.FloatTensor(X_test)
    y_quality_train = torch.FloatTensor(y_quality_train).reshape(-1, 1)
    y_quality_test = torch.FloatTensor(y_quality_test).reshape(-1, 1)
    y_class_train = torch.FloatTensor(y_class_train).reshape(-1, 1)
    y_class_test = torch.FloatTensor(y_class_test).reshape(-1, 1)
    
    return X_train, X_test, y_quality_train, y_quality_test, y_class_train, y_class_test

# è®­ç»ƒæ¨¡å‹
def train_model(model, X_train, y_quality_train, y_class_train, epochs=100, lr=0.01):
    criterion_reg = nn.MSELoss()
    criterion_cls = nn.BCEWithLogitsLoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)
    
    for epoch in range(epochs):
        model.train()
        optimizer.zero_grad()
        
        quality_pred, is_good_pred = model(X_train)
        loss_reg = criterion_reg(quality_pred, y_quality_train)
        loss_cls = criterion_cls(is_good_pred, y_class_train)
        loss = loss_reg + loss_cls
        loss.backward()
        optimizer.step()
        
        if (epoch + 1) % 20 == 0:
            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}, '
                  f'Regression Loss: {loss_reg.item():.4f}, Classification Loss: {loss_cls.item():.4f}')

# è¯„ä¼°å’Œå¯è§†åŒ–
def evaluate_and_visualize(model, X_test, y_quality_test, y_class_test):
    model.eval()
    with torch.no_grad():
        quality_pred, is_good_pred = model(X_test)
        quality_pred = quality_pred.numpy()
        is_good_pred = (torch.sigmoid(is_good_pred) > 0.5).float().numpy()
        y_quality_test = y_quality_test.numpy()
        y_class_test = y_class_test.numpy()
    
    mse = mean_squared_error(y_quality_test, quality_pred)
    accuracy = accuracy_score(y_class_test, is_good_pred)
    print(f'\nTest Set Evaluation:')
    print(f'Regression MSE: {mse:.4f}')
    print(f'Classification Accuracy: {accuracy:.4f}')
    
    plt.figure(figsize=(10, 6))
    plt.scatter(y_quality_test, quality_pred, alpha=0.5)
    plt.plot([y_quality_test.min(), y_quality_test.max()], [y_quality_test.min(), y_quality_test.max()], 'r--')
    plt.xlabel('True Quality')
    plt.ylabel('Predicted Quality')
    plt.title('Wine Quality Prediction (Regression Task)')
    plt.tight_layout()
    plt.savefig('wine_quality_prediction.png')
    plt.close()
    print("Prediction scatter plot saved as 'wine_quality_prediction.png'")

    print("\nSample Predictions (First 5):")
    for i in range(5):
        print(f"Sample {i+1}: True Quality={y_quality_test[i][0]:.2f}, Predicted Quality={quality_pred[i][0]:.2f}, "
              f"True Class={y_class_test[i][0]:.0f}, Predicted Class={is_good_pred[i][0]:.0f}")

def main():
    X_train, X_test, y_quality_train, y_quality_test, y_class_train, y_class_test = prepare_data()
    model = MultiTaskModel(input_dim=11, hidden_dim=64)
    train_model(model, X_train, y_quality_train, y_class_train, epochs=100)
    evaluate_and_visualize(model, X_test, y_quality_test, y_class_test)

if __name__ == "__main__":
    main()
````


## ğŸ“– ä»£ç è¯´æ˜ï¼š

1. **æ•°æ®é›†**ï¼š

   * ä½¿ç”¨ UCI Wine Quality æ•°æ®é›†ï¼ˆçº¢é…’ï¼Œ1599 æ¡æ ·æœ¬ï¼‰ï¼ŒåŒ…å« 11 ä¸ªåŒ–å­¦ç‰¹å¾å’Œè´¨é‡è¯„åˆ†ï¼ˆ3-8 åˆ†ï¼‰ã€‚
   * ä»»åŠ¡1ï¼ˆå›å½’ï¼‰ï¼šé¢„æµ‹è´¨é‡åˆ†æ•°ã€‚
   * ä»»åŠ¡2ï¼ˆåˆ†ç±»ï¼‰ï¼šé¢„æµ‹æ˜¯å¦ä¼˜è´¨ï¼ˆè´¨é‡ â‰¥ 6ï¼‰ã€‚
   * æ•°æ®é€šè¿‡ `pandas` ä» UCI ç½‘ç«™åŠ è½½ï¼Œæ ‡å‡†åŒ–ååˆ’åˆ†ä¸ºè®­ç»ƒé›†ï¼ˆ80%ï¼‰å’Œæµ‹è¯•é›†ï¼ˆ20%ï¼‰ã€‚

2. **æ¨¡å‹ç»“æ„**ï¼š

   * å…±äº«å±‚ï¼šä¸¤å±‚å…¨è¿æ¥ï¼ˆReLU æ¿€æ´»ï¼‰ï¼Œè¾“å…¥ 11 ç»´ç‰¹å¾ï¼Œéšå±‚ 64 ç»´ã€‚
   * å›å½’å¤´ï¼šè¾“å‡º 1 ç»´è´¨é‡åˆ†æ•°ã€‚
   * åˆ†ç±»å¤´ï¼šè¾“å‡º 1 ç»´äºŒåˆ†ç±»æ¦‚ç‡ï¼ˆä¼˜è´¨/éä¼˜è´¨ï¼‰ã€‚
   * æŸå¤±å‡½æ•°ï¼šå›å½’ç”¨ `MSELoss`ï¼Œåˆ†ç±»ç”¨ `BCEWithLogitsLoss`ï¼Œè”åˆæŸå¤±ä¸ºä¸¤è€…ä¹‹å’Œã€‚

3. **è®­ç»ƒ**ï¼š

   * ä½¿ç”¨ Adam ä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡ 0.01ï¼Œè®­ç»ƒ 100 ä¸ª epochã€‚
   * æ¯ 20 ä¸ª epoch æ‰“å°æ€»æŸå¤±ã€å›å½’æŸå¤±å’Œåˆ†ç±»æŸå¤±ã€‚

4. **è¯„ä¼°ä¸å¯è§†åŒ–**ï¼š

   * è¯„ä¼°å›å½’ä»»åŠ¡çš„å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰å’Œåˆ†ç±»ä»»åŠ¡çš„å‡†ç¡®ç‡ã€‚
   * ç»˜åˆ¶æ•£ç‚¹å›¾ï¼Œå±•ç¤ºçœŸå®è´¨é‡ä¸é¢„æµ‹è´¨é‡çš„å…³ç³»ï¼Œä¿å­˜ä¸º `wine_quality_prediction.png`ã€‚
   * æ‰“å°å‰ 5 ä¸ªæµ‹è¯•æ ·æœ¬çš„çœŸå®å’Œé¢„æµ‹å€¼ï¼ˆè´¨é‡åˆ†æ•°å’Œåˆ†ç±»ç»“æœï¼‰ã€‚

5. **ä¾èµ–**ï¼š

   * éœ€å®‰è£… `torch`ã€`sklearn`ã€`pandas`ã€`matplotlib`ã€`seaborn`

     ```bash
     pip install torch scikit-learn pandas matplotlib seaborn datasets
     ```
   * æ•°æ®é›†åœ¨çº¿åŠ è½½ï¼Œæ— éœ€æ‰‹åŠ¨ä¸‹è½½ã€‚


## ğŸ“– è¿è¡Œç»“æœï¼š

* è¾“å‡ºè®­ç»ƒè¿‡ç¨‹ä¸­çš„æŸå¤±å€¼ã€‚
* æµ‹è¯•é›†è¯„ä¼°ï¼š

  * å›å½’ä»»åŠ¡çš„ MSEï¼ˆåæ˜ é¢„æµ‹è´¨é‡åˆ†æ•°çš„è¯¯å·®ï¼‰ã€‚
  * åˆ†ç±»ä»»åŠ¡çš„å‡†ç¡®ç‡ï¼ˆåæ˜ ä¼˜è´¨/éä¼˜è´¨åˆ†ç±»æ­£ç¡®ç‡ï¼‰ã€‚
* ç”Ÿæˆ `wine_quality_prediction.png`ï¼Œå±•ç¤ºé¢„æµ‹è´¨é‡ä¸çœŸå®è´¨é‡çš„æ•£ç‚¹å›¾ï¼ˆçº¢çº¿ä¸ºç†æƒ³é¢„æµ‹çº¿ï¼‰ã€‚
* æ‰“å°å‰ 5 ä¸ªæ ·æœ¬çš„é¢„æµ‹ç»“æœï¼Œå±•ç¤ºçœŸå®å’Œé¢„æµ‹çš„è´¨é‡åˆ†æ•°åŠåˆ†ç±»ç»“æœã€‚


