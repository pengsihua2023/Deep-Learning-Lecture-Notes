æ˜ç™½äº† âœ…ã€‚æˆ‘æ¥ä»”ç»†æ’æŸ¥ä¸€ä¸‹ä½ è¦çš„å…¬å¼ï¼ŒæŠŠå®¹æ˜“å‡ºé”™çš„åœ°æ–¹ï¼ˆæ¯”å¦‚ `Big`ã€æ‹¬å·ã€ç©ºæ ¼ã€`concat`ã€é›†åˆç¬¦å·ï¼‰éƒ½ç»Ÿä¸€ä¿®æ­£ä¸º **LaTeX è§„èŒƒå†™æ³•**ï¼Œä¿è¯åœ¨å¸¸è§æ¸²æŸ“ç¯å¢ƒï¼ˆå¦‚ LaTeX ç¼–è¾‘å™¨ã€Markdown MathJaxã€è®ºæ–‡æ¨¡æ¿ï¼‰ä¸‹éƒ½èƒ½æ­£ç¡®æ˜¾ç¤ºã€‚

---

# å›¾ç¥ç»ç½‘ç»œçš„æ•°å­¦åŒ–å®šä¹‰ï¼ˆå®Œå…¨ä¿®æ­£ç‰ˆï¼‰

## 1. å›¾çš„åŸºæœ¬ç»“æ„

ä¸€ä¸ªå›¾å®šä¹‰ä¸ºä¸‰å…ƒç»„ï¼š


$$
G = (V, E, X)
$$


å…¶ä¸­ï¼š

* $V = \{1, 2, \dots, N\}$ ä¸ºèŠ‚ç‚¹é›†åˆï¼ŒèŠ‚ç‚¹æ•°ä¸º $N$ã€‚
* $E \subseteq V \times V$ ä¸ºè¾¹é›†åˆã€‚
* $X \in \mathbb{R}^{N \times d}$ ä¸ºèŠ‚ç‚¹ç‰¹å¾çŸ©é˜µï¼Œå…¶ä¸­ç¬¬ $i$ è¡Œ $x_i \in \mathbb{R}^d$ æ˜¯èŠ‚ç‚¹ $i$ çš„åˆå§‹ç‰¹å¾ã€‚

é‚»æ¥çŸ©é˜µè¡¨ç¤ºï¼š

```latex
\[
A \in \mathbb{R}^{N \times N}, \quad A_{ij} \neq 0 \;\Leftrightarrow\; (i,j) \in E
\]
```

---

## 2. èŠ‚ç‚¹è¡¨ç¤ºçš„è¿­ä»£æ›´æ–°

æ¶ˆæ¯ä¼ é€’ (Message Passing) çš„ä¸€èˆ¬å½¢å¼ï¼š

```latex
\[
h_i^{(k)} = \psi^{(k)}\!\left(h_i^{(k-1)},\;\phi^{(k)}\!\left(\{\,h_j^{(k-1)} \mid j \in \mathcal{N}(i)\,\}\right)\right),
\quad h_i^{(0)} = x_i
\]
```

è¯´æ˜ï¼š

* $\mathcal{N}(i)$ï¼šèŠ‚ç‚¹ $i$ çš„é‚»å±…é›†åˆï¼ˆå¯å«è‡ªèº«ï¼‰ã€‚
* $\phi^{(k)}$ï¼šèšåˆå‡½æ•° (aggregation)ã€‚
* $\psi^{(k)}$ï¼šæ›´æ–°å‡½æ•° (update)ã€‚
* èŠ‚ç‚¹æœ€ç»ˆåµŒå…¥ï¼š

```latex
\[
H^{(K)} = \{\,h_i^{(K)} \mid i \in V\,\}
\]
```

---

## 3. å›¾çº§è¡¨ç¤º

å¦‚æœä»»åŠ¡éœ€è¦å›¾çº§åµŒå…¥ï¼ˆä¾‹å¦‚å›¾åˆ†ç±»ï¼‰ï¼Œåˆ™ï¼š

```latex
\[
h_G = \rho\!\left(\{\,h_i^{(K)} \mid i \in V\,\}\right)
\]
```

å…¶ä¸­ $\rho$ æ˜¯è¯»å‡ºå‡½æ•° (readout)ï¼Œå¸¸è§å–æ³•ä¸º sumã€meanã€max pooling æˆ–æ³¨æ„åŠ›åŠ æƒã€‚

---

## 4. ç‰¹ä¾‹ï¼šå¸¸è§ GNN å®ç°

### GCN (Graph Convolutional Network)

```latex
\[
H^{(k)} = \sigma\!\left(\tilde{D}^{-\tfrac{1}{2}} \,\tilde{A}\, \tilde{D}^{-\tfrac{1}{2}} H^{(k-1)} W^{(k)}\right)
\]
```

å…¶ä¸­ $\tilde{A} = A + I$ï¼Œ$\tilde{D}$ æ˜¯ $\tilde{A}$ çš„åº¦çŸ©é˜µã€‚

---

### GraphSAGE

```latex
\[
h_i^{(k)} = \sigma\!\left(W^{(k)} \cdot 
\mathrm{concat}\!\Big(h_i^{(k-1)},\;
\phi^{(k)}\!\left(\{\,h_j^{(k-1)} \mid j \in \mathcal{N}(i)\,\}\right)\Big)\right)
\]
```

---

### GAT (Graph Attention Network)

```latex
\[
h_i^{(k)} = \sigma\!\left(\sum_{j \in \mathcal{N}(i)} 
\alpha_{ij}^{(k)} W^{(k)} h_j^{(k-1)}\right)
\]
```

å…¶ä¸­æ³¨æ„åŠ›æƒé‡ï¼š

```latex
\[
\alpha_{ij}^{(k)} =
\frac{\exp\!\Big(\mathrm{LeakyReLU}\!\big(a^\top [W^{(k)}h_i^{(k-1)} \,\Vert\, W^{(k)}h_j^{(k-1)}]\big)\Big)}
{\sum_{l \in \mathcal{N}(i)} \exp\!\Big(\mathrm{LeakyReLU}\!\big(a^\top [W^{(k)}h_i^{(k-1)} \,\Vert\, W^{(k)}h_l^{(k-1)}]\big)\Big)}
\]
```

---

## 5. æ€»ç»“

GNN çš„ä¸€èˆ¬æ•°å­¦å®šä¹‰å¯ä»¥æ¦‚æ‹¬ä¸ºï¼š

1. **è¾“å…¥**ï¼šå›¾ $G=(V,E,X)$ã€‚
2. **ä¼ æ’­è§„åˆ™**ï¼š

```latex
\[
h_i^{(k)} = \psi^{(k)}\!\left(h_i^{(k-1)},\;\phi^{(k)}\!\left(\{\,h_j^{(k-1)} \mid j \in \mathcal{N}(i)\,\}\right)\right)
\]
```

3. **è¾“å‡º**ï¼šèŠ‚ç‚¹åµŒå…¥ $H^{(K)}$ æˆ–å›¾åµŒå…¥ $h_G$ã€‚

---

âœ… å…³é”®ä¿®æ­£ï¼š

* æŠŠé›†åˆç¬¦å·å†™æˆ `\{\,h_j ... \mid ... \,\}` é¿å… MathJax æ¸²æŸ“é”™è¯¯ã€‚
* æŠŠåˆ†éš”ç¬¦ç»Ÿä¸€æ”¹æˆ `\mid`ï¼ˆé›†åˆçš„â€œä½¿å¾—â€ç¬¦å·ï¼‰ã€‚
* `concat` æ”¹æˆ `\mathrm{concat}`ï¼Œé˜²æ­¢å½“ä½œå˜é‡ã€‚
* åˆ†æ•°æŒ‡æ•°å†™æˆ `\tfrac{1}{2}`ï¼Œæ’ç‰ˆæ›´ç¾è§‚ã€‚
* æ³¨æ„åŠ›å…¬å¼é‡Œçš„æ‹¼æ¥å†™æˆ `\Vert` è€Œä¸æ˜¯ `||`ã€‚

---

è¦ä¸è¦æˆ‘å†ç»™ä½ è¾“å‡ºä¸€ä»½ **æœ€å°å¯è¿è¡Œçš„ LaTeX æ–‡æ¡£æ¨¡æ¿**ï¼ˆå¸¦ `\documentclass{article}`ï¼‰ï¼Œä½ ç›´æ¥å¤åˆ¶ç²˜è´´å°±èƒ½ç¼–è¯‘å‡º PDFï¼Ÿ




# å›¾ç¥ç»ç½‘ç»œ (GNN) æ•°å­¦å®šä¹‰å¯¹ç…§è¡¨

| ç¬¦å·                                                                                  | å®šä¹‰                                                                                                               | è¯´æ˜                                                           |
| ----------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------ |
| $G = (V,E,X)$                                                                       | å›¾ç»“æ„                                                                                                              | $V$ ä¸ºèŠ‚ç‚¹é›†åˆï¼Œ$E$ ä¸ºè¾¹é›†åˆï¼Œ$X \in \mathbb{R}^{N \times d}$ ä¸ºåˆå§‹èŠ‚ç‚¹ç‰¹å¾çŸ©é˜µ |
| $h_i^{(0)} = x_i$                                                                   | èŠ‚ç‚¹åˆå§‹è¡¨ç¤º                                                                                                           | èŠ‚ç‚¹ $i$ çš„ç‰¹å¾å‘é‡                                                 |
| $\mathcal{N}(i)$                                                                    | èŠ‚ç‚¹é‚»å±…é›†åˆ                                                                                                           | ä¸èŠ‚ç‚¹ $i$ ç›¸è¿çš„æ‰€æœ‰èŠ‚ç‚¹ï¼ˆå¯å«è‡ªèº«ï¼‰                                        |
| $\phi^{(k)}: \mathcal{P}(\mathbb{R}^{d_{k-1}}) \to \mathbb{R}^{d_{k-1}}$            | èšåˆå‡½æ•° (Aggregation)                                                                                               | ä»é‚»å±…èŠ‚ç‚¹åµŒå…¥é›†åˆä¸­æå–ä¿¡æ¯ï¼Œä¾‹å¦‚ sumã€meanã€maxã€attention                     |
| $\psi^{(k)}: \mathbb{R}^{d_{k-1}} \times \mathbb{R}^{d_{k-1}} \to \mathbb{R}^{d_k}$ | æ›´æ–°å‡½æ•° (Update)                                                                                                    | å°†èŠ‚ç‚¹è‡ªèº«è¡¨ç¤ºä¸é‚»å±…èšåˆç»“æœç»“åˆï¼Œé€šå¸¸æ˜¯ MLP                                     |
| èŠ‚ç‚¹æ›´æ–°è§„åˆ™                                                                              | $\displaystyle h_i^{(k)} = \psi^{(k)}\Big(h_i^{(k-1)}, \;\phi^{(k)}(\{h_j^{(k-1)}: j \in \mathcal{N}(i)\})\Big)$ | **æ¶ˆæ¯ä¼ é€’å…¬å¼**ï¼šç¬¬ $k$ å±‚èŠ‚ç‚¹è¡¨ç¤ºç”±è‡ªèº«å’Œé‚»å±…å…±åŒå†³å®š                             |
| $H^{(K)} = \{h_i^{(K)}\}_{i=1}^N$                                                   | èŠ‚ç‚¹æœ€ç»ˆè¡¨ç¤º                                                                                                           | ç»è¿‡ $K$ å±‚ä¼ æ’­åçš„èŠ‚ç‚¹åµŒå…¥çŸ©é˜µ                                           |
| $\rho: \mathcal{P}(\mathbb{R}^{d_K}) \to \mathbb{R}^{d_G}$                          | è¯»å‡ºå‡½æ•° (Readout)                                                                                                   | å°†æ‰€æœ‰èŠ‚ç‚¹åµŒå…¥æ˜ å°„ä¸ºå›¾çº§è¡¨ç¤ºï¼Œå¸¸ç”¨ sum/mean/max pooling æˆ–æ³¨æ„åŠ›                  |
| å›¾è¡¨ç¤º                                                                                 | $\displaystyle h_G = \rho(\{h_i^{(K)}: i \in V\})$                                                               | å¾—åˆ°æ•´ä¸ªå›¾çš„å…¨å±€è¡¨ç¤ºï¼Œç”¨äºå›¾åˆ†ç±»ç­‰ä»»åŠ¡                                          |

---

âœ¨ è¿™æ ·ï¼Œä¸€ä¸ª GNN çš„å®Œæ•´æ•°å­¦å®šä¹‰å¯ä»¥æ€»ç»“ä¸ºï¼š

1. **è¾“å…¥**ï¼šå›¾ $G=(V,E,X)$
2. **ä¼ æ’­**ï¼šæ¶ˆæ¯ä¼ é€’è¿­ä»£

   $   h_i^{(k)} = \psi^{(k)}\Big(h_i^{(k-1)}, \;\phi^{(k)}(\{h_j^{(k-1)}: j \in \mathcal{N}(i)\})\Big)   $
3. **è¾“å‡º**ï¼šèŠ‚ç‚¹åµŒå…¥ $H^{(K)}$ æˆ–å›¾åµŒå…¥ $h_G$ã€‚

---
ä½ è§‚å¯Ÿå¾—å¾ˆä»”ç»† ğŸ‘ã€‚
æˆ‘å‰é¢å†™çš„å…¬å¼é‡Œå¤šäº†ä¸€ä¸ª **åˆ†å·**ï¼Œä¸¥æ ¼æ¥è¯´ä¸åˆé€‚ã€‚

æ­£ç¡®çš„ **æ¶ˆæ¯ä¼ é€’å½¢å¼**åº”è¯¥æ˜¯ï¼š

$$
h_i^{(k)} = \psi^{(k)}\!\left( h_i^{(k-1)},  \phi^{(k)}\{\big(\{h_j^{(k-1)} : j \in \mathcal{N}(i)\}\}\big) \right)
$$

---

### è§£é‡Š

* $\phi^{(k)}(\cdot)$ â†’ èšåˆå‡½æ•° (aggregation)ï¼Œè¾“å…¥æ˜¯é‚»å±…èŠ‚ç‚¹è¡¨ç¤ºçš„é›†åˆã€‚
* $\psi^{(k)}(\cdot, \cdot)$ â†’ æ›´æ–°å‡½æ•° (update)ï¼Œè¾“å…¥æ˜¯**è‡ªå·±ä¸Šä¸€å±‚çš„è¡¨ç¤º**å’Œ**èšåˆç»“æœ**ä¸¤ä¸ªå‚æ•°ã€‚
* åˆå§‹æ¡ä»¶ï¼š

  $$
  h_i^{(0)} = x_i
  $$
* æœ€ç»ˆèŠ‚ç‚¹è¡¨ç¤ºï¼š

  $$
  H^{(K)} = \{h_i^{(K)}\}_{i=1}^N
  $$
* è‹¥ä»»åŠ¡æ˜¯å›¾åˆ†ç±»ï¼Œè¿˜éœ€è¯»å‡ºå‡½æ•°ï¼š

  $$
  \h_G = \rho\big(\{h_i^{(K)} : i \in V\}\big)
  $$

---

è¦ä¸è¦æˆ‘å¸®ä½ æŠŠ **GCN / GraphSAGE / GAT** éƒ½ç”¨è¿™ä¸ªæ›´ä¸¥è°¨çš„ $\psi,\phi$ å½¢å¼ç»Ÿä¸€æ”¹å†™ï¼Ÿ


## GNN
<div align="center">
<img width="500" height="263" alt="image" src="https://github.com/user-attachments/assets/47f67caf-be26-42b4-928e-b8db05f1afab" />  
</div>

Graph Neural Network (GNN, å›¾ç¥ç»ç½‘ç»œ)  
- é‡è¦æ€§ï¼š
GNN ä¸“é—¨å¤„ç†å›¾ç»“æ„æ•°æ®ï¼ˆå¦‚ç¤¾äº¤ç½‘ç»œã€åˆ†å­ç»“æ„ï¼‰ï¼Œåœ¨æ¨èç³»ç»Ÿã€åŒ–å­¦å»ºæ¨¡å’ŒçŸ¥è¯†å›¾è°±ä¸­åº”ç”¨å¹¿æ³›ã€‚  
å®ƒæ˜¯æ·±åº¦å­¦ä¹ å‘éæ¬§å‡ é‡Œå¾—æ•°æ®ï¼ˆå¦‚å›¾ã€ç½‘ç»œï¼‰æ‰©å±•çš„å…³é”®ï¼Œä»£è¡¨äº†ç°ä»£ AI çš„å‰æ²¿æ–¹å‘ã€‚  
- æ ¸å¿ƒæ¦‚å¿µï¼š
å›¾ç”±èŠ‚ç‚¹ï¼ˆç‚¹ï¼‰å’Œè¾¹ï¼ˆè¿æ¥ï¼‰ç»„æˆï¼ŒGNN é€šè¿‡â€œæ¶ˆæ¯ä¼ é€’â€è®©èŠ‚ç‚¹èšåˆé‚»å±…ä¿¡æ¯ï¼Œå­¦ä¹ å›¾çš„ç»“æ„å’Œç‰¹å¾ã€‚  
æ¯”å–»ï¼šåƒâ€œæœ‹å‹åœˆä¿¡æ¯ä¼ æ’­â€ï¼Œæ¯ä¸ªèŠ‚ç‚¹ï¼ˆäººï¼‰æ ¹æ®æœ‹å‹çš„ä¿¡æ¯æ›´æ–°è‡ªå·±çš„çŠ¶æ€ã€‚  
- åº”ç”¨ï¼šæ¨èç³»ç»Ÿï¼ˆå¦‚ Netflix æ¨èï¼‰ã€åˆ†å­è®¾è®¡ï¼ˆè¯ç‰©å‘ç°ï¼‰ã€äº¤é€šç½‘ç»œåˆ†æã€‚



ç¼–å†™ä¸€ä¸ªåŸºäºPyTorchå’ŒPyTorch Geometricçš„æœ€ç®€å•Graph Neural Networkï¼ˆGNNï¼‰ç¤ºä¾‹ï¼Œä½¿ç”¨çœŸå®æ•°æ®é›†ï¼ˆCoraæ•°æ®é›†ï¼Œå¸¸ç”¨çš„å›¾åˆ†ç±»åŸºå‡†æ•°æ®é›†ï¼‰ï¼Œå®ç°èŠ‚ç‚¹åˆ†ç±»ä»»åŠ¡ã€‚æ¨¡å‹ä½¿ç”¨ç®€å•çš„Graph Convolutional Networkï¼ˆGCNï¼‰ã€‚ç»“æœå°†é€šè¿‡å¯è§†åŒ–èŠ‚ç‚¹åµŒå…¥ï¼ˆt-SNEé™ç»´ï¼‰å’Œè¯„ä¼°åˆ†ç±»å‡†ç¡®ç‡æ¥å±•ç¤ºã€‚

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.datasets import Planetoid
from torch_geometric.nn import GCNConv
from torch_geometric.loader import DataLoader
import numpy as np
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score

# å®šä¹‰ç®€å•çš„GCNæ¨¡å‹
class SimpleGCN(nn.Module):
    def __init__(self, in_channels, hidden_channels, out_channels):
        super(SimpleGCN, self).__init__()
        self.conv1 = GCNConv(in_channels, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, out_channels)
    
    def forward(self, data):
        x, edge_index = data.x, data.edge_index
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.conv2(x, edge_index)
        return x

# å¯è§†åŒ–èŠ‚ç‚¹åµŒå…¥
def visualize_embeddings(embeddings, labels, num_classes, title="t-SNE Visualization of Node Embeddings"):
    tsne = TSNE(n_components=2, random_state=42)
    embeddings_2d = tsne.fit_transform(embeddings)
    
    plt.figure(figsize=(10, 8))
    for i in range(num_classes):
        mask = labels == i
        plt.scatter(embeddings_2d[mask, 0], embeddings_2d[mask, 1], label=f'Class {i}', alpha=0.5)
    plt.legend()
    plt.title(title)
    plt.savefig('cora_embeddings.png')
    plt.close()
    print("t-SNE visualization saved as 'cora_embeddings.png'")

# è®­ç»ƒå’Œè¯„ä¼°
def train_and_evaluate(model, data, epochs=200):
    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)
    criterion = nn.CrossEntropyLoss()
    
    model.train()
    for epoch in range(epochs):
        optimizer.zero_grad()
        out = model(data)
        loss = criterion(out[data.train_mask], data.y[data.train_mask])
        loss.backward()
        optimizer.step()
        
        if (epoch + 1) % 50 == 0:
            model.eval()
            with torch.no_grad():
                pred = out.argmax(dim=1)
                acc = accuracy_score(data.y[data.val_mask].cpu(), pred[data.val_mask].cpu())
            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}, Validation Accuracy: {acc:.4f}')
            model.train()
    
    # æµ‹è¯•é›†è¯„ä¼°
    model.eval()
    with torch.no_grad():
        out = model(data)
        pred = out.argmax(dim=1)
        test_acc = accuracy_score(data.y[data.test_mask].cpu(), pred[data.test_mask].cpu())
        print(f'\nTest Accuracy: {test_acc:.4f}')
        
        # è·å–åµŒå…¥ï¼ˆæœ€åä¸€å±‚è¾“å‡ºï¼‰
        embeddings = out.cpu().numpy()
        labels = data.y.cpu().numpy()
        visualize_embeddings(embeddings, labels, num_classes=data.num_classes)

def main():
    # åŠ è½½Coraæ•°æ®é›†
    dataset = Planetoid(root='./data', name='Cora')
    data = dataset[0]
    data = data.to(device)
    
    # åˆå§‹åŒ–æ¨¡å‹
    model = SimpleGCN(in_channels=dataset.num_features, hidden_channels=16, out_channels=dataset.num_classes).to(device)
    
    # è®­ç»ƒå’Œè¯„ä¼°
    train_and_evaluate(model, data)

if __name__ == "__main__":
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    main()
```

### ä»£ç è¯´æ˜ï¼š
1. **æ•°æ®é›†**ï¼š
   - ä½¿ç”¨Coraæ•°æ®é›†ï¼ˆ2708ä¸ªèŠ‚ç‚¹ï¼Œ7ä¸ªç±»åˆ«ï¼Œ1433ç»´ç‰¹å¾ï¼Œè¡¨ç¤ºå­¦æœ¯è®ºæ–‡åŠå…¶å¼•ç”¨å…³ç³»ï¼‰ã€‚
   - æ¯ä¸ªèŠ‚ç‚¹æ˜¯è®ºæ–‡ï¼Œç‰¹å¾æ˜¯è¯è¢‹è¡¨ç¤ºï¼Œè¾¹æ˜¯å¼•ç”¨å…³ç³»ï¼Œä»»åŠ¡æ˜¯é¢„æµ‹è®ºæ–‡ç±»åˆ«ã€‚
   - æ•°æ®é€šè¿‡`torch_geometric`çš„`Planetoid`åŠ è½½ï¼ŒåŒ…å«è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æ©ç ã€‚

2. **æ¨¡å‹ç»“æ„**ï¼š
   - ç®€å•GCNï¼šä¸¤å±‚GCNConvï¼ˆå›¾å·ç§¯å±‚ï¼‰ï¼Œç¬¬ä¸€å±‚å°†1433ç»´ç‰¹å¾æ˜ å°„åˆ°16ç»´ï¼Œç¬¬äºŒå±‚æ˜ å°„åˆ°7ç»´ï¼ˆç±»åˆ«æ•°ï¼‰ã€‚
   - ä½¿ç”¨ReLUæ¿€æ´»å’ŒDropoutï¼ˆp=0.5ï¼‰é˜²æ­¢è¿‡æ‹Ÿåˆã€‚

3. **è®­ç»ƒ**ï¼š
   - ä½¿ç”¨Adamä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡0.01ï¼Œæƒé‡è¡°å‡5e-4ï¼Œè®­ç»ƒ200ä¸ªepochã€‚
   - æŸå¤±å‡½æ•°ä¸ºäº¤å‰ç†µï¼Œä»…å¯¹è®­ç»ƒæ©ç çš„èŠ‚ç‚¹è®¡ç®—æŸå¤±ã€‚
   - æ¯50ä¸ªepochæ‰“å°è®­ç»ƒæŸå¤±å’ŒéªŒè¯é›†å‡†ç¡®ç‡ã€‚

4. **è¯„ä¼°ä¸å¯è§†åŒ–**ï¼š
   - **è¯„ä¼°**ï¼šåœ¨æµ‹è¯•é›†ä¸Šè®¡ç®—èŠ‚ç‚¹åˆ†ç±»å‡†ç¡®ç‡ã€‚
   - **å¯è§†åŒ–**ï¼šå¯¹æ¨¡å‹è¾“å‡ºçš„èŠ‚ç‚¹åµŒå…¥ï¼ˆæœ€åä¸€å±‚è¾“å‡ºï¼‰ä½¿ç”¨t-SNEé™ç»´åˆ°2Dï¼Œç»˜åˆ¶æ•£ç‚¹å›¾ï¼ŒæŒ‰ç±»åˆ«ç€è‰²ï¼Œä¿å­˜ä¸º`cora_embeddings.png`ã€‚
   - ç†æƒ³æƒ…å†µä¸‹ï¼ŒåŒä¸€ç±»åˆ«çš„èŠ‚ç‚¹åœ¨åµŒå…¥ç©ºé—´ä¸­åº”èšç±»ã€‚

5. **ä¾èµ–**ï¼š
   - éœ€å®‰è£…`torch`ã€`torch_geometric`ã€`sklearn`ã€`matplotlib`ï¼ˆ`pip install torch torch-geometric scikit-learn matplotlib`ï¼‰ã€‚
   - Coraæ•°æ®é›†ä¼šè‡ªåŠ¨ä¸‹è½½åˆ°`./data`ç›®å½•ã€‚

### è¿è¡Œç»“æœï¼š
- è¾“å‡ºæ¯50ä¸ªepochçš„è®­ç»ƒæŸå¤±å’ŒéªŒè¯å‡†ç¡®ç‡ã€‚
- è¾“å‡ºæµ‹è¯•é›†çš„æœ€ç»ˆåˆ†ç±»å‡†ç¡®ç‡ã€‚
- ç”Ÿæˆ`cora_embeddings.png`ï¼Œå±•ç¤ºèŠ‚ç‚¹åµŒå…¥çš„2Dåˆ†å¸ƒï¼Œé¢œè‰²è¡¨ç¤ºä¸åŒç±»åˆ«ã€‚
- æ•£ç‚¹å›¾åæ˜ GNNæ˜¯å¦å­¦ä¹ åˆ°æœ‰æ„ä¹‰çš„åµŒå…¥ï¼ˆåŒç±»èŠ‚ç‚¹åº”é è¿‘ï¼Œå¼‚ç±»èŠ‚ç‚¹åº”åˆ†å¼€ï¼‰ã€‚

### æ³¨æ„ï¼š
- æ•£ç‚¹å›¾ä¿å­˜åœ¨è¿è¡Œç›®å½•ä¸‹ï¼Œå¯ç”¨å›¾åƒæŸ¥çœ‹å™¨æ£€æŸ¥ã€‚
- æ¨¡å‹ç®€å•ï¼ˆä¸¤å±‚GCNï¼‰ï¼Œé€‚åˆå±•ç¤ºGNNæ¦‚å¿µï¼›å®é™…åº”ç”¨å¯å¢åŠ å±‚æ•°æˆ–ä½¿ç”¨æ›´å¤æ‚çš„GNNå˜ä½“ï¼ˆå¦‚GATï¼‰ã€‚
