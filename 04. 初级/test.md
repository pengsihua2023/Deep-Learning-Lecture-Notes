
---

## ğŸ“˜ ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (GAN) æ•°å­¦æè¿°

GAN ç”± **ç”Ÿæˆå™¨ $G$** å’Œ **åˆ¤åˆ«å™¨ $D$** ç»„æˆï¼Œä¸¤è€…è¿›è¡Œä¸€ä¸ª **æå¤§æå°åšå¼ˆ**ï¼š

$$
\min_G \max_D V(D, G) = \mathbb{E}_{x \sim p_{\text{data}}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]
$$

* **åˆ¤åˆ«å™¨ $D(x)$**ï¼šè¾“å…¥æ ·æœ¬ $x$ï¼Œè¾“å‡ºå…¶æ¥è‡ªçœŸå®æ•°æ®åˆ†å¸ƒ $p_{\text{data}}(x)$ çš„æ¦‚ç‡ã€‚
* **ç”Ÿæˆå™¨ $G(z)$**ï¼šè¾“å…¥å™ªå£° $z \sim p_z(z)$ï¼Œç”Ÿæˆä¼ªé€ æ ·æœ¬ $G(z)$ï¼Œå¸Œæœ›æ¬ºéª—åˆ¤åˆ«å™¨ã€‚
* **ç›®æ ‡**ï¼š

  * åˆ¤åˆ«å™¨ï¼šæœ€å¤§åŒ– $\log D(x)$ï¼ˆçœŸå®æ ·æœ¬çš„åˆ¤åˆ«å‡†ç¡®ç‡ï¼‰ï¼Œæœ€å¤§åŒ– $\log(1 - D(G(z)))$ï¼ˆæ‹’ç»ç”Ÿæˆæ ·æœ¬çš„èƒ½åŠ›ï¼‰ã€‚
  * ç”Ÿæˆå™¨ï¼šæœ€å°åŒ– $\log(1 - D(G(z)))$ï¼Œä½¿ç”Ÿæˆæ ·æœ¬å°½å¯èƒ½é€¼è¿‘çœŸå®åˆ†å¸ƒã€‚

---

## ğŸ§‘â€ğŸ’» æœ€ç®€å•çš„ GAN ä»£ç ç¤ºä¾‹ (PyTorch)

ä¸‹é¢çš„ä»£ç æ˜¯ä¸€ä¸ª **æœ€å°åŒ–å®ç°**ï¼Œè®­ç»ƒ GAN åœ¨ 1D é«˜æ–¯åˆ†å¸ƒä¸Šå­¦ä¹ ç”Ÿæˆæ•°æ®ï¼ˆç®€åŒ–ç‰ˆï¼Œä¾¿äºç†è§£ï¼‰ï¼š

```python
import torch
import torch.nn as nn
import torch.optim as optim

# ç”Ÿæˆå™¨ G
class Generator(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(1, 16),
            nn.ReLU(),
            nn.Linear(16, 1)
        )
    def forward(self, z):
        return self.net(z)

# åˆ¤åˆ«å™¨ D
class Discriminator(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(1, 16),
            nn.ReLU(),
            nn.Linear(16, 1),
            nn.Sigmoid()
        )
    def forward(self, x):
        return self.net(x)

# åˆå§‹åŒ–ç½‘ç»œ
G = Generator()
D = Discriminator()

# æŸå¤±å‡½æ•° & ä¼˜åŒ–å™¨
criterion = nn.BCELoss()
opt_G = optim.Adam(G.parameters(), lr=0.001)
opt_D = optim.Adam(D.parameters(), lr=0.001)

# è®­ç»ƒå¾ªç¯
for epoch in range(2000):
    # ===== è®­ç»ƒåˆ¤åˆ«å™¨ D =====
    real_data = torch.randn(16, 1) * 2 + 3     # çœŸå®æ•°æ®: N(3, 2)
    fake_data = G(torch.randn(16, 1))          # ç”Ÿæˆæ•°æ®

    real_labels = torch.ones(16, 1)
    fake_labels = torch.zeros(16, 1)

    D_loss = criterion(D(real_data), real_labels) + criterion(D(fake_data.detach()), fake_labels)
    opt_D.zero_grad()
    D_loss.backward()
    opt_D.step()

    # ===== è®­ç»ƒç”Ÿæˆå™¨ G =====
    fake_data = G(torch.randn(16, 1))
    G_loss = criterion(D(fake_data), real_labels)  # ç”Ÿæˆå™¨å¸Œæœ›åˆ¤åˆ«å™¨è¾“å‡º 1
    opt_G.zero_grad()
    G_loss.backward()
    opt_G.step()

    if epoch % 500 == 0:
        print(f"Epoch {epoch}, D_loss: {D_loss.item():.4f}, G_loss: {G_loss.item():.4f}")
```

---

### ğŸ”‘ ä»£ç è¦ç‚¹ï¼š

1. **çœŸå®æ•°æ®åˆ†å¸ƒ**ï¼šè®¾ä¸º $N(3, 2)$ é«˜æ–¯åˆ†å¸ƒã€‚
2. **ç”Ÿæˆå™¨**ï¼šè¾“å…¥å™ªå£° $z \sim N(0, 1)$ï¼Œè¾“å‡ºä¼ªé€ æ ·æœ¬ã€‚
3. **åˆ¤åˆ«å™¨**ï¼šäºŒåˆ†ç±»ç½‘ç»œï¼Œåˆ¤æ–­è¾“å…¥æ˜¯å¦æ¥è‡ªçœŸå®åˆ†å¸ƒã€‚
4. **æŸå¤±å‡½æ•°**ï¼šä½¿ç”¨äº¤å‰ç†µ (Binary Cross-Entropy)ã€‚
5. **äº¤æ›¿è®­ç»ƒ**ï¼šå…ˆè®­ç»ƒåˆ¤åˆ«å™¨ï¼Œå†è®­ç»ƒç”Ÿæˆå™¨ã€‚

---


