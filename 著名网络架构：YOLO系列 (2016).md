## è‘—åç½‘ç»œæ¶æ„ï¼šYOLOç³»åˆ— (2016)
æå‡ºè€…ï¼šJoseph Redmon ç­‰ï¼ˆYOLOv1ï¼‰   
<img width="600" height="450" alt="image" src="https://github.com/user-attachments/assets/274e55c4-2768-4d82-bd9f-bf7f04b465b6" />  
YOLO çš„æ ¸å¿ƒç†å¿µæ˜¯å°†ç›®æ ‡æ£€æµ‹ä»»åŠ¡è½¬åŒ–ä¸ºå•ä¸€çš„å›å½’é—®é¢˜ï¼Œé€šè¿‡ä¸€æ¬¡å‰å‘ä¼ æ’­å³å¯åŒæ—¶é¢„æµ‹ç›®æ ‡çš„è¾¹ç•Œæ¡†ï¼ˆBounding Boxï¼‰å’Œç±»åˆ«æ¦‚ç‡ï¼Œå…·æœ‰é€Ÿåº¦å¿«ã€ç«¯åˆ°ç«¯è®­ç»ƒçš„ç‰¹ç‚¹ï¼Œéå¸¸é€‚åˆå®æ—¶åº”ç”¨ã€‚  
ç‰¹ç‚¹ï¼šå•é˜¶æ®µç›®æ ‡æ£€æµ‹æ¶æ„ï¼Œé€Ÿåº¦å¿«ï¼ŒYOLOv5/v8ç­‰ç‰ˆæœ¬ä¼˜åŒ–äº†ç²¾åº¦å’Œæ•ˆç‡ã€‚  
åº”ç”¨ï¼šå®æ—¶ç›®æ ‡æ£€æµ‹ï¼ˆå¦‚è‡ªåŠ¨é©¾é©¶ã€å®‰é˜²ï¼‰ã€‚  
æŒæ¡è¦ç‚¹ï¼šå•é˜¶æ®µæ£€æµ‹ã€é”šæ¡†æœºåˆ¶ã€‚  

<img width="850" height="251" alt="image" src="https://github.com/user-attachments/assets/0a0b8862-4b86-418e-b20a-4f6269e012d7" />

<img width="2501" height="1405" alt="image" src="https://github.com/user-attachments/assets/ca70fc85-8658-4286-9002-56b6eb3864ba" />

## ä»£ç 

```
è¿™ä¸ª simple_yolo_fixed.py æ–‡ä»¶å®ç°äº†ä¸€ä¸ªæœ€ç®€å•YOLOç›®æ ‡æ£€æµ‹æ¨¡å‹ï¼Œä¸“é—¨ç”¨äºæ•™å­¦æ¼”ç¤ºå’ŒCIFAR-10æ•°æ®é›†çš„ç›®æ ‡æ£€æµ‹ä»»åŠ¡ã€‚
ğŸ¯ æ ¸å¿ƒåŠŸèƒ½
1. SimpleYOLOæ¨¡å‹ç±»
ç½‘ç»œæ¶æ„: 5å±‚CNNç‰¹å¾æå– + å…¨è¿æ¥å±‚è¾“å‡º
ç½‘æ ¼ç³»ç»Ÿ: 7Ã—7ç½‘æ ¼åˆ’åˆ†
é¢„æµ‹è¾“å‡º: æ¯ä¸ªç½‘æ ¼å•å…ƒé¢„æµ‹30ä¸ªå€¼
è¾¹ç•Œæ¡†1: x, y, w, h, confidence (5ä¸ªå€¼)
è¾¹ç•Œæ¡†2: x, y, w, h, confidence (5ä¸ªå€¼)
ç±»åˆ«æ¦‚ç‡: 10ä¸ªCIFAR-10ç±»åˆ« (10ä¸ªå€¼)
ä¿®å¤é‡ç‚¹: ä½¿ç”¨å…¨è¿æ¥å±‚å°†1Ã—1ç‰¹å¾å›¾è½¬æ¢ä¸º7Ã—7ç½‘æ ¼è¾“å‡º
2. SimpleYOLODatasetæ•°æ®é›†ç±»
æ•°æ®æº: CIFAR-10æ•°æ®é›†
è¾¹ç•Œæ¡†ç”Ÿæˆ: æ ¹æ®ç±»åˆ«æ™ºèƒ½ç”Ÿæˆä¸åŒå¤§å°çš„è¾¹ç•Œæ¡†
é£æœºã€æ±½è½¦ã€èˆ¹ã€å¡è½¦ â†’ è¾ƒå¤§æ¡†
å…¶ä»–ç±»åˆ« â†’ è¾ƒå°æ¡†
æ ‡ç­¾æ ¼å¼: YOLOæ ¼å¼ (x_center, y_center, width, height)
ç½‘æ ¼æ˜ å°„: è‡ªåŠ¨å°†è¾¹ç•Œæ¡†æ˜ å°„åˆ°7Ã—7ç½‘æ ¼ç³»ç»Ÿ
3. æŸå¤±å‡½æ•° (yolo_loss)
è¾¹ç•Œæ¡†æŸå¤±: MSEæŸå¤±è®¡ç®—åæ ‡å’Œç½®ä¿¡åº¦
ç±»åˆ«æŸå¤±: MSEæŸå¤±è®¡ç®—ç±»åˆ«æ¦‚ç‡
ç»„åˆæŸå¤±: åŠ æƒç»„åˆè¾¹ç•Œæ¡†å’Œç±»åˆ«æŸå¤±
4. è®­ç»ƒå‡½æ•° (train_simple_yolo)
è®­ç»ƒå‚æ•°: 2000è®­ç»ƒæ ·æœ¬ï¼Œ500æµ‹è¯•æ ·æœ¬
æ‰¹æ¬¡å¤§å°: 8
å­¦ä¹ ç‡: 0.001 (Adamä¼˜åŒ–å™¨)
è®­ç»ƒè½®æ•°: 20ä¸ªepoch
å­¦ä¹ ç‡è°ƒåº¦: æ¯10ä¸ªepochå‡åŠ
5. å¯è§†åŒ–åŠŸèƒ½
è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–: æ¯5ä¸ªepochæ˜¾ç¤ºé¢„æµ‹ç»“æœ
è¾¹ç•Œæ¡†ç»˜åˆ¶: çº¢è‰²çŸ©å½¢æ¡† + ç±»åˆ«æ ‡ç­¾ + ç½®ä¿¡åº¦
ç»¼åˆæµ‹è¯•: 8ä¸ªæ ·æœ¬çš„æ£€æµ‹ç»“æœå±•ç¤º
è®­ç»ƒæ›²çº¿: æŸå¤±å‡½æ•°å˜åŒ–å›¾
```

```
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from torch.utils.data import Dataset, DataLoader
import torchvision
import torchvision.transforms as transforms
from torchvision import datasets
import random

class SimpleYOLO(nn.Module):
    """æœ€ç®€å•çš„YOLOæ¨¡å‹å®ç° - ä¿®å¤ç‰ˆæœ¬"""
    def __init__(self, num_classes=10, grid_size=7, num_boxes=2):
        super(SimpleYOLO, self).__init__()
        
        self.num_classes = num_classes
        self.grid_size = grid_size
        self.num_boxes = num_boxes
        
        # æ¯ä¸ªç½‘æ ¼å•å…ƒé¢„æµ‹çš„ç»´åº¦ï¼š
        # 5 (x, y, w, h, confidence) * num_boxes + num_classes
        self.output_dim = (5 * num_boxes + num_classes)
        
        # ç‰¹å¾æå–ç½‘ç»œ (ä¿®å¤ç‰ˆæœ¬ - ç¡®ä¿è¾“å‡ºä¸º7x7)
        self.features = nn.Sequential(
            # ç¬¬ä¸€å±‚å·ç§¯å— - 32x32 -> 16x16
            nn.Conv2d(3, 16, kernel_size=3, padding=1),
            nn.BatchNorm2d(16),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),
            
            # ç¬¬äºŒå±‚å·ç§¯å— - 16x16 -> 8x8
            nn.Conv2d(16, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),
            
            # ç¬¬ä¸‰å±‚å·ç§¯å— - 8x8 -> 4x4
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),
            
            # ç¬¬å››å±‚å·ç§¯å— - 4x4 -> 2x2
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),
            
            # ç¬¬äº”å±‚å·ç§¯å— - 2x2 -> 1x1
            nn.Conv2d(128, 256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),
        )
        
        # å…¨è¿æ¥å±‚å°†1x1ç‰¹å¾å›¾è½¬æ¢ä¸º7x7ç½‘æ ¼
        self.fc = nn.Linear(256, grid_size * grid_size * self.output_dim)
        
    def forward(self, x):
        # ç‰¹å¾æå–
        features = self.features(x)  # è¾“å‡º: (batch_size, 256, 1, 1)
        
        # å±•å¹³ç‰¹å¾
        features = features.view(features.size(0), -1)  # (batch_size, 256)
        
        # å…¨è¿æ¥å±‚
        output = self.fc(features)  # (batch_size, 7*7*30)
        
        # é‡å¡‘è¾“å‡ºä¸º (batch_size, grid_size, grid_size, output_dim)
        output = output.view(output.size(0), self.grid_size, self.grid_size, self.output_dim)
        
        return output

class SimpleYOLODataset(Dataset):
    """ç®€åŒ–çš„YOLOæ•°æ®é›†"""
    def __init__(self, root='./data', train=True, transform=None, max_samples=None):
        self.cifar10 = datasets.CIFAR10(root=root, train=train, download=True, transform=None)
        self.transform = transform
        self.max_samples = max_samples
        self.grid_size = 7
        self.num_classes = 10
        self.num_boxes = 2
        
        # CIFAR-10ç±»åˆ«åç§°
        self.class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 
                           'dog', 'frog', 'horse', 'ship', 'truck']
        
    def __len__(self):
        if self.max_samples:
            return min(self.max_samples, len(self.cifar10))
        return len(self.cifar10)
    
    def __getitem__(self, idx):
        img, label = self.cifar10[idx]
        
        # å°†PILå›¾åƒè½¬æ¢ä¸ºnumpyæ•°ç»„
        img_np = np.array(img)
        
        # ç”Ÿæˆç®€åŒ–çš„è¾¹ç•Œæ¡†æ ‡æ³¨
        bbox = self.generate_simple_bbox(img_np, label)
        
        # è½¬æ¢ä¸ºPyTorchå¼ é‡
        img_tensor = torch.from_numpy(img_np.transpose(2, 0, 1)).float() / 255.0
        
        # åº”ç”¨transformï¼ˆå¦‚æœæœ‰ï¼‰
        if self.transform:
            img_tensor = self.transform(img_tensor)
        
        # ç”ŸæˆYOLOæ ¼å¼çš„æ ‡ç­¾
        yolo_label = self.create_yolo_label(bbox, label)
        
        return img_tensor, yolo_label
    
    def generate_simple_bbox(self, img, label):
        """ç”Ÿæˆç®€åŒ–çš„è¾¹ç•Œæ¡†"""
        h, w = img.shape[:2]
        
        # æ ¹æ®ç±»åˆ«ç”Ÿæˆä¸åŒå¤§å°çš„è¾¹ç•Œæ¡†
        if label in [0, 1, 8, 9]:  # é£æœºã€æ±½è½¦ã€èˆ¹ã€å¡è½¦ - è¾ƒå¤§çš„æ¡†
            box_w = random.randint(w//3, w//2)
            box_h = random.randint(h//3, h//2)
        else:  # å…¶ä»–ç±»åˆ« - è¾ƒå°çš„æ¡†
            box_w = random.randint(w//4, w//3)
            box_h = random.randint(h//4, h//3)
        
        # éšæœºä½ç½®ï¼Œä½†ç¡®ä¿æ¡†åœ¨å›¾åƒå†…
        x_center = random.randint(box_w//2, w - box_w//2)
        y_center = random.randint(box_h//2, h - box_h//2)
        
        return [x_center, y_center, box_w, box_h]
    
    def create_yolo_label(self, bbox, class_id):
        """åˆ›å»ºYOLOæ ¼å¼çš„æ ‡ç­¾å¼ é‡"""
        # åˆ›å»ºæ ‡ç­¾å¼ é‡ (grid_size, grid_size, 5*num_boxes + num_classes)
        label = torch.zeros(self.grid_size, self.grid_size, 
                           self.num_boxes * 5 + self.num_classes)
        
        x_center, y_center, box_w, box_h = bbox
        
        # è®¡ç®—ç½‘æ ¼åæ ‡
        grid_x = int(x_center * self.grid_size / 32)
        grid_y = int(y_center * self.grid_size / 32)
        
        # ç¡®ä¿ç½‘æ ¼åæ ‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
        grid_x = min(max(grid_x, 0), self.grid_size - 1)
        grid_y = min(max(grid_y, 0), self.grid_size - 1)
        
        # è®¡ç®—ç›¸å¯¹äºç½‘æ ¼çš„åæ ‡
        x_offset = (x_center * self.grid_size / 32) - grid_x
        y_offset = (y_center * self.grid_size / 32) - grid_y
        
        # å½’ä¸€åŒ–å®½åº¦å’Œé«˜åº¦
        w_norm = box_w / 32.0
        h_norm = box_h / 32.0
        
        # è®¾ç½®ç¬¬ä¸€ä¸ªè¾¹ç•Œæ¡†çš„é¢„æµ‹
        box_idx = 0
        start_idx = box_idx * 5
        
        label[grid_y, grid_x, start_idx:start_idx+4] = torch.tensor([x_offset, y_offset, w_norm, h_norm])
        label[grid_y, grid_x, start_idx+4] = 1.0  # confidence
        
        # è®¾ç½®ç±»åˆ«æ¦‚ç‡
        class_start_idx = self.num_boxes * 5
        label[grid_y, grid_x, class_start_idx + class_id] = 1.0
        
        return label

def yolo_loss(predictions, targets, lambda_coord=5.0, lambda_noobj=0.5):
    """ç®€åŒ–çš„YOLOæŸå¤±å‡½æ•°"""
    batch_size = predictions.size(0)
    grid_size = predictions.size(1)
    
    # åˆ†ç¦»é¢„æµ‹çš„å„ä¸ªç»„ä»¶
    pred_boxes = predictions[:, :, :, :10]  # å‰10ä¸ªæ˜¯è¾¹ç•Œæ¡† (x, y, w, h, conf) * 2
    pred_classes = predictions[:, :, :, 10:]  # å10ä¸ªæ˜¯ç±»åˆ«æ¦‚ç‡
    
    # åˆ†ç¦»ç›®æ ‡çš„å„ä¸ªç»„ä»¶
    target_boxes = targets[:, :, :, :10]
    target_classes = targets[:, :, :, 10:]
    
    # è®¡ç®—è¾¹ç•Œæ¡†æŸå¤±
    box_loss = F.mse_loss(pred_boxes, target_boxes, reduction='sum')
    
    # è®¡ç®—ç±»åˆ«æŸå¤±
    class_loss = F.mse_loss(pred_classes, target_classes, reduction='sum')
    
    # æ€»æŸå¤±
    total_loss = lambda_coord * box_loss + class_loss
    
    return total_loss / batch_size

def train_simple_yolo():
    """è®­ç»ƒç®€åŒ–çš„YOLOæ¨¡å‹"""
    # è®¾ç½®è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æ•°æ®å˜æ¢
    transform = transforms.Compose([
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = SimpleYOLODataset(root='./data', train=True, transform=transform, max_samples=2000)
    test_dataset = SimpleYOLODataset(root='./data', train=False, transform=transform, max_samples=500)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)
    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=0)
    
    print(f"è®­ç»ƒæ ·æœ¬æ•°: {len(train_dataset)}")
    print(f"æµ‹è¯•æ ·æœ¬æ•°: {len(test_dataset)}")
    
    # åˆ›å»ºæ¨¡å‹
    model = SimpleYOLO(num_classes=10, grid_size=7, num_boxes=2)
    model = model.to(device)
    
    print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    
    # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = yolo_loss
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)
    
    # è®­ç»ƒå¾ªç¯
    print("å¼€å§‹è®­ç»ƒ...")
    num_epochs = 20
    train_losses = []
    
    for epoch in range(num_epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        total_loss = 0
        
        for batch_idx, (inputs, targets) in enumerate(train_loader):
            inputs = inputs.to(device)
            targets = targets.to(device)
            
            # å‰å‘ä¼ æ’­
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            
            if batch_idx % 100 == 0:
                print(f'Epoch: {epoch+1}/{num_epochs}, Batch: {batch_idx}/{len(train_loader)}, '
                      f'Loss: {loss.item():.4f}')
        
        avg_loss = total_loss / len(train_loader)
        train_losses.append(avg_loss)
        
        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step()
        
        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_loss:.4f}')
        
        # æ¯5ä¸ªepochæ˜¾ç¤ºä¸€äº›é¢„æµ‹ç»“æœ
        if (epoch + 1) % 5 == 0:
            visualize_predictions(model, test_dataset, device, epoch + 1)
    
    return model, train_losses

def visualize_predictions(model, test_dataset, device, epoch, num_samples=6):
    """å¯è§†åŒ–YOLOé¢„æµ‹ç»“æœ"""
    model.eval()
    
    with torch.no_grad():
        fig, axes = plt.subplots(num_samples, 2, figsize=(12, 4*num_samples))
        
        for i in range(num_samples):
            input_img, target_label = test_dataset[i]
            input_img = input_img.unsqueeze(0).to(device)
            
            # é¢„æµ‹
            pred_output = model(input_img)
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„ç”¨äºæ˜¾ç¤º
            input_np = input_img[0].cpu().numpy().transpose(1, 2, 0)
            # åå½’ä¸€åŒ–
            input_np = (input_np * 0.5 + 0.5).clip(0, 1)
            
            # æ˜¾ç¤ºåŸå§‹å›¾åƒ
            axes[i, 0].imshow(input_np)
            axes[i, 0].set_title(f'Input Image {i+1}')
            axes[i, 0].axis('off')
            
            # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
            axes[i, 1].imshow(input_np)
            
            # ç»˜åˆ¶é¢„æµ‹çš„è¾¹ç•Œæ¡†
            pred_boxes = pred_output[0, :, :, :10].cpu().numpy()  # å‰10ä¸ªæ˜¯è¾¹ç•Œæ¡†
            pred_classes = pred_output[0, :, :, 10:].cpu().numpy()  # å10ä¸ªæ˜¯ç±»åˆ«
            
            grid_size = 7
            cell_size = 32 / grid_size
            
            for grid_y in range(grid_size):
                for grid_x in range(grid_size):
                    # æ£€æŸ¥ç¬¬ä¸€ä¸ªè¾¹ç•Œæ¡†çš„ç½®ä¿¡åº¦
                    conf = pred_boxes[grid_y, grid_x, 4]
                    if conf > 0.3:  # ç½®ä¿¡åº¦é˜ˆå€¼
                        # è·å–è¾¹ç•Œæ¡†åæ ‡
                        x_offset = pred_boxes[grid_y, grid_x, 0]
                        y_offset = pred_boxes[grid_y, grid_x, 1]
                        w_norm = pred_boxes[grid_y, grid_x, 2]
                        h_norm = pred_boxes[grid_y, grid_x, 3]
                        
                        # è½¬æ¢ä¸ºåƒç´ åæ ‡
                        x_center = (grid_x + x_offset) * cell_size
                        y_center = (grid_y + y_offset) * cell_size
                        width = w_norm * 32
                        height = h_norm * 32
                        
                        # è·å–é¢„æµ‹çš„ç±»åˆ«
                        class_probs = pred_classes[grid_y, grid_x, :]
                        pred_class = np.argmax(class_probs)
                        class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 
                                      'dog', 'frog', 'horse', 'ship', 'truck']
                        
                        # ç»˜åˆ¶è¾¹ç•Œæ¡†
                        rect = patches.Rectangle(
                            (x_center - width/2, y_center - height/2), 
                            width, height, 
                            linewidth=2, 
                            edgecolor='red', 
                            facecolor='none'
                        )
                        axes[i, 1].add_patch(rect)
                        
                        # æ·»åŠ ç±»åˆ«æ ‡ç­¾
                        axes[i, 1].text(
                            x_center - width/2, y_center - height/2 - 5,
                            f'{class_names[pred_class]} ({conf:.2f})',
                            color='red', fontsize=8, weight='bold'
                        )
            
            axes[i, 1].set_title(f'Prediction {i+1} (Epoch {epoch})')
            axes[i, 1].axis('off')
        
        plt.tight_layout()
        plt.savefig(f'yolo_predictions_epoch_{epoch}.png', dpi=300, bbox_inches='tight')
        plt.show()

def test_yolo_model_comprehensive(model, num_samples=8):
    """ç»¼åˆæµ‹è¯•YOLOæ¨¡å‹"""
    print("\nç»¼åˆæµ‹è¯•YOLOæ¨¡å‹...")
    model.eval()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    transform = transforms.Compose([
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])
    test_dataset = SimpleYOLODataset(root='./data', train=False, transform=transform, max_samples=num_samples)
    
    with torch.no_grad():
        fig, axes = plt.subplots(num_samples, 1, figsize=(10, 4*num_samples))
        
        for i in range(num_samples):
            input_img, target_label = test_dataset[i]
            input_img = input_img.unsqueeze(0).to(device)
            
            # é¢„æµ‹
            pred_output = model(input_img)
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„ç”¨äºæ˜¾ç¤º
            input_np = input_img[0].cpu().numpy().transpose(1, 2, 0)
            # åå½’ä¸€åŒ–
            input_np = (input_np * 0.5 + 0.5).clip(0, 1)
            
            # æ˜¾ç¤ºå›¾åƒå’Œé¢„æµ‹ç»“æœ
            axes[i].imshow(input_np)
            
            # ç»˜åˆ¶é¢„æµ‹çš„è¾¹ç•Œæ¡†
            pred_boxes = pred_output[0, :, :, :10].cpu().numpy()
            pred_classes = pred_output[0, :, :, 10:].cpu().numpy()
            
            grid_size = 7
            cell_size = 32 / grid_size
            class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 
                          'dog', 'frog', 'horse', 'ship', 'truck']
            
            for grid_y in range(grid_size):
                for grid_x in range(grid_size):
                    # æ£€æŸ¥ç¬¬ä¸€ä¸ªè¾¹ç•Œæ¡†çš„ç½®ä¿¡åº¦
                    conf = pred_boxes[grid_y, grid_x, 4]
                    if conf > 0.2:  # é™ä½ç½®ä¿¡åº¦é˜ˆå€¼ä»¥æ˜¾ç¤ºæ›´å¤šæ£€æµ‹
                        # è·å–è¾¹ç•Œæ¡†åæ ‡
                        x_offset = pred_boxes[grid_y, grid_x, 0]
                        y_offset = pred_boxes[grid_y, grid_x, 1]
                        w_norm = pred_boxes[grid_y, grid_x, 2]
                        h_norm = pred_boxes[grid_y, grid_x, 3]
                        
                        # è½¬æ¢ä¸ºåƒç´ åæ ‡
                        x_center = (grid_x + x_offset) * cell_size
                        y_center = (grid_y + y_offset) * cell_size
                        width = w_norm * 32
                        height = h_norm * 32
                        
                        # è·å–é¢„æµ‹çš„ç±»åˆ«
                        class_probs = pred_classes[grid_y, grid_x, :]
                        pred_class = np.argmax(class_probs)
                        
                        # ç»˜åˆ¶è¾¹ç•Œæ¡†
                        rect = patches.Rectangle(
                            (x_center - width/2, y_center - height/2), 
                            width, height, 
                            linewidth=2, 
                            edgecolor='red', 
                            facecolor='none'
                        )
                        axes[i].add_patch(rect)
                        
                        # æ·»åŠ ç±»åˆ«æ ‡ç­¾
                        axes[i].text(
                            x_center - width/2, y_center - height/2 - 5,
                            f'{class_names[pred_class]} ({conf:.2f})',
                            color='red', fontsize=8, weight='bold'
                        )
            
            axes[i].set_title(f'YOLO Detection {i+1}')
            axes[i].axis('off')
        
        plt.tight_layout()
        plt.savefig('yolo_comprehensive_detections.png', dpi=300, bbox_inches='tight')
        plt.show()

def plot_training_curves(train_losses):
    """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
    plt.figure(figsize=(10, 6))
    plt.plot(train_losses, 'b-', linewidth=2)
    plt.title('Simple YOLO Training Loss Curve', fontsize=14)
    plt.xlabel('Epoch', fontsize=12)
    plt.ylabel('YOLO Loss', fontsize=12)
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig('yolo_training_curves.png', dpi=300, bbox_inches='tight')
    plt.show()

def main():
    """ä¸»å‡½æ•°"""
    print("=== æœ€ç®€å•çš„YOLOæ¨¡å‹å®ç° (ä¿®å¤ç‰ˆæœ¬) ===")
    
    # è®­ç»ƒæ¨¡å‹
    model, train_losses = train_simple_yolo()
    
    # ç»¼åˆæµ‹è¯•æ¨¡å‹
    test_yolo_model_comprehensive(model)
    
    # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    plot_training_curves(train_losses)
    
    print("\nè®­ç»ƒå®Œæˆï¼")
    print("å¯è§†åŒ–ç»“æœå·²ä¿å­˜:")
    print("- yolo_comprehensive_detections.png: ç»¼åˆæ£€æµ‹ç»“æœ")
    print("- yolo_training_curves.png: è®­ç»ƒæ›²çº¿")
    print("- yolo_predictions_epoch_*.png: è®­ç»ƒè¿‡ç¨‹ä¸­çš„é¢„æµ‹ç»“æœ")

if __name__ == "__main__":
    main()

```

## è®­ç»ƒç»“æœ

Epoch: 20/20, Batch: 0/250, Loss: 11.6010  
Epoch: 20/20, Batch: 100/250, Loss: 10.1258  
Epoch: 20/20, Batch: 200/250, Loss: 10.2170  
Epoch 20/20, Train Loss: 10.7619  

ç»¼åˆæµ‹è¯•YOLOæ¨¡å‹... 

è®­ç»ƒå®Œæˆï¼  
å¯è§†åŒ–ç»“æœå·²ä¿å­˜:  
- yolo_comprehensive_detections.png: ç»¼åˆæ£€æµ‹ç»“æœ  
- yolo_training_curves.png: è®­ç»ƒæ›²çº¿  
- yolo_predictions_epoch_*.png: è®­ç»ƒè¿‡ç¨‹ä¸­çš„é¢„æµ‹ç»“æœ   


<img width="840" height="950" alt="image" src="https://github.com/user-attachments/assets/980e6e4b-f042-4193-bdec-485665ef05f2" />   

<img width="212" height="833" alt="image" src="https://github.com/user-attachments/assets/aaf3e0bb-8053-4afb-96fb-fa5dd36a82cb" />  


<img width="992" height="602" alt="image" src="https://github.com/user-attachments/assets/41c604fb-ee9a-45fa-b1d4-195cc45593f9" />   
