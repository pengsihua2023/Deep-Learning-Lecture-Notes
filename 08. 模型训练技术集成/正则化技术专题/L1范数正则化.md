## L1èŒƒæ•°æ­£åˆ™åŒ–
### ğŸ“– ä»€ä¹ˆæ˜¯L1èŒƒæ•°æ­£åˆ™åŒ–ï¼Ÿ

L1èŒƒæ•°æ­£åˆ™åŒ–ï¼ˆä¹Ÿç§°ä¸ºLassoæ­£åˆ™åŒ–ï¼‰æ˜¯ä¸€ç§åœ¨æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ ä¸­å¸¸ç”¨çš„æ­£åˆ™åŒ–æŠ€æœ¯ï¼Œç”¨äºé˜²æ­¢æ¨¡å‹è¿‡æ‹Ÿåˆå¹¶ä¿ƒè¿›å‚æ•°ç¨€ç–æ€§ã€‚ä¸L2èŒƒæ•°æ­£åˆ™åŒ–ï¼ˆRidgeæ­£åˆ™åŒ–ï¼‰ä¸åŒï¼ŒL1æ­£åˆ™åŒ–é€šè¿‡åœ¨æŸå¤±å‡½æ•°ä¸­æ·»åŠ æ¨¡å‹å‚æ•°çš„L1èŒƒæ•°ï¼ˆå³æƒé‡çš„ç»å¯¹å€¼ä¹‹å’Œï¼‰ä½œä¸ºæƒ©ç½šé¡¹ï¼Œå€¾å‘äºå°†éƒ¨åˆ†æƒé‡æ¨å‘é›¶ï¼Œä»è€Œç”Ÿæˆç¨€ç–æ¨¡å‹ã€‚

#### æ ¸å¿ƒåŸç†
- **æŸå¤±å‡½æ•°ä¿®æ”¹**ï¼šL1æ­£åˆ™åŒ–åœ¨åŸå§‹æŸå¤±å‡½æ•°ä¸Šæ·»åŠ L1èŒƒæ•°æƒ©ç½šé¡¹ï¼š


$$
\text{Loss}_ {\text{regularized}} = \text{Loss}_{\text{original}} + \lambda \sum_i |w_i|
$$

å…¶ä¸­ï¼š

* $\text{Loss}_{\text{original}}$ æ˜¯åŸå§‹æŸå¤±ï¼ˆå¦‚å‡æ–¹è¯¯å·®æˆ–äº¤å‰ç†µï¼‰ã€‚
* $w_i$ æ˜¯æ¨¡å‹å‚æ•°ï¼ˆå¦‚æƒé‡ï¼‰ã€‚
* $|w_i|$ æ˜¯æƒé‡çš„ç»å¯¹å€¼ï¼Œ $\sum |w_i|$ æ˜¯ L1 èŒƒæ•°ã€‚
* $\lambda$ æ˜¯æ­£åˆ™åŒ–å¼ºåº¦çš„è¶…å‚æ•°ï¼Œæ§åˆ¶æƒ©ç½šåŠ›åº¦ã€‚




- **æ•ˆæœ**ï¼š
  - L1æ­£åˆ™åŒ–å€¾å‘äºå°†ä¸é‡è¦çš„æƒé‡è®¾ä¸ºé›¶ï¼Œç”Ÿæˆç¨€ç–æ¨¡å‹ï¼ˆå³ç‰¹å¾é€‰æ‹©æ•ˆæœï¼‰ã€‚
  - ç¨€ç–æ€§æœ‰åŠ©äºå‡å°‘æ¨¡å‹å¤æ‚åº¦ã€æé«˜å¯è§£é‡Šæ€§ï¼Œå¹¶é™ä½è¿‡æ‹Ÿåˆé£é™©ã€‚
  - ç›¸æ¯”L2æ­£åˆ™åŒ–ï¼ˆä½¿æƒé‡å˜å°ä½†éé›¶ï¼‰ï¼ŒL1æ­£åˆ™åŒ–æ›´é€‚åˆéœ€è¦ç¨€ç–è§£çš„åœºæ™¯ã€‚

- **ä¸L2æ­£åˆ™åŒ–çš„åŒºåˆ«**ï¼š


* L2 æ­£åˆ™åŒ– $\left(\sum w_i^2\right)$ ä½¿æƒé‡è¶‹å‘äºå°å€¼ï¼Œä¿æŒæ‰€æœ‰æƒé‡éé›¶ã€‚
* L1 æ­£åˆ™åŒ– $\left(\sum |w_i|\right)$ å› å…¶ä¸å¯å¾®çš„ç‰¹æ€§ï¼ˆåœ¨é›¶ç‚¹å¤„ï¼‰ï¼Œèƒ½å°†éƒ¨åˆ†æƒé‡ç²¾ç¡®æ¨å‘é›¶ã€‚
* L1 æ­£åˆ™åŒ–åœ¨é«˜ç»´æ•°æ®ï¼ˆå¦‚ç‰¹å¾é€‰æ‹©ï¼‰ä¸­æ›´æœ‰æ•ˆï¼Œè€Œ L2 æ­£åˆ™åŒ–æ›´é€‚åˆå¹³æ»‘æƒé‡åˆ†å¸ƒã€‚




#### åº”ç”¨åœºæ™¯
- **ç‰¹å¾é€‰æ‹©**ï¼šåœ¨æœºå™¨å­¦ä¹ ï¼ˆå¦‚çº¿æ€§å›å½’ã€é€»è¾‘å›å½’ï¼‰ä¸­ï¼ŒL1æ­£åˆ™åŒ–å¯è‡ªåŠ¨é€‰æ‹©é‡è¦ç‰¹å¾ã€‚
- **ç¥ç»ç½‘ç»œ**ï¼šåœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼ŒL1æ­£åˆ™åŒ–å¯ç”¨äºç¨€ç–åŒ–ç½‘ç»œï¼ˆå¦‚å·ç§¯å±‚æˆ–å…¨è¿æ¥å±‚ï¼‰ã€‚
- **å‹ç¼©æ¨¡å‹**ï¼šç¨€ç–æ¨¡å‹æ›´å®¹æ˜“è¿›è¡Œå‰ªææˆ–é‡åŒ–ï¼Œé€‚ç”¨äºèµ„æºå—é™çš„è®¾å¤‡ã€‚

---

### ğŸ“– Pythonä»£ç ç¤ºä¾‹

ä»¥ä¸‹æ˜¯ä¸€ä¸ªä½¿ç”¨PyTorchå®ç°L1èŒƒæ•°æ­£åˆ™åŒ–çš„ç¤ºä¾‹ï¼ŒåŸºäºMNISTæ‰‹å†™æ•°å­—åˆ†ç±»ä»»åŠ¡ã€‚L1æ­£åˆ™åŒ–é€šå¸¸éœ€è¦æ‰‹åŠ¨æ·»åŠ åˆ°æŸå¤±å‡½æ•°ä¸­ï¼Œå› ä¸ºPyTorchçš„ä¼˜åŒ–å™¨ï¼ˆå¦‚SGDã€Adamï¼‰å†…ç½®æ”¯æŒ`weight_decay`ï¼ˆå¯¹åº”L2æ­£åˆ™åŒ–ï¼‰ï¼Œä½†ä¸æ”¯æŒç›´æ¥çš„L1æ­£åˆ™åŒ–ã€‚
```
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# æ­¥éª¤1: å®šä¹‰ç®€å•çš„å…¨è¿æ¥ç¥ç»ç½‘ç»œ
class SimpleNet(nn.Module):
    def __init__(self):
        super(SimpleNet, self).__init__()
        self.fc1 = nn.Linear(28 * 28, 128)  # è¾“å…¥ï¼š28x28åƒç´ 
        self.fc2 = nn.Linear(128, 10)       # è¾“å‡ºï¼š10ç±»
        self.relu = nn.ReLU()
    
    def forward(self, x):
        x = x.view(-1, 28 * 28)  # å±•å¹³è¾“å…¥
        x = self.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# æ­¥éª¤2: åŠ è½½MNISTæ•°æ®é›†
transform = transforms.ToTensor()
train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64)

# æ­¥éª¤3: åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
model = SimpleNet()
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.01)
l1_lambda = 1e-4  # L1æ­£åˆ™åŒ–ç³»æ•°

# æ­¥éª¤4: è®­ç»ƒå‡½æ•°ï¼ˆæ‰‹åŠ¨æ·»åŠ L1æ­£åˆ™åŒ–ï¼‰
def train(epoch):
    model.train()
    total_loss = 0
    for batch_idx, (data, target) in enumerate(train_loader):
        optimizer.zero_grad()  # æ¸…ç©ºæ¢¯åº¦
        output = model(data)
        # è®¡ç®—åŸå§‹æŸå¤±
        loss = criterion(output, target)
        # æ·»åŠ L1æ­£åˆ™åŒ–é¡¹
        l1_norm = sum(torch.abs(p).sum() for p in model.parameters())
        loss = loss + l1_lambda * l1_norm
        # åå‘ä¼ æ’­å’Œä¼˜åŒ–
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    print(f'Epoch {epoch}, Average Loss: {total_loss / len(train_loader):.4f}')

# æ­¥éª¤5: æµ‹è¯•å‡½æ•°
def test():
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for data, target in test_loader:
            output = model(data)
            _, predicted = torch.max(output.data, 1)
            total += target.size(0)
            correct += (predicted == target).sum().item()
    accuracy = 100. * correct / total
    print(f'Test Accuracy: {accuracy:.2f}%')

# æ­¥éª¤6: è¿è¡Œè®­ç»ƒå’Œæµ‹è¯•
epochs = 5
for epoch in range(1, epochs + 1):
    train(epoch)
    test()
```

### ğŸ“– ä»£ç è¯´æ˜

1. **æ¨¡å‹å®šä¹‰**ï¼š
   - `SimpleNet` æ˜¯ä¸€ä¸ªç®€å•çš„å…¨è¿æ¥ç¥ç»ç½‘ç»œï¼Œè¾“å…¥ä¸ºMNISTçš„28x28åƒç´ å›¾åƒï¼Œè¾“å‡ºä¸º10ç±»åˆ†ç±»ã€‚

2. **æ•°æ®é›†**ï¼š
   - ä½¿ç”¨`torchvision`åŠ è½½MNISTæ•°æ®é›†ï¼Œæ‰¹é‡å¤§å°ä¸º64ï¼Œæ•°æ®é¢„å¤„ç†ä»…åŒ…æ‹¬è½¬æ¢ä¸ºå¼ é‡ã€‚

3. **L1æ­£åˆ™åŒ–å®ç°**ï¼š
   - PyTorchä¼˜åŒ–å™¨ä¸æ”¯æŒç›´æ¥çš„L1æ­£åˆ™åŒ–ï¼ˆä¸åƒL2çš„`weight_decay`ï¼‰ï¼Œå› æ­¤æ‰‹åŠ¨è®¡ç®—L1èŒƒæ•°ã€‚
   - é€šè¿‡`sum(torch.abs(p).sum() for p in model.parameters())`è®¡ç®—æ‰€æœ‰å‚æ•°çš„L1èŒƒæ•°ï¼ˆç»å¯¹å€¼å’Œï¼‰ã€‚
   - å°†L1èŒƒæ•°ä¹˜ä»¥ç³»æ•°`l1_lambda`ï¼ˆå¦‚1e-4ï¼‰åŠ åˆ°æŸå¤±å‡½æ•°ä¸­ã€‚

4. **è®­ç»ƒä¸æµ‹è¯•**ï¼š
   - è®­ç»ƒæ—¶ï¼ŒæŸå¤±åŒ…æ‹¬åŸå§‹äº¤å‰ç†µæŸå¤±å’ŒL1æ­£åˆ™åŒ–é¡¹ã€‚
   - æ¯ä¸ªepochæ‰“å°å¹³å‡æŸå¤±ï¼Œæµ‹è¯•æ—¶è®¡ç®—åˆ†ç±»å‡†ç¡®ç‡ã€‚
   - L1æ­£åˆ™åŒ–ä¼šæ¨åŠ¨éƒ¨åˆ†æƒé‡è¶‹å‘äºé›¶ï¼Œå¯é€šè¿‡æ£€æŸ¥`model.parameters()`éªŒè¯ç¨€ç–æ€§ã€‚

5. **è¾“å‡ºç¤ºä¾‹**ï¼š
   ```
   Epoch 1, Average Loss: 0.9123
   Test Accuracy: 91.50%
   Epoch 2, Average Loss: 0.4321
   Test Accuracy: 93.80%
   ...
   Epoch 5, Average Loss: 0.3124
   Test Accuracy: 95.20%
   ```
   å®é™…å€¼å› éšæœºåˆå§‹åŒ–è€Œå¼‚ã€‚

---

### æ£€æŸ¥ç¨€ç–æ€§
ä¸ºäº†éªŒè¯L1æ­£åˆ™åŒ–çš„ç¨€ç–æ•ˆæœï¼Œå¯ä»¥åœ¨è®­ç»ƒåæ£€æŸ¥æ¨¡å‹æƒé‡ï¼š

```python
# æ£€æŸ¥æƒé‡çš„ç¨€ç–æ€§
def check_sparsity(model):
    total_params = 0
    zero_params = 0
    for param in model.parameters():
        total_params += param.numel()
        zero_params += (param == 0).sum().item()
    sparsity = 100. * zero_params / total_params
    print(f'æ¨¡å‹ç¨€ç–æ€§: {sparsity:.2f}% (é›¶æƒé‡å æ¯”)')

# åœ¨è®­ç»ƒåè°ƒç”¨
check_sparsity(model)
```

L1æ­£åˆ™åŒ–ä¼šå¢åŠ é›¶æƒé‡çš„æ¯”ä¾‹ï¼Œå°¤å…¶å½“`l1_lambda`è¾ƒå¤§æ—¶ã€‚

---

### L1ä¸L2æ­£åˆ™åŒ–çš„å¯¹æ¯”
- **L1æ­£åˆ™åŒ–**ï¼š
  - å€¾å‘äºäº§ç”Ÿç¨€ç–æƒé‡ï¼ˆéƒ¨åˆ†æƒé‡ä¸º0ï¼‰ã€‚
  - é€‚åˆç‰¹å¾é€‰æ‹©æˆ–éœ€è¦å‹ç¼©çš„åœºæ™¯ã€‚
  - æ¢¯åº¦ä¸è¿ç»­ï¼ˆåœ¨é›¶ç‚¹ä¸å¯å¾®ï¼‰ï¼Œä¼˜åŒ–å¯èƒ½æ›´å¤æ‚ã€‚
- **L2æ­£åˆ™åŒ–**ï¼š
  - ä½¿æƒé‡å˜å°ä½†éé›¶ï¼Œä¿æŒå¹³æ»‘ã€‚
  - é€‚åˆéœ€è¦ç¨³å®šæ¢¯åº¦æ›´æ–°çš„åœºæ™¯ã€‚
  - PyTorché€šè¿‡`weight_decay`ç›´æ¥æ”¯æŒã€‚

#### ç»“åˆL1å’ŒL2ï¼ˆElastic Netï¼‰
å¯ä»¥åŒæ—¶ä½¿ç”¨L1å’ŒL2æ­£åˆ™åŒ–ï¼Œå½¢æˆElastic Netæ­£åˆ™åŒ–ï¼š

```python
l1_lambda = 1e-4
l2_lambda = 1e-4
loss = criterion(output, target)
l1_norm = sum(torch.abs(p).sum() for p in model.parameters())
l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())
loss = loss + l1_lambda * l1_norm + l2_lambda * l2_norm
```

---

### å®é™…åº”ç”¨åœºæ™¯
- **ç‰¹å¾é€‰æ‹©**ï¼šåœ¨ä¼ ç»Ÿæœºå™¨å­¦ä¹ ä¸­ï¼ˆå¦‚é€»è¾‘å›å½’ï¼‰ï¼ŒL1æ­£åˆ™åŒ–ç”¨äºé€‰æ‹©é‡è¦ç‰¹å¾ã€‚
- **ç¥ç»ç½‘ç»œå‹ç¼©**ï¼šL1æ­£åˆ™åŒ–å¯ç”Ÿæˆç¨€ç–ç½‘ç»œï¼Œä¾¿äºå‰ªææˆ–éƒ¨ç½²åˆ°èµ„æºå—é™è®¾å¤‡ã€‚
- **é«˜ç»´æ•°æ®**ï¼šåœ¨è¾“å…¥ç‰¹å¾è¾ƒå¤šæ—¶ï¼ŒL1æ­£åˆ™åŒ–èƒ½æœ‰æ•ˆå‡å°‘ä¸ç›¸å…³æƒé‡ã€‚
- **è¶…å‚æ•°è°ƒä¼˜**ï¼š`l1_lambda`éœ€é€šè¿‡äº¤å‰éªŒè¯æˆ–è´å¶æ–¯ä¼˜åŒ–ï¼ˆå¦‚å‰è¿°é—®é¢˜ï¼‰è°ƒæ•´ï¼Œå…¸å‹èŒƒå›´ä¸º1e-5åˆ°1e-3ã€‚

---
