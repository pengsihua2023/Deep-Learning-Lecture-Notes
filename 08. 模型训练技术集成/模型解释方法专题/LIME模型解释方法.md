# LIMEæ¨¡å‹è§£é‡Šæ–¹æ³• (Local Interpretable Model-agnostic Explanations)


## 1. å®šä¹‰

**LIME** æ˜¯ä¸€ç§ **æ¨¡å‹æ— å…³ (model-agnostic)** çš„å±€éƒ¨å¯è§£é‡Šæ–¹æ³•ï¼Œç”¨äºè§£é‡Šä»»æ„é»‘ç®±æ¨¡å‹çš„é¢„æµ‹ç»“æœã€‚
æ ¸å¿ƒæ€æƒ³ï¼š

* ç»™å®šä¸€ä¸ªè¾“å…¥æ ·æœ¬ $x$ å’Œæ¨¡å‹ $f$ï¼Œæˆ‘ä»¬å¸Œæœ›çŸ¥é“è¾“å…¥çš„å“ªäº›ç‰¹å¾å¯¹é¢„æµ‹ $f(x)$ å½±å“æœ€å¤§ã€‚
* LIME çš„åšæ³•æ˜¯ï¼š

  1. åœ¨ $x$ é™„è¿‘ç”Ÿæˆè®¸å¤šæ‰°åŠ¨æ ·æœ¬ $x'$ï¼›
  2. ç”¨é»‘ç®±æ¨¡å‹ $f$ é¢„æµ‹è¿™äº›æ‰°åŠ¨æ ·æœ¬ï¼›
  3. æ ¹æ®ä¸åŸå§‹æ ·æœ¬çš„â€œé‚»è¿‘åº¦â€åŠ æƒè¿™äº›æ ·æœ¬ï¼›
  4. åœ¨è¿™äº›æ ·æœ¬ä¸Šè®­ç»ƒä¸€ä¸ªç®€å•çš„ **å¯è§£é‡Šæ¨¡å‹ï¼ˆå¦‚çº¿æ€§å›å½’ã€å†³ç­–æ ‘ï¼‰**ï¼›
  5. ç”¨è¯¥æ¨¡å‹çš„ç³»æ•°ä½œä¸ºå±€éƒ¨è§£é‡Šã€‚


## 2. æ•°å­¦æè¿°

è®¾ï¼š

* é»‘ç®±æ¨¡å‹ï¼š$f: \mathbb{R}^d \to \mathbb{R}$
* ç›®æ ‡è¾“å…¥ï¼š$x \in \mathbb{R}^d$
* é‚»åŸŸé‡‡æ ·ï¼šç”Ÿæˆæ ·æœ¬ $\{z_i\}_{i=1}^N$
* é‚»è¿‘åº¦å‡½æ•°ï¼š$\pi_x(z)$ï¼Œè¡¡é‡ $z$ å’Œ $x$ çš„ç›¸ä¼¼æ€§ï¼ˆé€šå¸¸ç”¨ RBF æ ¸å‡½æ•°ï¼‰

LIME è®­ç»ƒä¸€ä¸ªç®€å•çš„è§£é‡Šæ¨¡å‹ $g \in G$ï¼ˆå¦‚çº¿æ€§æ¨¡å‹ï¼‰ï¼Œä¼˜åŒ–ç›®æ ‡ï¼š

$$
\underset{g \in G}{\arg\min} \; \mathcal{L}(f, g, \pi_x) + \Omega(g)
$$

å…¶ä¸­ï¼š

* $\mathcal{L}(f, g, \pi_x) = \sum_i \pi_x(z_i)\,(f(z_i) - g(z_i))^2$ï¼Œå³åŠ æƒæ‹Ÿåˆè¯¯å·®ï¼›
* $\Omega(g)$ æ˜¯è§£é‡Šæ¨¡å‹çš„å¤æ‚åº¦æƒ©ç½šï¼ˆä¾‹å¦‚é™åˆ¶ç‰¹å¾æ•°é‡ï¼‰ã€‚

æœ€ç»ˆï¼Œ$g$ çš„å‚æ•°å°±ä»£è¡¨äº†è¾“å…¥ $x$ é™„è¿‘çš„å±€éƒ¨è§£é‡Šã€‚


## 3. æœ€ç®€ä»£ç ä¾‹å­

æˆ‘ä»¬ç”¨ `lime` åº“æ¥è§£é‡Šä¸€ä¸ª sklearn é€»è¾‘å›å½’åˆ†ç±»å™¨çš„é¢„æµ‹ã€‚

```python
import numpy as np
from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
import lime
import lime.lime_tabular

# 1. åŠ è½½æ•°æ®é›†
iris = load_iris()
X, y = iris.data, iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)

# 2. è®­ç»ƒä¸€ä¸ªé»‘ç®±æ¨¡å‹ (é€»è¾‘å›å½’)
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

# 3. åˆå§‹åŒ– LIME è§£é‡Šå™¨
explainer = lime.lime_tabular.LimeTabularExplainer(
    training_data=X_train,
    feature_names=iris.feature_names,
    class_names=iris.target_names,
    mode="classification"
)

# 4. é€‰æ‹©ä¸€ä¸ªæ ·æœ¬è¿›è¡Œè§£é‡Š
i = 0
exp = explainer.explain_instance(
    data_row=X_test[i],
    predict_fn=model.predict_proba,
    num_features=2  # åªè§£é‡Šæœ€é‡è¦çš„2ä¸ªç‰¹å¾
)

# 5. æ‰“å°è§£é‡Šç»“æœ
print("çœŸå®ç±»åˆ«:", iris.target_names[y_test[i]])
print("é¢„æµ‹ç±»åˆ«:", iris.target_names[model.predict(X_test[i].reshape(1, -1))[0]])
print("LIMEè§£é‡Š:")
print(exp.as_list())
```

è¾“å‡ºç±»ä¼¼ï¼š

```
çœŸå®ç±»åˆ«: versicolor
é¢„æµ‹ç±»åˆ«: versicolor
LIMEè§£é‡Š:
[('petal width (cm) <= 1.75', -0.25), ('petal length (cm) > 4.8', +0.35)]
```

è¯´æ˜ï¼šåœ¨è¿™ä¸ªæ ·æœ¬é™„è¿‘ï¼Œæ¨¡å‹é¢„æµ‹ä¸»è¦å—èŠ±ç“£å®½åº¦å’ŒèŠ±ç“£é•¿åº¦å½±å“ã€‚

---

## æ€»ç»“

* **LIME å®šä¹‰**ï¼šé€šè¿‡å±€éƒ¨æ‰°åŠ¨ + ç®€å•æ¨¡å‹æ‹Ÿåˆï¼Œè§£é‡Šé»‘ç®±æ¨¡å‹é¢„æµ‹ã€‚
* **å…¬å¼**ï¼š$\arg\min_g \sum_i \pi_x(z_i)\,(f(z_i)-g(z_i))^2 + \Omega(g)$ã€‚
* **ä»£ç **ï¼šç”¨ `lime` åº“å‡ è¡Œä»£ç å³å¯å®ç°å¯¹åˆ†ç±»æ¨¡å‹çš„è§£é‡Šã€‚

---
ä¸‹é¢æ˜¯ä¸€ä¸ª **LIME ç”¨äºæ–‡æœ¬åˆ†ç±»æ¨¡å‹è§£é‡Šçš„å®Œæ•´ç¤ºä¾‹**ã€‚æˆ‘ä»¬ç”¨ä¸€ä¸ªç®€å•çš„æƒ…æ„Ÿåˆ†ææ¨¡å‹ï¼ˆå½±è¯„æ­£é¢/è´Ÿé¢åˆ†ç±»ï¼‰ï¼Œç„¶åç”¨ **LIME** æ¥è§£é‡Šæ¨¡å‹çš„é¢„æµ‹ã€‚

## LIME è§£é‡Šæ–‡æœ¬åˆ†ç±»æ¨¡å‹

```python
from sklearn.datasets import fetch_20newsgroups
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline
import lime
import lime.lime_text

# 1. å‡†å¤‡æ•°æ®ï¼ˆè¿™é‡Œç”¨20ç±»æ–°é—»æ•°æ®ï¼Œç®€åŒ–æˆäºŒåˆ†ç±»ï¼‰
categories = ['rec.autos', 'sci.med']  # ä¸¤ä¸ªä¸»é¢˜ï¼šæ±½è½¦ vs åŒ»å­¦
train = fetch_20newsgroups(subset='train', categories=categories)
test = fetch_20newsgroups(subset='test', categories=categories)

# 2. æ„å»ºæ–‡æœ¬åˆ†ç±»æ¨¡å‹ (TF-IDF + é€»è¾‘å›å½’)
model = make_pipeline(TfidfVectorizer(), LogisticRegression(max_iter=1000))
model.fit(train.data, train.target)

# 3. åˆå§‹åŒ– LIME è§£é‡Šå™¨
class_names = train.target_names
explainer = lime.lime_text.LimeTextExplainer(class_names=class_names)

# 4. é€‰æ‹©ä¸€æ¡æµ‹è¯•æ ·æœ¬
idx = 10
text_sample = test.data[idx]
true_label = class_names[test.target[idx]]
pred_label = class_names[model.predict([text_sample])[0]]

# 5. LIME è§£é‡Š
exp = explainer.explain_instance(
    text_instance=text_sample,
    classifier_fn=model.predict_proba,
    num_features=5   # æ˜¾ç¤ºæœ€é‡è¦çš„5ä¸ªè¯
)

# 6. æ‰“å°ç»“æœ
print("åŸæ–‡ï¼š", text_sample[:200], "...")
print(f"çœŸå®ç±»åˆ«: {true_label}")
print(f"é¢„æµ‹ç±»åˆ«: {pred_label}")
print("\nLIMEè§£é‡Šï¼ˆæŒ‰è¯çš„é‡è¦æ€§ï¼‰ï¼š")
print(exp.as_list())
```


## è¾“å‡ºç¤ºä¾‹ï¼ˆå¯èƒ½ç±»ä¼¼è¿™æ ·ï¼‰

```
åŸæ–‡ï¼š I recently bought a new car and I really love driving it ...  
çœŸå®ç±»åˆ«: rec.autos  
é¢„æµ‹ç±»åˆ«: rec.autos  

LIMEè§£é‡Šï¼ˆæŒ‰è¯çš„é‡è¦æ€§ï¼‰:
[('car', +0.42), ('driving', +0.25), ('engine', +0.15), ('doctor', -0.18), ('medicine', -0.22)]
```

è§£é‡Šï¼š

* æ¨¡å‹è®¤ä¸º **"car"**ã€**"driving"**ã€**"engine"** å¼ºçƒˆæ¨åŠ¨äº†é¢„æµ‹ä¸º "æ±½è½¦" ç±»ï¼›
* å¦‚æœå‡ºç° **"doctor"**ã€**"medicine"** è¿™ç±»åŒ»å­¦ç›¸å…³è¯ï¼Œä¼šæ¨åŠ¨é¢„æµ‹ä¸º "åŒ»å­¦" ç±»ã€‚



## æ€»ç»“

* **LIME for text**ï¼šé€šè¿‡æ‰°åŠ¨æ–‡æœ¬ï¼ˆåˆ é™¤/æ›¿æ¢è¯è¯­ï¼‰å¹¶è§‚å¯Ÿé¢„æµ‹å˜åŒ–ï¼Œæ‰¾åˆ°å¯¹æ¨¡å‹é¢„æµ‹å½±å“æœ€å¤§çš„è¯ã€‚
* **è¾“å‡º**ï¼šåˆ—å‡ºæ­£å‘/è´Ÿå‘çš„é‡è¦è¯ï¼Œå¸®åŠ©ç†è§£æ¨¡å‹å†³ç­–ä¾æ®ã€‚

---
ä¸‹é¢æ˜¯ä¸€ä¸ª **LIME ç”¨äºå›¾åƒåˆ†ç±»æ¨¡å‹è§£é‡Šçš„å®Œæ•´ç¤ºä¾‹**ã€‚è¿™é‡Œæˆ‘ä»¬ç”¨ Keras é‡Œè‡ªå¸¦çš„ **MNIST æ‰‹å†™æ•°å­—åˆ†ç±»æ¨¡å‹**ï¼Œç„¶åç”¨ **LIME** æ¥è§£é‡Šæ¨¡å‹ä¸ºä»€ä¹ˆé¢„æµ‹æŸå¼ å›¾ç‰‡ä¸ºâ€œ8â€ã€‚


## LIME è§£é‡Šå›¾åƒåˆ†ç±»æ¨¡å‹

```python
import numpy as np
import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from lime import lime_image
from skimage.segmentation import mark_boundaries
import matplotlib.pyplot as plt

# 1. åŠ è½½æ•°æ®
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0  # å½’ä¸€åŒ–
x_train = np.expand_dims(x_train, -1)  # [N, 28, 28, 1]
x_test = np.expand_dims(x_test, -1)

# 2. ç®€å•çš„ CNN æ¨¡å‹
model = Sequential([
    Flatten(input_shape=(28, 28, 1)),
    Dense(128, activation='relu'),
    Dense(10, activation='softmax')
])
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(x_train, y_train, epochs=1, batch_size=128, verbose=1)  # åªè®­ç»ƒ1è½®åšæ¼”ç¤º

# 3. é€‰æ‹©ä¸€å¼ å›¾ç‰‡
idx = 0
image = x_test[idx]
label = y_test[idx]
pred = np.argmax(model.predict(image[np.newaxis]))
print(f"çœŸå®æ ‡ç­¾: {label}, é¢„æµ‹æ ‡ç­¾: {pred}")

# 4. ç”¨ LIME è§£é‡Š
explainer = lime_image.LimeImageExplainer()

def predict_fn(images):
    return model.predict(images)

explanation = explainer.explain_instance(
    image=image.astype('double'),
    classifier_fn=predict_fn,
    top_labels=1,
    hide_color=0,
    num_samples=1000
)

# 5. å¯è§†åŒ–è§£é‡Š
from skimage.color import gray2rgb
temp, mask = explanation.get_image_and_mask(
    label=pred, 
    positive_only=True, 
    hide_rest=False, 
    num_features=10, 
    min_weight=0.0
)

plt.subplot(1,2,1)
plt.title(f"åŸå§‹å›¾åƒ (label={label}, pred={pred})")
plt.imshow(image.squeeze(), cmap="gray")

plt.subplot(1,2,2)
plt.title("LIME è§£é‡Š")
plt.imshow(mark_boundaries(gray2rgb(temp), mask))
plt.show()
```


## è¿è¡Œç»“æœ

* **å·¦è¾¹**ï¼šåŸå§‹çš„æ‰‹å†™æ•°å­—ï¼ˆä¾‹å¦‚ â€œ8â€ï¼‰ã€‚
* **å³è¾¹**ï¼šLIME æ ‡å‡ºå¯¹åˆ†ç±»æœ€é‡è¦çš„å±€éƒ¨åŒºåŸŸï¼ˆç»¿è‰²/è¾¹æ¡†é«˜äº®éƒ¨åˆ†ï¼‰ã€‚

ä¾‹å¦‚ï¼š

* å¦‚æœé¢„æµ‹ä¸º **8**ï¼ŒLIME å¯èƒ½ä¼šé«˜äº® â€œä¸­é—´çš„ç¯å½¢éƒ¨åˆ†â€å’Œâ€œä¸Šä¸‹ä¸¤æ¡å¼§çº¿â€ï¼›
* å¦‚æœé¢„æµ‹ä¸º **3**ï¼ŒLIME å¯èƒ½ä¼šé«˜äº® â€œä¸ŠåŠåœ†â€å’Œâ€œä¸‹åŠåœ†â€éƒ¨åˆ†ã€‚

## æ€»ç»“

* **LIME for images**ï¼šé€šè¿‡æ‰°åŠ¨å›¾åƒçš„ä¸åŒåŒºåŸŸï¼ˆå¦‚é®æŒ¡ superpixelï¼‰ï¼Œè§‚å¯Ÿé¢„æµ‹å˜åŒ–ï¼Œä»è€Œæ‰¾å‡ºæ¨¡å‹æœ€ä¾èµ–çš„åŒºåŸŸã€‚
* **å¥½å¤„**ï¼šä¸ä¾èµ–äºå…·ä½“æ¨¡å‹ç»“æ„ï¼ˆCNN/Transformer éƒ½èƒ½ç”¨ï¼‰ï¼ŒçœŸæ­£å®ç° **æ¨¡å‹æ— å…³è§£é‡Š**ã€‚

---

## LIME åœ¨æ–‡æœ¬ / å›¾åƒ / è¡¨æ ¼ä¸Šçš„å¯¹æ¯”

| æ•°æ®ç±»å‹               | æ‰°åŠ¨æ–¹å¼                         | å¯è§£é‡Šæ¨¡å‹                 | è¾“å‡ºè§£é‡Š                 | åº”ç”¨åœºæ™¯                  |
| ------------------ | ---------------------------- | --------------------- | -------------------- | --------------------- |
| **è¡¨æ ¼æ•°æ® (Tabular)** | éšæœºé‡‡æ ·å¹¶æ›¿æ¢éƒ¨åˆ†ç‰¹å¾å€¼ï¼ˆä¿æŒå±€éƒ¨é‚»åŸŸï¼‰         | çº¿æ€§å›å½’ / å†³ç­–æ ‘            | ç‰¹å¾é‡è¦æ€§åˆ—è¡¨ï¼ˆæƒé‡å¤§å°ã€æ­£è´Ÿå½±å“ï¼‰   | ç»“æ„åŒ–æ•°æ®å»ºæ¨¡ï¼ˆä¿¡ç”¨è¯„åˆ†ã€åŒ»ç–—é£é™©é¢„æµ‹ç­‰ï¼‰ |
| **æ–‡æœ¬æ•°æ® (Text)**    | éšæœºåˆ é™¤/å±è”½å•è¯æˆ– n-gramï¼Œå†çœ‹é¢„æµ‹å˜åŒ–     | çº¿æ€§æ¨¡å‹ï¼ˆåŸºäºè¯è¢‹è¡¨ç¤ºï¼‰          | è¯è¯­é‡è¦æ€§æ’åºï¼ˆå“ªäº›è¯æ¨åŠ¨äº†é¢„æµ‹ï¼‰    | æƒ…æ„Ÿåˆ†æã€ä¸»é¢˜åˆ†ç±»ã€æ–‡æœ¬åˆ†ç±»        |
| **å›¾åƒæ•°æ® (Image)**   | æŠŠå›¾åƒåˆ†æˆ superpixelsï¼Œç„¶åéšæœºé®æŒ¡æŸäº›åŒºåŸŸ | çº¿æ€§æ¨¡å‹ï¼ˆåœ¨ superpixels ä¸Šï¼‰ | çƒ­åŠ›å›¾ / åŒºåŸŸé«˜äº®ï¼ˆæ˜¾ç¤ºæœ€å…³é”®çš„åŒºåŸŸï¼‰ | å›¾åƒåˆ†ç±»ã€åŒ»å­¦å½±åƒè¯Šæ–­ã€ç›®æ ‡æ£€æµ‹      |



## æ€»ç»“

* **è¡¨æ ¼æ•°æ®** â†’ LIME ä¼šå‘Šè¯‰ä½ ï¼šå“ªäº›ç‰¹å¾ï¼ˆå¹´é¾„ã€æ”¶å…¥ã€è¡€å‹ç­‰ï¼‰åœ¨å½“å‰æ ·æœ¬é™„è¿‘å½±å“æœ€å¤§ã€‚
* **æ–‡æœ¬æ•°æ®** â†’ LIME ä¼šå‘Šè¯‰ä½ ï¼šå“ªäº›å•è¯/çŸ­è¯­æœ€æ¨åŠ¨é¢„æµ‹ç»“æœï¼ˆä¾‹å¦‚æƒ…æ„Ÿåˆ†æä¸­çš„ â€œgreatâ€ æˆ– â€œterribleâ€ï¼‰ã€‚
* **å›¾åƒæ•°æ®** â†’ LIME ä¼šå‘Šè¯‰ä½ ï¼šå›¾åƒçš„å“ªäº›åŒºåŸŸï¼ˆçœ¼ç›ã€è¾¹ç¼˜ã€è½®å»“ç­‰ï¼‰æ˜¯æ¨¡å‹åšå‡ºé¢„æµ‹çš„ä¾æ®ã€‚

---

## ğŸ”¹ LIME vs SHAP å¯¹æ¯”

| ç‰¹ç‚¹        | **LIME**                                                    | **SHAP**                                            |   |      |   |                                |
| --------- | ----------------------------------------------------------- | --------------------------------------------------- | - | ---- | - | ------------------------------ |
| **å…¨ç§°**    | Local Interpretable Model-agnostic Explanations             | SHapley Additive exPlanations                       |   |      |   |                                |
| **æ ¸å¿ƒæ€æƒ³**  | åœ¨å±€éƒ¨é‚»åŸŸé‡‡æ · â†’ ç”¨ç®€å•æ¨¡å‹è¿‘ä¼¼é»‘ç®±æ¨¡å‹                                       | åŸºäºåšå¼ˆè®ºçš„ **Shapley å€¼** â†’ è¡¡é‡æ¯ä¸ªç‰¹å¾çš„è¾¹é™…è´¡çŒ®                  |   |      |   |                                |
| **æ•°å­¦å…¬å¼**  | $\arg\min_g \sum_i \pi_x(z_i)(f(z_i)-g(z_i))^2 + \Omega(g)$ | (\phi\_i = \sum\_{S \subseteq F\setminus{i}} \frac{ | S | !(M- | S | -1)!}{M!}\[f(S\cup {i})-f(S)]) |
| **æ¨¡å‹ä¾èµ–æ€§** | å®Œå…¨æ¨¡å‹æ— å…³                                                      | ä¹Ÿå¯æ¨¡å‹æ— å…³ï¼Œä½†æœ‰ä¸“é—¨ä¼˜åŒ–ç‰ˆæœ¬ï¼ˆTreeSHAPã€DeepSHAPï¼‰                  |   |      |   |                                |
| **ç»“æœå½¢å¼**  | å±€éƒ¨è§£é‡Šï¼šæŸä¸ªè¾“å…¥æ ·æœ¬é™„è¿‘ï¼Œç‰¹å¾å¯¹é¢„æµ‹çš„å½±å“                                      | å…¨å±€ + å±€éƒ¨è§£é‡Šï¼šæ¯ä¸ªç‰¹å¾çš„è¾¹é™…è´¡çŒ®å€¼ï¼Œå…·æœ‰åšå¼ˆè®ºä¿è¯                        |   |      |   |                                |
| **ç¨³å®šæ€§**   | ä¸ç¨³å®šï¼ˆä¸åŒé‡‡æ ·å¯èƒ½è§£é‡Šä¸åŒï¼‰                                             | ç¨³å®šï¼ˆShapley å€¼å”¯ä¸€ï¼Œæ»¡è¶³å…¬å¹³æ€§å…¬ç†ï¼‰                             |   |      |   |                                |
| **è®¡ç®—å¤æ‚åº¦** | è¾ƒä½ï¼ˆä¾èµ–é‡‡æ ·å’Œæ‹Ÿåˆçº¿æ€§æ¨¡å‹ï¼‰                                             | è¾ƒé«˜ï¼ˆåŸå§‹ Shapley å¤æ‚åº¦æŒ‡æ•°çº§ï¼Œä½†æœ‰è¿‘ä¼¼/é«˜æ•ˆç®—æ³•ï¼‰                     |   |      |   |                                |
| **å¯è§£é‡Šæ€§**  | ç®€å•ç›´è§‚ï¼Œèƒ½å¿«é€Ÿç»™å‡ºå±€éƒ¨è§£é‡Š                                              | æ›´ä¸¥æ ¼ã€ç†è®ºæ”¯æ’‘å¼ºï¼Œè§£é‡Šç»“æœæ›´å¯ä¿¡                                   |   |      |   |                                |
| **é€‚ç”¨åœºæ™¯**  | éœ€è¦å¿«é€Ÿè¿‘ä¼¼è§£é‡Šï¼Œé‡ç‚¹åœ¨å•ä¸ªæ ·æœ¬çš„å±€éƒ¨å†³ç­–                                       | éœ€è¦ä¸¥æ ¼ã€ç¨³å®šçš„è§£é‡Šï¼Œå°¤å…¶é€‚åˆé«˜é£é™©é¢†åŸŸï¼ˆåŒ»ç–—ã€é‡‘èï¼‰                         |   |      |   |                                |



## æ€»ç»“

* **LIME**ï¼šä¼˜ç‚¹æ˜¯ç›´è§‚ã€å¿«é€Ÿã€æ¨¡å‹æ— å…³ï¼Œç¼ºç‚¹æ˜¯è§£é‡Šä¸ç¨³å®šã€‚é€‚åˆå¿«é€Ÿæ¢ç´¢ã€è°ƒè¯•æ¨¡å‹ã€‚
* **SHAP**ï¼šåŸºäº Shapley å€¼ï¼Œæœ‰æ•°å­¦ä¿è¯ï¼Œæ›´ç¨³å®šã€æ›´å¯ä¿¡ï¼Œä½†è®¡ç®—æˆæœ¬æ›´é«˜ã€‚é€‚åˆéœ€è¦é«˜å¯é æ€§çš„åœºæ™¯ã€‚





