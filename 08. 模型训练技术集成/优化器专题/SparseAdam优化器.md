# SparseAdam ä¼˜åŒ–å™¨

## 1. å®šä¹‰

**SparseAdam** æ˜¯ **Adam** çš„ä¸€ä¸ªå˜ä½“ï¼Œä¸“é—¨ç”¨äºå¤„ç† **ç¨€ç–æ¢¯åº¦ï¼ˆsparse gradientsï¼‰** çš„åœºæ™¯ï¼Œå…¸å‹åº”ç”¨å°±æ˜¯ **embedding å±‚**ï¼ˆå¦‚ NLP çš„è¯å‘é‡è®­ç»ƒï¼‰ã€‚

æ™®é€š Adam ä¼šå¯¹æ‰€æœ‰å‚æ•°ç»´æŠ¤ä¸€é˜¶ã€äºŒé˜¶çŸ©çš„åŠ¨é‡ä¼°è®¡ï¼ˆ`m, v`ï¼‰ï¼Œå³ä½¿æŸäº›å‚æ•°æœ¬è½®æ²¡æœ‰æ›´æ–°ä¹Ÿä¼šè®¡ç®—ï¼Œä»è€Œé€ æˆé¢å¤–å¼€é”€ã€‚è€Œ SparseAdamï¼š

* **åªæ›´æ–°éé›¶æ¢¯åº¦å¯¹åº”çš„å‚æ•°å’ŒåŠ¨é‡é¡¹**ï¼Œé¿å…äº†æ— æ„ä¹‰çš„æ›´æ–°ï¼›
* å¯¹æœªæ›´æ–°çš„å‚æ•°ï¼Œå…¶åŠ¨é‡ä¿æŒä¸å˜ï¼ˆä¸ä¼šè¡°å‡ä¸º 0ï¼‰ã€‚

å› æ­¤åœ¨å¤§è§„æ¨¡ç¨€ç–æ¢¯åº¦åœºæ™¯ï¼ˆå¦‚è¯è¡¨ä¸Šç™¾ä¸‡è§„æ¨¡ï¼‰ï¼ŒSparseAdam èƒ½æ˜¾è‘—æé«˜æ•ˆç‡ã€‚


## 2. æ•°å­¦å…¬å¼

è®¾ï¼š

* å‚æ•°ï¼š $\theta_t$
* æ¢¯åº¦ï¼š $g_t$ï¼ˆç¨€ç–ï¼Œå³å¤§éƒ¨åˆ†åˆ†é‡ä¸º 0ï¼‰
* ä¸€é˜¶çŸ©ï¼ˆåŠ¨é‡ï¼‰ï¼š $m_t$
* äºŒé˜¶çŸ©ï¼š $v_t$
* å­¦ä¹ ç‡ï¼š $\alpha$
* è¡°å‡ç³»æ•°ï¼š $\beta_1, \beta_2 \in [0,1)$
* æ•°å€¼ç¨³å®šé¡¹ï¼š $\epsilon$

### æ›´æ–°æ­¥éª¤ï¼š

1. æ¢¯åº¦è®¡ç®—ï¼ˆç¨€ç–ï¼‰ï¼š

$$
g_t = \nabla_\theta f_t(\theta_{t-1}) \quad (\text{ä»…éé›¶éƒ¨åˆ†})
$$

2. ä¸€é˜¶ä¸äºŒé˜¶çŸ©æ›´æ–°ï¼ˆä»…éé›¶ç´¢å¼•ï¼‰ï¼š

$$
m_t[i] = \beta_1 m_{t-1}[i] + (1-\beta_1) g_t[i]
$$

$$
v_t[i] = \beta_2 v_{t-1}[i] + (1-\beta_2) g_t[i]^2
$$

3. åå·®ä¿®æ­£ï¼ˆbias correctionï¼‰ï¼š

$$
\hat{m}_t[i] = \frac{m_t[i]}{1-\beta_1^t}, \quad 
\hat{v}_t[i] = \frac{v_t[i]}{1-\beta_2^t}
$$

4. å‚æ•°æ›´æ–°ï¼š

$$
\theta_t[i] = \theta_{t-1}[i] - \alpha \cdot \frac{\hat{m}_t[i]}{\sqrt{\hat{v}_t[i]} + \epsilon}
$$

è¿™é‡Œçš„ $i$ è¡¨ç¤ºåªæœ‰ **éé›¶æ¢¯åº¦å¯¹åº”çš„å‚æ•°ç´¢å¼•** è¢«æ›´æ–°ã€‚


## 3. æœ€ç®€ä»£ç ä¾‹å­

ç”¨ **PyTorch çš„ SparseAdam** åœ¨ä¸€ä¸ªåµŒå…¥å±‚ä¸Šåšæ¼”ç¤ºï¼š

```python
import torch
import torch.nn as nn
import torch.optim as optim

# æ¨¡æ‹Ÿä¸€ä¸ªåµŒå…¥å±‚ (è¯è¡¨å¤§å°=1000, ç»´åº¦=50)
embedding = nn.Embedding(1000, 50, sparse=True)

# éšæœºç”Ÿæˆä¸€äº›è¯ID (batch_size=4, seq_len=5)
input_ids = torch.randint(0, 1000, (4, 5))

# å‰å‘ä¼ æ’­ (å¾—åˆ° embedding å‘é‡)
embeddings = embedding(input_ids)

# å®šä¹‰ä¸€ä¸ªç®€å•çš„ç›®æ ‡ (æœ€å°åŒ– embedding å‘é‡çš„ L2 èŒƒæ•°)
loss = embeddings.pow(2).sum()

# ä¼˜åŒ–å™¨ï¼šSparseAdam
optimizer = optim.SparseAdam(embedding.parameters(), lr=0.01)

# åå‘ä¼ æ’­ & æ›´æ–°
optimizer.zero_grad()
loss.backward()
optimizer.step()

print("æ›´æ–°åçš„åµŒå…¥å‘é‡(éƒ¨åˆ†):")
print(embedding.weight[input_ids[0]])
```

### è§£é‡Š

1. **Embedding å±‚** è®¾ç½®äº† `sparse=True`ï¼Œæ¢¯åº¦å°±æ˜¯ç¨€ç–çš„ã€‚
2. **SparseAdam** ä¼šåªæ›´æ–°æœ¬æ¬¡ batch ä¸­å‡ºç°çš„ token å¯¹åº”çš„ embeddingã€‚
3. å…¶ä»–æ²¡å‡ºç°çš„è¯å‘é‡ä¿æŒä¸å˜ï¼Œæ•ˆç‡æ›´é«˜ã€‚

---

## Adam vs SparseAdam å¯¹æ¯”

| ç‰¹ç‚¹               | **Adam**                                 | **SparseAdam**                                                     |
| ---------------- | ---------------------------------------- | ------------------------------------------------------------------ |
| **é€‚ç”¨åœºæ™¯**         | é€šç”¨ä¼˜åŒ–å™¨ï¼Œé€‚åˆæ‰€æœ‰å‚æ•°ï¼ˆç¨ å¯†æ¢¯åº¦ï¼‰ã€‚                      | ä¸“ä¸º **ç¨€ç–æ¢¯åº¦**ï¼ˆå¦‚ `nn.Embedding(sparse=True)`ï¼‰è®¾è®¡ã€‚                      |
| **æ›´æ–°æ–¹å¼**         | å¯¹ **æ‰€æœ‰å‚æ•°** æ›´æ–°ä¸€é˜¶ã€äºŒé˜¶çŸ©ï¼Œå³ä½¿æ¢¯åº¦ä¸º 0ã€‚             | åªæ›´æ–° **éé›¶æ¢¯åº¦å¯¹åº”çš„å‚æ•°** åŠå…¶åŠ¨é‡é¡¹ï¼Œæœªå‡ºç°çš„å‚æ•°ä¿æŒä¸å˜ã€‚                                |
| **å­˜å‚¨å¼€é”€**         | å¿…é¡»ç»´æŠ¤æ‰€æœ‰å‚æ•°çš„åŠ¨é‡çŠ¶æ€ã€‚                           | åªç»´æŠ¤éé›¶ç´¢å¼•çš„åŠ¨é‡çŠ¶æ€ï¼Œå†…å­˜å’Œè®¡ç®—æ›´é«˜æ•ˆã€‚                                             |
| **æ”¶æ•›è¡¨ç°**         | åœ¨ç¨€ç–åœºæ™¯ä¸‹å¯èƒ½æ•ˆç‡ä½ï¼Œè®­ç»ƒæ…¢ã€‚                         | åœ¨ç¨€ç–åœºæ™¯ä¸‹æ›´å¿«ï¼Œèƒ½æ˜¾è‘—å‡å°‘æ— æ•ˆæ›´æ–°ã€‚                                                |
| **å…¸å‹åº”ç”¨**         | CNNã€RNNã€Transformer ç­‰é€šç”¨ä»»åŠ¡ã€‚               | è¯åµŒå…¥ï¼ˆword embeddingsï¼‰ã€å¤§è§„æ¨¡ NLP è¯è¡¨ï¼ˆæ•°åä¸‡ç”šè‡³ç™¾ä¸‡è¯æ±‡ï¼‰ã€‚                        |
| **PyTorch ä½¿ç”¨æ–¹å¼** | `optim.Adam(model.parameters(), lr=...)` | `optim.SparseAdam(embedding.parameters(), lr=...)`  ä»…æ”¯æŒ sparse å‚æ•°ã€‚ |

---

ğŸ‘‰ æ€»ç»“ï¼š

* å¦‚æœæ¨¡å‹å‚æ•° **ç¨ å¯†**ï¼ˆå¦‚å·ç§¯å±‚ã€å…¨è¿æ¥å±‚ï¼‰ï¼Œç”¨ **Adam**ã€‚
* å¦‚æœæ¨¡å‹å‚æ•° **ç¨€ç–**ï¼ˆå°¤å…¶æ˜¯ Embedding å±‚ï¼‰ï¼Œç”¨ **SparseAdam** ä¼šæ›´é«˜æ•ˆã€‚


