## Adamå˜ä½“ ï¼ˆAdamWï¼‰
### ğŸ“– ä»€ä¹ˆæ˜¯Adamå˜ä½“ï¼ˆAdamWï¼‰ï¼Ÿ

AdamWï¼ˆAdaptive Moment Estimation with Weight Decayï¼‰æ˜¯Adamä¼˜åŒ–å™¨çš„ä¸€ç§å˜ä½“ï¼Œæ”¹è¿›äº†Adamåœ¨æ­£åˆ™åŒ–ï¼ˆç‰¹åˆ«æ˜¯L2æ­£åˆ™åŒ–æˆ–æƒé‡è¡°å‡ï¼‰æ–¹é¢çš„å¤„ç†æ–¹å¼ã€‚AdamWé€šè¿‡å°†æƒé‡è¡°å‡ï¼ˆWeight Decayï¼‰ä¸è‡ªé€‚åº”å­¦ä¹ ç‡è§£è€¦ï¼Œè§£å†³äº†åŸå§‹Adamåœ¨æƒé‡è¡°å‡ä¸Šçš„æ¬¡ä¼˜è¡¨ç°é—®é¢˜ï¼Œä½¿å…¶åœ¨è®¸å¤šä»»åŠ¡ä¸­æ”¶æ•›æ›´å¿«ä¸”æ³›åŒ–èƒ½åŠ›æ›´å¼ºã€‚

### ğŸ“– æ ¸å¿ƒåŸç†
Adamä¼˜åŒ–å™¨ç»“åˆäº†ä¸€é˜¶åŠ¨é‡ï¼ˆæ¢¯åº¦å‡å€¼ï¼‰å’ŒäºŒé˜¶åŠ¨é‡ï¼ˆæ¢¯åº¦å¹³æ–¹å‡å€¼ï¼‰æ¥è°ƒæ•´å­¦ä¹ ç‡ï¼ˆè§å‰è¿°Adamé—®é¢˜ï¼‰ã€‚åŸå§‹Adamå°†æƒé‡è¡°å‡ç›´æ¥èå…¥æ¢¯åº¦æ›´æ–°ï¼Œç›¸å½“äºåœ¨æŸå¤±å‡½æ•°ä¸­æ·»åŠ L2æ­£åˆ™åŒ–é¡¹ï¼š


$$
Loss_{Adam} = Loss_{original} + \frac{\lambda}{2} \sum w_i^2
$$

ç„¶è€Œï¼Œè¿™ç§æ–¹å¼ä¸ Adam çš„è‡ªé€‚åº”å­¦ä¹ ç‡æœºåˆ¶ï¼ˆåŸºäºæ¢¯åº¦å¹³æ–¹å‡å€¼ï¼‰ç›¸äº’å¹²æ‰°ï¼Œå¯¼è‡´æ­£åˆ™åŒ–æ•ˆæœä¸ä½³ã€‚
AdamW é€šè¿‡è§£è€¦æƒé‡è¡°å‡ï¼Œç›´æ¥åœ¨å‚æ•°æ›´æ–°æ­¥éª¤ä¸­å‡å»æƒé‡è¡°å‡é¡¹ï¼Œè€Œä¸æ˜¯å°†å…¶èå…¥æ¢¯åº¦è®¡ç®—ï¼š


1. **è®¡ç®—æ¢¯åº¦**ï¼šå¯¹åŸå§‹æŸå¤±å‡½æ•°æ±‚æ¢¯åº¦ $g_t$ã€‚

2. **æ›´æ–°ä¸€é˜¶åŠ¨é‡**ï¼š

$$
m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t
$$

3. **æ›´æ–°äºŒé˜¶åŠ¨é‡**ï¼š

$$
v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2
$$

4. **åå·®æ ¡æ­£**ï¼šå¯¹ $m_t$ å’Œ $v_t$ è¿›è¡Œæ ¡æ­£ä»¥æ¶ˆé™¤åˆå§‹åŒ–åå·®ã€‚

5. **å‚æ•°æ›´æ–°ï¼ˆAdamW çš„åŒºåˆ«åœ¨æ­¤ï¼‰**ï¼š

$$
\theta_{t+1} = \theta_t - \eta \left( \frac{m_t}{\sqrt{v_t} + \epsilon} + \lambda \theta_t \right)
$$


* å…¶ä¸­ï¼š

  * $\eta$ï¼šåˆå§‹å­¦ä¹ ç‡ï¼ˆé€šå¸¸ 0.001ï¼‰ã€‚
  * $\beta_1, \beta_2$ï¼šåŠ¨é‡å‚æ•°ï¼ˆé€šå¸¸ 0.9 å’Œ 0.999ï¼‰ã€‚
  * $\epsilon$ï¼šé˜²æ­¢é™¤é›¶ï¼ˆé€šå¸¸ $1e^{-8}$ï¼‰ã€‚
  * $\lambda$ï¼šæƒé‡è¡°å‡ç³»æ•°ï¼ˆé€šè¿‡ *weight\_decay* è®¾ç½®ï¼‰ã€‚



AdamW ç›´æ¥å¯¹å‚æ•°æ–½åŠ  $\lambda \theta_t$ çš„è¡°å‡ï¼Œè€Œä¸æ˜¯å°†å…¶ä½œä¸ºæ¢¯åº¦çš„ä¸€éƒ¨åˆ†ï¼Œä»è€Œæ›´å¥½åœ°å¹³è¡¡ä¼˜åŒ–å’Œæ­£åˆ™åŒ–ã€‚


### ğŸ“– ä¼˜åŠ¿
- **æ›´å¥½çš„æ­£åˆ™åŒ–**ï¼šè§£è€¦æƒé‡è¡°å‡æé«˜æ³›åŒ–èƒ½åŠ›ï¼Œä¼˜äºåŸå§‹Adamçš„L2æ­£åˆ™åŒ–ã€‚
- **æ”¶æ•›æ›´å¿«**ï¼šåœ¨è®¸å¤šä»»åŠ¡ï¼ˆå¦‚Transformerã€CNNï¼‰ä¸­ï¼ŒAdamWæ¯”Adamæ›´ç¨³å®šã€‚
- **å¹¿æ³›åº”ç”¨**ï¼šAdamWæ˜¯ç°ä»£æ·±åº¦å­¦ä¹ ï¼ˆå¦‚BERTã€GPTï¼‰çš„é»˜è®¤ä¼˜åŒ–å™¨ã€‚

#### å±€é™æ€§
- **è¶…å‚æ•°æ•æ„Ÿ**ï¼šæƒé‡è¡°å‡ç³»æ•° lambda éœ€è°ƒä¼˜ã€‚
- **å†…å­˜éœ€æ±‚**ï¼šä¸Adamç›¸åŒï¼Œéœ€å­˜å‚¨ä¸€é˜¶å’ŒäºŒé˜¶åŠ¨é‡ã€‚

---

### ğŸ“– Pythonä»£ç ç¤ºä¾‹

ä»¥ä¸‹æ˜¯ä¸€ä¸ªæœ€ç®€å•çš„PyTorchç¤ºä¾‹ï¼Œå±•ç¤ºå¦‚ä½•åœ¨MNISTæ‰‹å†™æ•°å­—åˆ†ç±»ä»»åŠ¡ä¸­ä½¿ç”¨AdamWä¼˜åŒ–å™¨ã€‚ä»£ç ä¿æŒæç®€ï¼Œèšç„¦AdamWçš„å®ç°ã€‚

```
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# æ­¥éª¤1: å®šä¹‰ç®€å•çš„å…¨è¿æ¥ç¥ç»ç½‘ç»œ
class SimpleNet(nn.Module):
    def __init__(self):
        super(SimpleNet, self).__init__()
        self.fc = nn.Linear(28 * 28, 10)  # è¾“å…¥ï¼š28x28åƒç´ ï¼Œè¾“å‡ºï¼š10ç±»
    
    def forward(self, x):
        x = x.view(-1, 28 * 28)  # å±•å¹³è¾“å…¥
        x = self.fc(x)
        return x

# æ­¥éª¤2: åŠ è½½MNISTæ•°æ®é›†
transform = transforms.ToTensor()
train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64)

# æ­¥éª¤3: åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°å’ŒAdamWä¼˜åŒ–å™¨
model = SimpleNet()
criterion = nn.CrossEntropyLoss()
optimizer = optim.AdamW(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-8, weight_decay=0.01)

# æ­¥éª¤4: è®­ç»ƒå‡½æ•°
def train(epoch):
    model.train()
    total_loss = 0
    for data, target in train_loader:
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    print(f'Epoch {epoch}, Loss: {total_loss / len(train_loader):.4f}')

# æ­¥éª¤5: æµ‹è¯•å‡½æ•°
def test():
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for data, target in test_loader:
            output = model(data)
            _, predicted = torch.max(output.data, 1)
            total += target.size(0)
            correct += (predicted == target).sum().item()
    accuracy = 100. * correct / total
    print(f'Test Accuracy: {accuracy:.2f}%')

# æ­¥éª¤6: è®­ç»ƒå¾ªç¯
epochs = 5
for epoch in range(1, epochs + 1):
    train(epoch)
    test()
```

---

### ğŸ“– ä»£ç è¯´æ˜

1. **æ¨¡å‹å®šä¹‰**ï¼š
   - `SimpleNet` æ˜¯ä¸€ä¸ªæç®€çš„å…¨è¿æ¥ç¥ç»ç½‘ç»œï¼Œè¾“å…¥ä¸ºMNISTçš„28x28åƒç´ å›¾åƒï¼Œè¾“å‡ºä¸º10ç±»åˆ†ç±»ã€‚

2. **æ•°æ®é›†**ï¼š
   - ä½¿ç”¨`torchvision`åŠ è½½MNISTæ•°æ®é›†ï¼Œæ‰¹é‡å¤§å°ä¸º64ï¼Œæ•°æ®é¢„å¤„ç†ä»…åŒ…æ‹¬è½¬æ¢ä¸ºå¼ é‡ã€‚

3. **AdamWä¼˜åŒ–å™¨**ï¼š
   - åˆå§‹åŒ–ä¸º`optim.AdamW(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-8, weight_decay=0.01)`ã€‚
     - `lr=0.001`ï¼šåˆå§‹å­¦ä¹ ç‡ï¼ŒAdamWå¸¸ç”¨å€¼ã€‚
     - `betas=(0.9, 0.999)`ï¼šä¸€é˜¶å’ŒäºŒé˜¶åŠ¨é‡å‚æ•°ï¼Œä¸Adamç›¸åŒã€‚
     - `eps=1e-8`ï¼šé˜²æ­¢é™¤é›¶ã€‚
     - `weight_decay=0.01`ï¼šæƒé‡è¡°å‡ç³»æ•°ï¼Œæ§åˆ¶æ­£åˆ™åŒ–å¼ºåº¦ï¼ˆæ¯”Adamçš„L2æ­£åˆ™åŒ–æ›´æœ‰æ•ˆï¼‰ã€‚

4. **è®­ç»ƒä¸æµ‹è¯•**ï¼š
   - è®­ç»ƒæ—¶ä½¿ç”¨AdamWæ›´æ–°å‚æ•°ï¼Œæ‰“å°å¹³å‡æŸå¤±ã€‚
   - æµ‹è¯•æ—¶è®¡ç®—åˆ†ç±»å‡†ç¡®ç‡ã€‚

5. **è¾“å‡ºç¤ºä¾‹**ï¼š
   ```
   Epoch 1, Loss: 0.4321, Test Accuracy: 92.50%
   Epoch 2, Loss: 0.2876, Test Accuracy: 93.80%
   Epoch 3, Loss: 0.2564, Test Accuracy: 94.20%
   Epoch 4, Loss: 0.2345, Test Accuracy: 94.50%
   Epoch 5, Loss: 0.2213, Test Accuracy: 94.70%
   ```
   å®é™…å€¼å› éšæœºåˆå§‹åŒ–è€Œå¼‚ã€‚

---

### ğŸ“– å…³é”®ç‚¹
- **è§£è€¦æƒé‡è¡°å‡**ï¼šAdamWç›´æ¥å¯¹å‚æ•°æ–½åŠ è¡°å‡ï¼ˆ`Î»Î¸`ï¼‰ï¼Œè€Œä¸æ˜¯å°†å…¶èå…¥æ¢¯åº¦ï¼Œæ•ˆæœä¼˜äºAdamçš„L2æ­£åˆ™åŒ–ã€‚
- **è¶…å‚æ•°**ï¼š
   - `lr=0.001`ï¼šé»˜è®¤å€¼é€šå¸¸æœ‰æ•ˆã€‚
   - `weight_decay=0.01`ï¼šå¸¸è§å€¼ï¼Œéœ€æ ¹æ®ä»»åŠ¡è°ƒä¼˜ï¼ˆèŒƒå›´1e-4åˆ°1e-1ï¼‰ã€‚
- **ä¸Adamå¯¹æ¯”**ï¼šAdamWåœ¨å¤§å¤šæ•°ä»»åŠ¡ï¼ˆå°¤å…¶æ˜¯Transformerï¼‰ä¸­æ³›åŒ–æ€§èƒ½æ›´å¥½ã€‚

---

### ğŸ“– å®é™…åº”ç”¨åœºæ™¯
- **Transformeræ¨¡å‹**ï¼šAdamWæ˜¯BERTã€GPTç­‰æ¨¡å‹çš„æ ‡å‡†ä¼˜åŒ–å™¨ï¼Œå› å…¶æ­£åˆ™åŒ–æ•ˆæœæ›´å¥½ã€‚
- **æ·±åº¦å­¦ä¹ **ï¼šé€‚ç”¨äºCNNã€RNNç­‰ä»»åŠ¡ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦å¼ºæ­£åˆ™åŒ–çš„åœºæ™¯ã€‚
- **ä¸å…¶ä»–æŠ€æœ¯ç»“åˆ**ï¼šå¯ä¸Dropoutã€BatchNormã€ReduceLROnPlateauï¼ˆå¦‚å‰è¿°é—®é¢˜ï¼‰è”åˆä½¿ç”¨ã€‚

#### æ³¨æ„äº‹é¡¹
- **æƒé‡è¡°å‡è°ƒä¼˜**ï¼š`weight_decay`éœ€é€šè¿‡äº¤å‰éªŒè¯æˆ–è´å¶æ–¯ä¼˜åŒ–è°ƒæ•´ã€‚
- **å­¦ä¹ ç‡**ï¼šAdamWå¯¹å­¦ä¹ ç‡æ•æ„Ÿï¼Œå¯ç»“åˆå­¦ä¹ ç‡è°ƒåº¦ï¼ˆå¦‚ReduceLROnPlateauï¼‰ã€‚
- **å†…å­˜éœ€æ±‚**ï¼šä¸Adamç›¸åŒï¼Œéœ€å­˜å‚¨åŠ¨é‡ä¿¡æ¯ã€‚
