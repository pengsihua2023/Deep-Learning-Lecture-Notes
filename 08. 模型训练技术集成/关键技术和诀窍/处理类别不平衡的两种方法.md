## 处理类别不平衡的两种方法：加权损失函数和过采样
### 什么是类别不平衡及其处理方法？

**类别不平衡**是指在分类任务中，数据集的类别分布不均，例如某些类别样本数量远多于其他类别（如 90% 属于类别 A，10% 属于类别 B）。这会导致模型偏向多数类，忽略少数类，降低性能。深度学习中处理类别不平衡的常见方法包括：

1. **重新采样（Resampling）**：
   - **过采样（Oversampling）**：增加少数类样本（如复制或生成新样本，如 SMOTE）。
   - **欠采样（Undersampling）**：减少多数类样本（如随机丢弃）。
2. **加权损失函数（Weighted Loss Function）**：
   - 给少数类样本分配更高的损失权重，使模型更关注少数类。
3. **数据增强（Data Augmentation）**：
   - 为少数类生成增强数据（如图像旋转、翻转）。
4. **生成模型（如 GAN）**：
   - 使用生成对抗网络为少数类生成新样本。
5. **调整分类阈值**：
   - 在预测时调整分类边界（如降低多数类的阈值）。

以下重点介绍两种最常用且易实现的方法：**加权损失函数**和**过采样**，并提供简单的代码示例。

---

### 方法 1：加权损失函数
#### 原理
在损失函数（如交叉熵损失）中为不同类别分配不同权重，少数类样本的损失权重更高，促使模型更关注少数类。通常根据类别样本比例的倒数计算权重。

#### 代码示例
以下是一个基于 PyTorch 的示例，展示如何用加权交叉熵损失处理 MNIST 数据集的类别不平衡（人为制造不平衡）。

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, Subset
import numpy as np

# 1. 定义模型
class SimpleNet(nn.Module):
    def __init__(self):
        super(SimpleNet, self).__init__()
        self.fc1 = nn.Linear(28 * 28, 256)
        self.fc2 = nn.Linear(256, 10)
    
    def forward(self, x):
        x = x.view(-1, 28 * 28)
        x = torch.relu(self.fc1(x))
        return self.fc2(x)

# 2. 制造不平衡数据集（假设类别 0 占 90%，其他占 10%）
transform = transforms.ToTensor()
train_dataset = datasets.MNIST('.', train=True, download=True, transform=transform)

# 获取每个类别的索引
indices = []
for i in range(10):
    idx = [j for j, (_, label) in enumerate(train_dataset) if label == i]
    if i == 0:  # 类别 0（多数类）保留 90%
        indices.extend(np.random.choice(idx, int(0.9 * len(idx)), replace=False))
    else:  # 其他类别（少数类）保留 10%
        indices.extend(np.random.choice(idx, int(0.1 * len(idx)), replace=False))

imbalanced_dataset = Subset(train_dataset, indices)
train_loader = DataLoader(imbalanced_dataset, batch_size=64, shuffle=True)

# 3. 计算类别权重（根据类别频率的倒数）
class_counts = np.bincount([train_dataset.targets[i] for i in indices])
class_weights = 1.0 / class_counts
class_weights = class_weights / class_weights.sum() * len(class_counts)  # 归一化
class_weights = torch.FloatTensor(class_weights).to(device=torch.device("cuda" if torch.cuda.is_available() else "cpu"))

# 4. 训练设置
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = SimpleNet().to(device)
optimizer = optim.Adam(model.parameters(), lr=1e-3)
criterion = nn.CrossEntropyLoss(weight=class_weights)  # 加权损失

# 5. 训练循环
for epoch in range(2):  # 2 个 epoch 作为示例
    model.train()
    total_loss = 0
    for data, target in train_loader:
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    print(f"Epoch {epoch + 1}, Avg Loss: {total_loss / len(train_loader):.6f}")

# 6. 测试
test_loader = DataLoader(datasets.MNIST('.', train=False, transform=transform), batch_size=64)
model.eval()
correct = 0
total = 0
with torch.no_grad():
    for data, target in test_loader:
        data, target = data.to(device), target.to(device)
        output = model(data)
        pred = output.argmax(dim=1, keepdim=True)
        correct += pred.eq(target.view_as(pred)).sum().item()
        total += target.size(0)
print(f"Test Accuracy: {correct / total * 100:.2f}%")
```

#### 代码说明
1. **制造不平衡**：通过采样使类别 0 占 90%，其他类别占 10%，模拟不平衡数据集。
2. **类权重**：计算每个类别的权重（频率倒数），传入 `nn.CrossEntropyLoss` 的 `weight` 参数。
3. **训练**：加权损失函数使模型更关注少数类（类别 1-9）。
4. **评估**：在完整测试集上评估模型性能。

---

### 方法 2：过采样（Oversampling）
#### 原理
通过重复采样少数类样本，增加其在训练中的出现频率，使数据集更平衡。可以使用 `WeightedRandomSampler` 来实现按权重采样的过采样。

#### 代码示例
基于 PyTorch 的过采样示例，同样在 MNIST 上人为制造不平衡并处理。

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, Subset, WeightedRandomSampler
import numpy as np

# 1. 定义模型（与方法 1 相同）
class SimpleNet(nn.Module):
    def __init__(self):
        super(SimpleNet, self).__init__()
        self.fc1 = nn.Linear(28 * 28, 256)
        self.fc2 = nn.Linear(256, 10)
    
    def forward(self, x):
        x = x.view(-1, 28 * 28)
        x = torch.relu(self.fc1(x))
        return self.fc2(x)

# 2. 制造不平衡数据集（与方法 1 相同）
transform = transforms.ToTensor()
train_dataset = datasets.MNIST('.', train=True, download=True, transform=transform)
indices = []
for i in range(10):
    idx = [j for j, (_, label) in enumerate(train_dataset) if label == i]
    if i == 0:
        indices.extend(np.random.choice(idx, int(0.9 * len(idx)), replace=False))
    else:
        indices.extend(np.random.choice(idx, int(0.1 * len(idx)), replace=False))
imbalanced_dataset = Subset(train_dataset, indices)

# 3. 过采样：计算采样权重
targets = [train_dataset.targets[i].item() for i in indices]
class_counts = np.bincount(targets)
class_weights = 1.0 / class_counts
samples_weights = [class_weights[t] for t in targets]
sampler = WeightedRandomSampler(weights=samples_weights, num_samples=len(samples_weights), replacement=True)
train_loader = DataLoader(imbalanced_dataset, batch_size=64, sampler=sampler)

# 4. 训练设置
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = SimpleNet().to(device)
optimizer = optim.Adam(model.parameters(), lr=1e-3)
criterion = nn.CrossEntropyLoss()  # 无需加权损失，使用过采样平衡

# 5. 训练循环
for epoch in range(2):
    model.train()
    total_loss = 0
    for data, target in train_loader:
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    print(f"Epoch {epoch + 1}, Avg Loss: {total_loss / len(train_loader):.6f}")

# 6. 测试
test_loader = DataLoader(datasets.MNIST('.', train=False, transform=transform), batch_size=64)
model.eval()
correct = 0
total = 0
with torch.no_grad():
    for data, target in test_loader:
        data, target = data.to(device), target.to(device)
        output = model(data)
        pred = output.argmax(dim=1, keepdim=True)
        correct += pred.eq(target.view_as(pred)).sum().item()
        total += target.size(0)
print(f"Test Accuracy: {correct / total * 100:.2f}%")
```

#### 代码说明
1. **制造不平衡**：同方法 1，类别 0 占 90%。
2. **过采样**：使用 `WeightedRandomSampler`，根据类别频率倒数设置采样权重，确保少数类被更频繁采样。
3. **训练**：通过采样器平衡数据分布，无需修改损失函数。
4. **评估**：在测试集上验证模型性能。

---

### 关键点
1. **加权损失**：
   - 简单且无需修改数据集，直接在损失函数中调整权重。
   - 适合大多数分类任务，但需手动计算权重。
2. **过采样**：
   - 通过采样平衡数据，适合数据量较小时。
   - 可能导致过拟合少数类，需结合正则化。
3. **结合其他技术**：
   - 可与 **Curriculum Learning**（先用平衡数据训练简单样本）、**AMP**（加速训练）或 **Optuna/Ray Tune**（优化超参数）结合。
   - 示例中可添加 `torch.cuda.amp` 或 Optuna 优化学习率。

---

### 实际效果
- **加权损失**：提高少数类预测准确率（如类别 1-9），对多数类影响较小。
- **过采样**：平衡训练过程，但可能增加训练时间（因少数类样本重复）。
- **适用性**：两种方法在不平衡比率较高（如 10:1）时显著提升少数类性能，通常可提高 5-20% 的少数类准确率。

