## è‡ªåŠ¨æ··åˆç²¾åº¦ï¼ˆAMPï¼‰è®­ç»ƒ
â€œè‡ªåŠ¨æ··åˆç²¾åº¦ï¼ˆAutomatic Mixed Precisionï¼ŒAMPï¼‰â€æ˜¯æ·±åº¦å­¦ä¹ è®­ç»ƒä¸­ä¸€ç§ **è‡ªåŠ¨ä½¿ç”¨ä¸åŒæ•°å€¼ç²¾åº¦ï¼ˆFP16 å’Œ FP32ï¼‰è¿›è¡Œè®¡ç®—** çš„æŠ€æœ¯ï¼Œä¸»è¦ç›®çš„æ˜¯åœ¨ **ä¿æŒæ¨¡å‹ç²¾åº¦çš„åŒæ—¶åŠ é€Ÿè®­ç»ƒå¹¶å‡å°‘æ˜¾å­˜å ç”¨**ã€‚

---

### 1. èƒŒæ™¯

åœ¨æ·±åº¦å­¦ä¹ ä¸­å¸¸ç”¨çš„æµ®ç‚¹æ•°ç²¾åº¦æœ‰ï¼š

* **FP32 (å•ç²¾åº¦æµ®ç‚¹æ•°)**ï¼šå¸¸è§„è®­ç»ƒçš„æ ‡å‡†æ ¼å¼ï¼Œæ•°å€¼èŒƒå›´å¤§ã€ç¨³å®šæ€§å¥½ï¼Œä½†è¿ç®—é€Ÿåº¦æ…¢ã€æ˜¾å­˜å ç”¨é«˜ã€‚
* **FP16 (åŠç²¾åº¦æµ®ç‚¹æ•°)**ï¼šç²¾åº¦è¾ƒä½ï¼Œä½†è¿ç®—é€Ÿåº¦æ›´å¿«ï¼Œå ç”¨æ˜¾å­˜æ›´å°‘ã€‚

å¦‚æœæŠŠæ‰€æœ‰è¿ç®—éƒ½åˆ‡æ¢åˆ° FP16ï¼Œè®­ç»ƒå¯èƒ½ä¼šå› ä¸ºæº¢å‡ºã€ä¸‹æº¢ã€èˆå…¥è¯¯å·®è€Œå¤±è´¥ã€‚
äºæ˜¯ AMP å°±å‡ºç°äº†â€”â€”å®ƒèƒ½ **æ™ºèƒ½åœ°å†³å®šå“ªäº›æ“ä½œç”¨ FP16ï¼Œå“ªäº›å¿…é¡»ä¿ç•™ FP32**ã€‚

---

### 2. AMP çš„æ ¸å¿ƒæ€æƒ³

AMP ä¼šï¼š

* åœ¨ **é€‚åˆ FP16 çš„åœ°æ–¹**ï¼ˆæ¯”å¦‚çŸ©é˜µä¹˜æ³•ã€å·ç§¯ï¼‰ä½¿ç”¨ FP16 â†’ åŠ é€Ÿè¿ç®—ã€èŠ‚çœæ˜¾å­˜ã€‚
* åœ¨ **éœ€è¦é«˜ç²¾åº¦çš„åœ°æ–¹**ï¼ˆæ¯”å¦‚ loss è®¡ç®—ã€æ¢¯åº¦ç´¯ç§¯ã€softmaxã€batch normï¼‰ä¿ç•™ FP32 â†’ ä¿è¯æ•°å€¼ç¨³å®šæ€§ã€‚
* ä½¿ç”¨ **åŠ¨æ€ loss scalingï¼ˆæŸå¤±ç¼©æ”¾ï¼‰** é¿å… FP16 ä¸‹çš„ä¸‹æº¢é—®é¢˜ã€‚

è¿™æ ·å°±èƒ½æ—¢å¿«åˆç¨³ã€‚

---

### 3. åœ¨ä¸»æµæ¡†æ¶ä¸­çš„å®ç°

* **PyTorch**ï¼š
  æä¾› `torch.cuda.amp`ï¼Œé€šè¿‡ `autocast` å’Œ `GradScaler` å®ç°ã€‚

  ```python
  scaler = torch.cuda.amp.GradScaler()

  for data, target in loader:
      optimizer.zero_grad()
      with torch.cuda.amp.autocast():
          output = model(data)
          loss = loss_fn(output, target)
      scaler.scale(loss).backward()
      scaler.step(optimizer)
      scaler.update()
  ```

* **TensorFlow**ï¼š
  å¯ä»¥é€šè¿‡ `mixed_float16` policy è‡ªåŠ¨æ··åˆç²¾åº¦ã€‚

* **NVIDIA Apex**ï¼ˆæ—©æœŸï¼‰ï¼š
  æä¾› `amp.initialize` æ¥ç®€åŒ– FP16 è®­ç»ƒï¼Œä½†ç°åœ¨ PyTorch è‡ªå¸¦ `torch.cuda.amp` å·²æˆä¸ºä¸»æµã€‚

---

### 4. AMP çš„ä¼˜ç‚¹

- åŠ å¿«è®­ç»ƒé€Ÿåº¦ï¼ˆç‰¹åˆ«æ˜¯ GPU Tensor Cores ä¸Šï¼‰
- æ˜¾å­˜å ç”¨æ›´ä½ï¼Œå¯ä»¥è®­ç»ƒæ›´å¤§ batch size / æ¨¡å‹
- ä¿æŒå‡ ä¹ç›¸åŒçš„æ”¶æ•›ç²¾åº¦

---
### ä»£ç ä¾‹å­
**PyTorch + AMP** çš„æœ€å°ç¤ºä¾‹ï¼Œç”¨ä¸€ä¸ªç®€å•çš„ **å…¨è¿æ¥ç½‘ç»œåœ¨ MNIST ä¸Šè®­ç»ƒ** æ¥è¯´æ˜è‡ªåŠ¨æ··åˆç²¾åº¦ï¼ˆAMPï¼‰çš„ç”¨æ³•ã€‚

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms

# 1. æ•°æ®åŠ è½½
transform = transforms.Compose([transforms.ToTensor()])
train_loader = torch.utils.data.DataLoader(
    datasets.MNIST('.', train=True, download=True, transform=transform),
    batch_size=64, shuffle=True
)

# 2. ç®€å•çš„æ¨¡å‹
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(28*28, 256)
        self.fc2 = nn.Linear(256, 10)

    def forward(self, x):
        x = x.view(-1, 28*28)
        x = torch.relu(self.fc1(x))
        return self.fc2(x)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = Net().to(device)

optimizer = optim.Adam(model.parameters(), lr=1e-3)
criterion = nn.CrossEntropyLoss()

# 3. AMP ç›¸å…³å¯¹è±¡
scaler = torch.cuda.amp.GradScaler()  # è‡ªåŠ¨ç¼©æ”¾é¿å…æº¢å‡º

# 4. è®­ç»ƒå¾ªç¯
for epoch in range(1, 3):  # åªè·‘ 2 ä¸ª epoch ç¤ºä¾‹
    model.train()
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)

        optimizer.zero_grad()

        # åœ¨ autocast ä¸‹è‡ªåŠ¨æ··åˆç²¾åº¦
        with torch.cuda.amp.autocast():
            output = model(data)
            loss = criterion(output, target)

        # åå‘ä¼ æ’­æ—¶ç”¨ scaler æ¥ç¼©æ”¾æ¢¯åº¦
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()

        if batch_idx % 200 == 0:
            print(f"Train Epoch: {epoch} [{batch_idx*len(data)}/{len(train_loader.dataset)}]  Loss: {loss.item():.6f}")
```

---

### ğŸ”‘ å…³é”®ç‚¹ï¼š

1. `torch.cuda.amp.autocast()`

   * å‰å‘ä¼ æ’­æ—¶è‡ªåŠ¨é€‰æ‹© FP16 / FP32ã€‚
   * æ¯”å¦‚å·ç§¯ã€çŸ©é˜µä¹˜æ³•ä¼šç”¨ FP16ï¼ŒåŠ é€Ÿå¹¶å‡å°‘æ˜¾å­˜ï¼›è€ŒæŸå¤±è®¡ç®—ä»ç”¨ FP32 ä¿æŒç¨³å®šã€‚

2. `torch.cuda.amp.GradScaler()`

   * åå‘ä¼ æ’­æ—¶è‡ªåŠ¨ç¼©æ”¾ lossï¼Œé¿å… FP16 ä¸‹æ¢¯åº¦ä¸‹æº¢ã€‚

3. å…¶ä½™åœ°æ–¹å’Œæ™®é€šè®­ç»ƒæµç¨‹å‡ ä¹ä¸€æ ·ï¼Œå‡ ä¹ä¸ç”¨æ”¹åŠ¨ä»£ç ï¼Œå°±èƒ½å¯ç”¨ AMPã€‚

---

