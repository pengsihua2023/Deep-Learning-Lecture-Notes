# æ¨¡å‹å‰ªæï¼ˆModel Pruningï¼‰

## ğŸ“– 1. å®šä¹‰ï¼ˆDefinitionï¼‰

**æ¨¡å‹å‰ªæï¼ˆModel Pruningï¼‰** æ˜¯ä¸€ç§ **å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•**ï¼Œé€šè¿‡ **ç§»é™¤ç¥ç»ç½‘ç»œä¸­å†—ä½™æˆ–ä¸é‡è¦çš„å‚æ•°/è¿æ¥**ï¼Œä»¥å‡å°‘æ¨¡å‹å¤§å°å’Œè®¡ç®—å¼€é”€ï¼ŒåŒæ—¶å°½é‡ä¿æŒæ€§èƒ½ã€‚

* å‰ªæé€šå¸¸åœ¨ **é¢„è®­ç»ƒæ¨¡å‹** ä¸Šè¿›è¡Œï¼Œç„¶åå†å¯¹ä¿ç•™çš„å‚æ•°è¿›è¡Œ **å¾®è°ƒ**ã€‚
* å¯åˆ†ä¸ºï¼š

  * **éç»“æ„åŒ–å‰ªæï¼ˆunstructured pruningï¼‰**ï¼šç›´æ¥å°†æŸäº›æƒé‡ç½®é›¶ï¼Œä¸æ”¹å˜å¼ é‡å½¢çŠ¶ã€‚
  * **ç»“æ„åŒ–å‰ªæï¼ˆstructured pruningï¼‰**ï¼šç§»é™¤æ•´ä¸ªé€šé“ã€å·ç§¯æ ¸æˆ–æ³¨æ„åŠ›å¤´ã€‚
* å¾®è°ƒé˜¶æ®µï¼š

  * ä¿ç•™éé›¶å‚æ•°ï¼Œç»§ç»­åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸Šè®­ç»ƒï¼Œä»¥æ¢å¤æ€§èƒ½ã€‚

---

## ğŸ”¢ 2. æ•°å­¦æè¿°ï¼ˆMathematical Formulationï¼‰

è®¾åŸå§‹æ¨¡å‹å‚æ•°ä¸ºï¼š

$$
W = \{ w_1, w_2, \dots, w_n \}
$$

å®šä¹‰ä¸€ä¸ª **æ©ç å‘é‡** $M = \{ m_1, m_2, \dots, m_n \}$ï¼Œå…¶ä¸­ï¼š

$$
m_i \in \{0, 1\}, \quad W' = W \odot M
$$

å…¶ä¸­ï¼š

* $m_i = 0$ è¡¨ç¤ºè¯¥å‚æ•°è¢«å‰ªæï¼›
* $m_i = 1$ è¡¨ç¤ºè¯¥å‚æ•°ä¿ç•™ï¼›
* $\odot$ è¡¨ç¤ºé€å…ƒç´ ä¹˜æ³•ã€‚

è®­ç»ƒç›®æ ‡å‡½æ•°å˜ä¸ºï¼š

$$
\mathcal{L}(W', M) = - \sum_{(x, y)} \log p(y \mid x; W \odot M)
$$

åœ¨å¾®è°ƒæ—¶ï¼Œå›ºå®š $M$ï¼Œä¼˜åŒ–ä¿ç•™ä¸‹æ¥çš„å‚æ•° $W'$ã€‚


## ğŸ’» 3. ç®€å•ä»£ç æ¼”ç¤ºï¼ˆPyTorchï¼‰

ä»¥ä¸‹ä»£ç å±•ç¤ºä¸€ä¸ª **éç»“æ„åŒ–å‰ªæ + å¾®è°ƒ** çš„æœ€å°ç¤ºä¾‹ï¼ŒåŸºäº PyTorchï¼š

```python
import torch
import torch.nn as nn
import torch.nn.utils.prune as prune
import torch.nn.functional as F

# ä¸€ä¸ªç®€å•çš„å…¨è¿æ¥ç½‘ç»œ
class SimpleNet(nn.Module):
    def __init__(self, input_size=100, hidden_size=50, num_classes=2):
        super(SimpleNet, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, num_classes)

    def forward(self, x):
        x = F.relu(self.fc1(x))
        return self.fc2(x)

# åˆå§‹åŒ–æ¨¡å‹
model = SimpleNet()
print("å‚æ•°æ•°é‡ (å‰ªæå‰):", sum(p.numel() for p in model.parameters()))

# å¯¹ç¬¬ä¸€å±‚æƒé‡è¿›è¡Œéç»“æ„åŒ–å‰ªæ (50% æœ€å°æƒé‡å‰ªæ)
prune.l1_unstructured(model.fc1, name="weight", amount=0.5)

# æŸ¥çœ‹å‰ªææ©ç 
print("å‰ªææ©ç ï¼š")
print(model.fc1.weight_mask)

# ä½¿ç”¨å‰ªæåçš„æ¨¡å‹è¿›è¡Œä¸€æ¬¡å‰å‘ä¼ æ’­
x = torch.randn(4, 100)
logits = model(x)
print("è¾“å‡º logits:", logits)

# å‰ªæåç»§ç»­å¾®è°ƒ
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
labels = torch.tensor([0, 1, 0, 1])
loss = F.cross_entropy(logits, labels)
loss.backward()
optimizer.step()
```


## âœ… æ€»ç»“

* **å®šä¹‰**ï¼šModel Pruning æ˜¯é€šè¿‡å‰ªæ‰ä¸é‡è¦çš„æƒé‡/é€šé“æ¥å‹ç¼©æ¨¡å‹ï¼Œç„¶åå¯¹å‰©ä½™å‚æ•°è¿›è¡Œå¾®è°ƒã€‚
* **æ•°å­¦å½¢å¼**ï¼šä½¿ç”¨æ©ç  $M$ å¯¹å‚æ•° $W$ è¿›è¡Œç¨€ç–åŒ–ï¼Œä¼˜åŒ– $\mathcal{L}(W \odot M)$ã€‚
* **ä»£ç **ï¼šPyTorch çš„ `torch.nn.utils.prune` å¯æ–¹ä¾¿åœ°å®ç°æƒé‡å‰ªæï¼Œå¹¶åœ¨å‰ªæåè¿›è¡Œå¾®è°ƒã€‚

