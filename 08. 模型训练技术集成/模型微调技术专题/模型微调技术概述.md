# 模型微调（Fine-Tuning）技术概述

## 📖 1. 什么是模型微调

* **模型微调 (Fine-Tuning)** 是指在预训练模型（Pre-trained Model）的基础上，利用下游任务数据进一步训练，使模型适应具体任务的过程。
* 与 **从零训练模型** 相比，微调通常：

  * 需要更少的数据；
  * 收敛更快；
  * 具有更好的泛化性能。

微调是现代 **迁移学习 (Transfer Learning)** 的核心手段，尤其在大规模预训练模型（如 BERT、GPT、ResNet、Vision Transformer）出现之后，已成为标准范式。



## 📖 2. 微调的主要技术分类

### （1）全参数微调 (Full Fine-Tuning)

* 思路：加载预训练模型 → **更新所有参数**。
* 优点：灵活、效果好；
* 缺点：参数量大，计算/存储开销高，不适合超大模型（如百亿参数 LLM）。


### （2）参数高效微调 (PEFT, Parameter-Efficient Fine-Tuning)

目标：只更新一小部分参数，大幅降低计算和存储成本。
常见方法：

* **Adapter Tuning**

  * 在 Transformer 层中插入小型瓶颈网络（降维→升维），只训练 Adapter。
  * 公式： $h' = h + W_{up}\,\sigma(W_{down} h)$。

* **LoRA (Low-Rank Adaptation)**

  * 冻结原始权重，只学习低秩增量：
$\Delta W = BA$ 。
  * 特点：超高效，适合 LLM。

* **Prefix Tuning / Prompt Tuning**

  * 在注意力机制中注入 **可训练前缀向量**，不改动模型参数。
  * 常用于文本生成类任务。

* **QLoRA**

  * 在 LoRA 的基础上，先把大模型量化到 4-bit，再插入 LoRA，进一步降低显存占用。

* **其他扩展**

  * **LoHA**：低秩 + Hadamard 乘积增强表示能力。
  * **LoKr**：利用 Kronecker 积构造低秩更新，进一步减少参数。


### （3）冻结部分层微调

* 方法：只更新部分层（如最后几层），其他层冻结。
* 适合任务数据有限时，避免过拟合。


### （4）多任务 & 连续微调

* **多任务微调**：一个模型同时适应多个任务。
* **连续微调 (Continual Fine-Tuning)**：在新任务上继续训练，同时避免灾难性遗忘。


## 📖 3. 优缺点对比

| 方法                   | 优点             | 缺点                   | 适用场景           |
| -------------------- | -------------- | -------------------- | -------------- |
| 全参数微调                | 效果最好，可灵活适配任务   | 参数量大，存储 & 计算开销高      | 小模型或任务非常重要时    |
| Adapter              | 参数量少，可快速切换任务   | 需要修改模型结构             | 多任务学习，NLP/NLU  |
| LoRA / QLoRA         | 极小参数量，显存需求低，易用 | 需要挑选合适的插入位置          | LLM 指令微调、聊天机器人 |
| Prefix/Prompt Tuning | 与模型大小解耦，参数最少   | 表达能力受限，通常需要较长 prefix | 文本生成、对话系统      |
| 层冻结微调                | 简单，能防止过拟合      | 灵活性有限，可能性能不足         | 数据较少的小任务       |



## 📖 4. 应用场景

* **自然语言处理 (NLP)**

  * 文本分类、问答系统、机器翻译、对话系统
  * 典型：BERT 微调文本分类；GPT 微调对话任务

* **计算机视觉 (CV)**

  * 图像分类、目标检测、医学影像分析
  * 典型：ResNet 微调用于医学图像识别

* **大语言模型 (LLM) 微调**

  * 指令微调 (Instruction Tuning)
  * 对齐 (Alignment)：RLHF、DPO
  * 行业垂直应用：金融、法律、医疗大模型


## 📖 总结

* **模型微调** = 在预训练模型基础上适配下游任务
* **全参数微调**：灵活但代价高
* **参数高效微调 (PEFT)**：Adapter、LoRA、Prefix/Prompt Tuning、QLoRA → 是当前主流
* **选择方法的关键**：任务规模、数据多少、显存限制、性能需求

---

模型微调技术路线图（思维导图版）  

## 模型微调技术路线图

```
模型微调 (Fine-Tuning)
│
├── 全参数微调 (Full Fine-Tuning)
│   └── 更新所有参数
│       ├─ 优点：灵活、效果好
│       └─ 缺点：参数量大，计算开销高
│
├── 参数高效微调 (PEFT, Parameter-Efficient Fine-Tuning)
│   │
│   ├── Adapter
│   │   └── 在每层插入瓶颈层 (降维→非线性→升维)
│   │
│   ├── LoRA (Low-Rank Adaptation)
│   │   └── 低秩矩阵分解 ΔW = B A
│   │
│   ├── QLoRA
│   │   └── 量化 (4-bit) + LoRA
│   │
│   ├── Prefix Tuning
│   │   └── 在注意力层加 prefix key/value
│   │
│   ├── Prompt Tuning
│   │   └── 训练可学习的 prompt 向量
│   │
│   ├── LoHA
│   │   └── ΔW = (B A) ⊙ (D C)，Hadamard 增强
│   │
│   └── LoKr
│       └── ΔW = A ⊗ B，Kronecker 积压缩
│
├── 层冻结微调
│   └── 冻结部分层，只训练最后几层
│
└── 特殊形式
    ├── 多任务微调
    ├── 连续学习 (Continual Fine-Tuning)
    └── 指令微调 / RLHF / DPO (LLM 对齐)
```


## 解读

* **主干**：微调分为 **全参数** 和 **参数高效** 两大类；
* **PEFT 技术**：是目前大模型微调的主流，涵盖 Adapter、LoRA、QLoRA、Prefix/Prompt Tuning 等；
* **扩展方法**：LoHA、LoKr 等是在 LoRA 基础上的改进；
* **特殊形式**：多任务、连续学习、对齐技术。




